{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "# import seaborn as sns\n",
    "# sns.set_style(\"white\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import adam_v2\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, Dropout, Lambda, BatchNormalization\n",
    "from tensorflow import cast, uint32, where\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from PIL import Image\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size_ori = 500\n",
    "img_size_target = 256\n",
    "\n",
    "def upsample(img):\n",
    "    if img_size_ori == img_size_target:\n",
    "        return img\n",
    "    return img.resize((img_size_target, img_size_target), Image.ANTIALIAS)\n",
    "    #res = np.zeros((img_size_target, img_size_target), dtype=img.dtype)\n",
    "    #res[:img_size_ori, :img_size_ori] = img\n",
    "    #return res\n",
    "    \n",
    "# def downsample(img):\n",
    "#     if img_size_ori == img_size_target:\n",
    "#         return img\n",
    "#     return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)\n",
    "#     #return img[:img_size_ori, :img_size_ori]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2569\n"
     ]
    }
   ],
   "source": [
    "out = os.listdir(\"TIFF black\")\n",
    "out.sort()\n",
    "inp = os.listdir(\"TIFF 8bit\")\n",
    "inp.sort()\n",
    "N = len(out)\n",
    "out_data = np.zeros((N, 256, 256))\n",
    "in_data = np.zeros((N,256,256))\n",
    "print(N)\n",
    "\n",
    "for i in range(N):\n",
    "    out_data[i] = upsample(load_img(r\"TIFF black/\"+out[i], color_mode='grayscale'))\n",
    "for i in range(N):\n",
    "    in_data[i] = upsample(load_img(r\"TIFF 8bit/\"+inp[i], color_mode='grayscale'))\n",
    "    \n",
    "    \n",
    "#plt.imshow(in_data[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_data = np.array(out_data)/255\n",
    "inp_data = np.array(in_data)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(in_data.reshape(-1, img_size_target, img_size_target, 1), \n",
    "    out_data.reshape(-1, img_size_target, img_size_target, 1),  test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1] [0 1]\n"
     ]
    }
   ],
   "source": [
    "#x_train = (lambda x(x_train)\n",
    "#x_test = (lambda x: 1.0*(x>0.02))(x_test)\n",
    "y_train = (lambda x: (x>0.03).astype(int))(y_train)\n",
    "y_test =(lambda x: (x>0.03).astype(int))(y_test)\n",
    "\n",
    "print(np.unique(y_train), np.unique(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05c9a4c820>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y_train[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05c9988df0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out_data[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f05c996e760>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inp_data[150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 03:53:48.321097: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 03:53:51.058263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 28105 MB memory:  -> device: 0, name: Tesla V100-SXM3-32GB, pci bus id: 0000:3b:00.0, compute capability: 7.0\n",
      "2022-05-06 03:53:51.060821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 28141 MB memory:  -> device: 1, name: Tesla V100-SXM3-32GB, pci bus id: 0000:57:00.0, compute capability: 7.0\n",
      "2022-05-06 03:53:51.064274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 28141 MB memory:  -> device: 2, name: Tesla V100-SXM3-32GB, pci bus id: 0000:59:00.0, compute capability: 7.0\n",
      "2022-05-06 03:53:51.066562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 28105 MB memory:  -> device: 3, name: Tesla V100-SXM3-32GB, pci bus id: 0000:5e:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    # 128 -> 64\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 64 -> 32\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.25)(pool3)\n",
    "    \n",
    "    # 16 -> 8\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.25)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(pool4)\n",
    "    convm = BatchNormalization()(convm)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'he_normal')(convm)\n",
    "    convm = BatchNormalization()(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.25)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = BatchNormalization()(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = BatchNormalization()(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.25)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = BatchNormalization()(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = BatchNormalization()(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "\n",
    "    #uconv1 = Dropout(0.5)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "#     output_layer = Lambda(lambda x : cast(x, uint32))(output_layer)\n",
    "    \n",
    "    return output_layer\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_layer, start_neurons):\n",
    "    # 128 -> 64\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(input_layer)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(conv1)\n",
    "    conv1 = BatchNormalization()(conv1)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(0.25)(pool1)\n",
    "\n",
    "    # 64 -> 32\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(pool1)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(0.25)(pool2)\n",
    "\n",
    "    # 32 -> 16\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(pool2)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(0.25)(pool3)\n",
    "    \n",
    "    # 16 -> 8\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(pool3)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(conv4)\n",
    "    conv4 = BatchNormalization()(conv4)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(0.25)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(pool4)\n",
    "    convm = BatchNormalization()(convm)\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=\"relu\", padding=\"same\", kernel_initializer = 'uniform')(convm)\n",
    "    convm = BatchNormalization()(convm)\n",
    "\n",
    "    # 8 -> 16\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = Dropout(0.25)(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = BatchNormalization()(uconv4)\n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=\"relu\", padding=\"same\")(uconv4)\n",
    "    uconv4 = BatchNormalization()(uconv4)\n",
    "\n",
    "    # 16 -> 32\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = Dropout(0.25)(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = BatchNormalization()(uconv3)\n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=\"relu\", padding=\"same\")(uconv3)\n",
    "    uconv3 = BatchNormalization()(uconv3)\n",
    "\n",
    "    # 32 -> 64\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = Dropout(0.25)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=\"relu\", padding=\"same\")(uconv2)\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "\n",
    "    # 64 -> 128\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = Dropout(0.25)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=\"relu\", padding=\"same\")(uconv1)\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "\n",
    "    #uconv1 = Dropout(0.5)(uconv1)\n",
    "    output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "#     output_layer = Lambda(lambda x : cast(x, uint32))(output_layer)\n",
    "    \n",
    "    return output_layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(A,B):\n",
    "    return ((A & B).sum()+1)/(A.sum()+1)\n",
    "\n",
    "def precision(A,B):\n",
    "    return ((B&A).sum()+1)/(B.sum()+1)\n",
    "\n",
    "def f1(A,B):\n",
    "    p = precision(A,B)\n",
    "    r = recall(A,B)\n",
    "    return 2*p*r/(p+r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "1.0\n",
      "0.14285714285714285\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[1,0,1],[1,1,1],[0,1,0]])\n",
    "B = np.array([[0,0,0],[0,0,0],[0,0,0]])\n",
    "\n",
    "print(A & B)\n",
    "print(precision(A,B))\n",
    "print(recall(A,B))\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, MeanIoU, Accuracy\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightedBinCrossEntr(positive_weight=15):\n",
    "    def f(y_true, y_pred, w = positive_weight):\n",
    "        y_true = cast(y_true, tf.float32)\n",
    "        weights = tf.ones_like(y_pred)  # (None,512,512,1)\n",
    "        weights = tf.where(y_pred > 0.5, w * weights, weights)\n",
    "        out = keras.losses.binary_crossentropy(y_true, y_pred)  # (None,512,512)\n",
    "        out = K.expand_dims(out, axis=-1) * weights  # (None,512,512,1)* (None,512,512,1)\n",
    "        return K.mean(out)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceLoss():  \n",
    "    def f(targets, inputs, smooth=1e-6):\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = cast(K.flatten(targets), tf.float32)\n",
    "\n",
    "        intersection = K.sum(tf.multiply(targets, inputs))\n",
    "        dice = (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "        return 1 - dice\n",
    "    return f\n",
    "\n",
    "def weightedDiceLoss(weight_ratio=4):\n",
    "    def f(targets, inputs, smooth=1e-6, weight_ratio = weight_ratio):\n",
    "        weights = tf.ones_like(targets)  # (None,512,512,1)\n",
    "        weights = tf.where(inputs > 0.5, weight_ratio * weights, weights)\n",
    "        out = diceLoss()(targets, inputs)  # (None,512,512)\n",
    "        out = K.expand_dims(out, axis=-1) * cast(weights, tf.float32)  # (None,512,512,1)* (None,512,512,1)\n",
    "        return K.mean(out)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DiceBCE():\n",
    "    def f(targets, inputs, smooth=1e-6):\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = K.flatten(targets)\n",
    "        targets=cast(targets,tf.float32)\n",
    "        print(inputs[:10])\n",
    "        print(targets[:10])\n",
    "        BCE =  keras.losses.binary_crossentropy(targets, inputs)\n",
    "        intersection = K.sum(tf.multiply(cast(targets,tf.float32), cast(inputs, tf.float32)))  \n",
    "        dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "\n",
    "        return Dice_BCE\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoULoss():\n",
    "    def f(targets, inputs, smooth=1e-6):\n",
    "        inputs = K.flatten(inputs)\n",
    "        targets = cast(K.flatten(targets), tf.float32)\n",
    "\n",
    "        intersection = K.sum(tf.multiply(targets, inputs))\n",
    "        total = K.sum(targets) + K.sum(inputs)\n",
    "        union = total - intersection\n",
    "\n",
    "        IoU = (intersection + smooth) / (union + smooth)\n",
    "        return 1 - IoU\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model(input_layer, output_layer) for x in range(20)\n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models[\"BCE\"]=[0,Model(input_layer, output_layer)]\n",
    "\n",
    "\n",
    "for i in [3,10, 17, 25, 40]:\n",
    "    input_layer = Input((img_size_target, img_size_target,1))\n",
    "    output_layer = build_model(input_layer, 20)\n",
    "    models[\"wBCE-\"+str(i)]=[i, Model(input_layer, output_layer)]\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models[\"diceLoss\"] = [0,Model(input_layer, output_layer)]\n",
    "\n",
    "\n",
    "for i in [3,10, 17, 25, 40]:\n",
    "    input_layer = Input((img_size_target, img_size_target,1))\n",
    "    output_layer = build_model(input_layer, 20)\n",
    "    models[\"wDice-\"+str(i)]=[i, Model(input_layer, output_layer)]\n",
    "\n",
    "    \n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models[\"DiceBCE\"] = [0,Model(input_layer, output_layer)]\n",
    "    \n",
    "    \n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models[\"IoULoss\"]=[0, Model(input_layer, output_layer)]\n",
    "\n",
    "\n",
    "weighteds=[\"wBCE\", \"wDice\"]\n",
    "functions = {   \"BCE\": BinaryCrossentropy,\n",
    "                \"wBCE\": weightedBinCrossEntr,\n",
    "                \"diceLoss\": diceLoss,\n",
    "                \"wDice\": weightedDiceLoss,\n",
    "                \"DiceBCE\": DiceBCE,\n",
    "                \"IoULoss\":IoULoss\n",
    "            }\n",
    "\n",
    "histories = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 03:54:04.177268: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/65 [==============================] - ETA: 0s - loss: 0.5789 - recall: 0.8483 - precision: 0.1233 - mean_io_u: 0.5387 - accuracy: 0.8886 - auc: 0.8977\n",
      "Epoch 1: val_loss improved from inf to 0.46644, saving model to ./iter_BCE.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 03:54:23.545670: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 28s 333ms/step - loss: 0.5789 - recall: 0.8483 - precision: 0.1233 - mean_io_u: 0.5387 - accuracy: 0.8886 - auc: 0.8977 - val_loss: 0.4664 - val_recall: 0.5250 - val_precision: 0.3213 - val_mean_io_u: 0.4910 - val_accuracy: 0.9714 - val_auc: 0.8667 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3166 - recall: 0.8290 - precision: 0.6205 - mean_io_u: 0.6993 - accuracy: 0.9878 - auc: 0.9519\n",
      "Epoch 2: val_loss improved from 0.46644 to 0.14346, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.3163 - recall: 0.8287 - precision: 0.6209 - mean_io_u: 0.6993 - accuracy: 0.9878 - auc: 0.9518 - val_loss: 0.1435 - val_recall: 0.2451 - val_precision: 0.8578 - val_mean_io_u: 0.4953 - val_accuracy: 0.9857 - val_auc: 0.8786 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1769 - recall: 0.7478 - precision: 0.7956 - mean_io_u: 0.7108 - accuracy: 0.9920 - auc: 0.9771\n",
      "Epoch 3: val_loss improved from 0.14346 to 0.08575, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.1767 - recall: 0.7477 - precision: 0.7956 - mean_io_u: 0.7108 - accuracy: 0.9920 - auc: 0.9770 - val_loss: 0.0858 - val_recall: 0.3142 - val_precision: 0.9131 - val_mean_io_u: 0.5211 - val_accuracy: 0.9871 - val_auc: 0.9477 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1061 - recall: 0.7265 - precision: 0.8349 - mean_io_u: 0.6928 - accuracy: 0.9925 - auc: 0.9902\n",
      "Epoch 4: val_loss improved from 0.08575 to 0.06686, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.1060 - recall: 0.7265 - precision: 0.8350 - mean_io_u: 0.6928 - accuracy: 0.9925 - auc: 0.9902 - val_loss: 0.0669 - val_recall: 0.2614 - val_precision: 0.9519 - val_mean_io_u: 0.5341 - val_accuracy: 0.9864 - val_auc: 0.9697 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0694 - recall: 0.7572 - precision: 0.8338 - mean_io_u: 0.6771 - accuracy: 0.9929 - auc: 0.9943\n",
      "Epoch 5: val_loss improved from 0.06686 to 0.05408, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0694 - recall: 0.7572 - precision: 0.8338 - mean_io_u: 0.6771 - accuracy: 0.9929 - auc: 0.9943 - val_loss: 0.0541 - val_recall: 0.3437 - val_precision: 0.9128 - val_mean_io_u: 0.5632 - val_accuracy: 0.9876 - val_auc: 0.9846 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0498 - recall: 0.7778 - precision: 0.8366 - mean_io_u: 0.6682 - accuracy: 0.9933 - auc: 0.9961\n",
      "Epoch 6: val_loss improved from 0.05408 to 0.04085, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0498 - recall: 0.7778 - precision: 0.8366 - mean_io_u: 0.6682 - accuracy: 0.9933 - auc: 0.9961 - val_loss: 0.0409 - val_recall: 0.5474 - val_precision: 0.9165 - val_mean_io_u: 0.6077 - val_accuracy: 0.9909 - val_auc: 0.9939 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0385 - recall: 0.7927 - precision: 0.8407 - mean_io_u: 0.6593 - accuracy: 0.9936 - auc: 0.9968\n",
      "Epoch 7: val_loss improved from 0.04085 to 0.03360, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0385 - recall: 0.7928 - precision: 0.8406 - mean_io_u: 0.6592 - accuracy: 0.9936 - auc: 0.9968 - val_loss: 0.0336 - val_recall: 0.7153 - val_precision: 0.8646 - val_mean_io_u: 0.6398 - val_accuracy: 0.9928 - val_auc: 0.9952 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0315 - recall: 0.8052 - precision: 0.8442 - mean_io_u: 0.6556 - accuracy: 0.9938 - auc: 0.9974\n",
      "Epoch 8: val_loss improved from 0.03360 to 0.02661, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.0315 - recall: 0.8053 - precision: 0.8443 - mean_io_u: 0.6556 - accuracy: 0.9938 - auc: 0.9974 - val_loss: 0.0266 - val_recall: 0.7344 - val_precision: 0.8757 - val_mean_io_u: 0.6298 - val_accuracy: 0.9933 - val_auc: 0.9956 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0271 - recall: 0.8132 - precision: 0.8458 - mean_io_u: 0.6491 - accuracy: 0.9940 - auc: 0.9976\n",
      "Epoch 9: val_loss improved from 0.02661 to 0.02429, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.0271 - recall: 0.8133 - precision: 0.8458 - mean_io_u: 0.6491 - accuracy: 0.9940 - auc: 0.9976 - val_loss: 0.0243 - val_recall: 0.7667 - val_precision: 0.8612 - val_mean_io_u: 0.6240 - val_accuracy: 0.9936 - val_auc: 0.9965 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0237 - recall: 0.8225 - precision: 0.8502 - mean_io_u: 0.6453 - accuracy: 0.9942 - auc: 0.9978\n",
      "Epoch 10: val_loss improved from 0.02429 to 0.02073, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0237 - recall: 0.8225 - precision: 0.8502 - mean_io_u: 0.6453 - accuracy: 0.9942 - auc: 0.9978 - val_loss: 0.0207 - val_recall: 0.7985 - val_precision: 0.8829 - val_mean_io_u: 0.6402 - val_accuracy: 0.9945 - val_auc: 0.9976 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0212 - recall: 0.8315 - precision: 0.8528 - mean_io_u: 0.6423 - accuracy: 0.9944 - auc: 0.9980\n",
      "Epoch 11: val_loss improved from 0.02073 to 0.01935, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.0212 - recall: 0.8315 - precision: 0.8528 - mean_io_u: 0.6423 - accuracy: 0.9944 - auc: 0.9980 - val_loss: 0.0193 - val_recall: 0.8069 - val_precision: 0.8778 - val_mean_io_u: 0.6581 - val_accuracy: 0.9945 - val_auc: 0.9970 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0195 - recall: 0.8356 - precision: 0.8545 - mean_io_u: 0.6394 - accuracy: 0.9945 - auc: 0.9980\n",
      "Epoch 12: val_loss improved from 0.01935 to 0.01770, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0195 - recall: 0.8356 - precision: 0.8546 - mean_io_u: 0.6393 - accuracy: 0.9945 - auc: 0.9980 - val_loss: 0.0177 - val_recall: 0.8243 - val_precision: 0.8741 - val_mean_io_u: 0.6477 - val_accuracy: 0.9947 - val_auc: 0.9976 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0177 - recall: 0.8457 - precision: 0.8602 - mean_io_u: 0.6422 - accuracy: 0.9947 - auc: 0.9981\n",
      "Epoch 13: val_loss did not improve from 0.01770\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0177 - recall: 0.8457 - precision: 0.8602 - mean_io_u: 0.6422 - accuracy: 0.9947 - auc: 0.9981 - val_loss: 0.0184 - val_recall: 0.7802 - val_precision: 0.8642 - val_mean_io_u: 0.6217 - val_accuracy: 0.9938 - val_auc: 0.9974 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0165 - recall: 0.8521 - precision: 0.8639 - mean_io_u: 0.6416 - accuracy: 0.9949 - auc: 0.9985\n",
      "Epoch 14: val_loss improved from 0.01770 to 0.01482, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0165 - recall: 0.8521 - precision: 0.8639 - mean_io_u: 0.6416 - accuracy: 0.9949 - auc: 0.9985 - val_loss: 0.0148 - val_recall: 0.8311 - val_precision: 0.8955 - val_mean_io_u: 0.6504 - val_accuracy: 0.9952 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0156 - recall: 0.8566 - precision: 0.8646 - mean_io_u: 0.6379 - accuracy: 0.9950 - auc: 0.9986\n",
      "Epoch 15: val_loss did not improve from 0.01482\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.0156 - recall: 0.8566 - precision: 0.8646 - mean_io_u: 0.6380 - accuracy: 0.9950 - auc: 0.9986 - val_loss: 0.0160 - val_recall: 0.8178 - val_precision: 0.8754 - val_mean_io_u: 0.6359 - val_accuracy: 0.9946 - val_auc: 0.9971 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0147 - recall: 0.8612 - precision: 0.8694 - mean_io_u: 0.6395 - accuracy: 0.9952 - auc: 0.9987\n",
      "Epoch 16: val_loss did not improve from 0.01482\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.0147 - recall: 0.8612 - precision: 0.8694 - mean_io_u: 0.6394 - accuracy: 0.9952 - auc: 0.9987 - val_loss: 0.0150 - val_recall: 0.8400 - val_precision: 0.8779 - val_mean_io_u: 0.6445 - val_accuracy: 0.9950 - val_auc: 0.9977 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0140 - recall: 0.8647 - precision: 0.8710 - mean_io_u: 0.6390 - accuracy: 0.9953 - auc: 0.9987\n",
      "Epoch 17: val_loss did not improve from 0.01482\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0140 - recall: 0.8647 - precision: 0.8711 - mean_io_u: 0.6390 - accuracy: 0.9953 - auc: 0.9987 - val_loss: 0.0207 - val_recall: 0.8223 - val_precision: 0.8702 - val_mean_io_u: 0.6698 - val_accuracy: 0.9946 - val_auc: 0.9948 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0134 - recall: 0.8677 - precision: 0.8743 - mean_io_u: 0.6424 - accuracy: 0.9954 - auc: 0.9987\n",
      "Epoch 18: val_loss improved from 0.01482 to 0.01410, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.0134 - recall: 0.8677 - precision: 0.8743 - mean_io_u: 0.6424 - accuracy: 0.9954 - auc: 0.9987 - val_loss: 0.0141 - val_recall: 0.8405 - val_precision: 0.8804 - val_mean_io_u: 0.6444 - val_accuracy: 0.9951 - val_auc: 0.9975 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0129 - recall: 0.8693 - precision: 0.8767 - mean_io_u: 0.6395 - accuracy: 0.9954 - auc: 0.9986\n",
      "Epoch 19: val_loss improved from 0.01410 to 0.01331, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.0129 - recall: 0.8693 - precision: 0.8767 - mean_io_u: 0.6395 - accuracy: 0.9954 - auc: 0.9986 - val_loss: 0.0133 - val_recall: 0.8543 - val_precision: 0.8810 - val_mean_io_u: 0.6392 - val_accuracy: 0.9953 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0126 - recall: 0.8703 - precision: 0.8773 - mean_io_u: 0.6338 - accuracy: 0.9955 - auc: 0.9987\n",
      "Epoch 20: val_loss improved from 0.01331 to 0.01223, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0126 - recall: 0.8703 - precision: 0.8773 - mean_io_u: 0.6338 - accuracy: 0.9955 - auc: 0.9987 - val_loss: 0.0122 - val_recall: 0.8700 - val_precision: 0.8862 - val_mean_io_u: 0.6459 - val_accuracy: 0.9956 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0121 - recall: 0.8741 - precision: 0.8804 - mean_io_u: 0.6374 - accuracy: 0.9956 - auc: 0.9987\n",
      "Epoch 21: val_loss did not improve from 0.01223\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.0121 - recall: 0.8741 - precision: 0.8804 - mean_io_u: 0.6374 - accuracy: 0.9956 - auc: 0.9987 - val_loss: 0.0125 - val_recall: 0.8585 - val_precision: 0.8844 - val_mean_io_u: 0.6310 - val_accuracy: 0.9954 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0123 - recall: 0.8678 - precision: 0.8781 - mean_io_u: 0.6289 - accuracy: 0.9954 - auc: 0.9985\n",
      "Epoch 22: val_loss improved from 0.01223 to 0.01211, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0123 - recall: 0.8678 - precision: 0.8781 - mean_io_u: 0.6289 - accuracy: 0.9954 - auc: 0.9985 - val_loss: 0.0121 - val_recall: 0.8560 - val_precision: 0.8815 - val_mean_io_u: 0.6221 - val_accuracy: 0.9953 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0118 - recall: 0.8732 - precision: 0.8812 - mean_io_u: 0.6289 - accuracy: 0.9956 - auc: 0.9987\n",
      "Epoch 23: val_loss improved from 0.01211 to 0.01108, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0118 - recall: 0.8733 - precision: 0.8812 - mean_io_u: 0.6289 - accuracy: 0.9956 - auc: 0.9987 - val_loss: 0.0111 - val_recall: 0.8721 - val_precision: 0.8953 - val_mean_io_u: 0.6390 - val_accuracy: 0.9959 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0112 - recall: 0.8775 - precision: 0.8850 - mean_io_u: 0.6355 - accuracy: 0.9957 - auc: 0.9988\n",
      "Epoch 24: val_loss did not improve from 0.01108\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0112 - recall: 0.8775 - precision: 0.8851 - mean_io_u: 0.6355 - accuracy: 0.9957 - auc: 0.9988 - val_loss: 0.0112 - val_recall: 0.8652 - val_precision: 0.8934 - val_mean_io_u: 0.6325 - val_accuracy: 0.9957 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0108 - recall: 0.8824 - precision: 0.8885 - mean_io_u: 0.6393 - accuracy: 0.9959 - auc: 0.9988\n",
      "Epoch 25: val_loss improved from 0.01108 to 0.01068, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0108 - recall: 0.8824 - precision: 0.8885 - mean_io_u: 0.6393 - accuracy: 0.9959 - auc: 0.9988 - val_loss: 0.0107 - val_recall: 0.8737 - val_precision: 0.8997 - val_mean_io_u: 0.6479 - val_accuracy: 0.9960 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0104 - recall: 0.8848 - precision: 0.8918 - mean_io_u: 0.6438 - accuracy: 0.9960 - auc: 0.9989\n",
      "Epoch 26: val_loss did not improve from 0.01068\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0104 - recall: 0.8848 - precision: 0.8918 - mean_io_u: 0.6438 - accuracy: 0.9960 - auc: 0.9989 - val_loss: 0.0107 - val_recall: 0.8680 - val_precision: 0.9016 - val_mean_io_u: 0.6395 - val_accuracy: 0.9959 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0105 - recall: 0.8830 - precision: 0.8906 - mean_io_u: 0.6387 - accuracy: 0.9959 - auc: 0.9988\n",
      "Epoch 27: val_loss did not improve from 0.01068\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0105 - recall: 0.8830 - precision: 0.8906 - mean_io_u: 0.6387 - accuracy: 0.9959 - auc: 0.9988 - val_loss: 0.0107 - val_recall: 0.8790 - val_precision: 0.8966 - val_mean_io_u: 0.6528 - val_accuracy: 0.9960 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0100 - recall: 0.8869 - precision: 0.8938 - mean_io_u: 0.6461 - accuracy: 0.9961 - auc: 0.9989\n",
      "Epoch 28: val_loss improved from 0.01068 to 0.01048, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0100 - recall: 0.8869 - precision: 0.8938 - mean_io_u: 0.6461 - accuracy: 0.9961 - auc: 0.9989 - val_loss: 0.0105 - val_recall: 0.8782 - val_precision: 0.8928 - val_mean_io_u: 0.6319 - val_accuracy: 0.9959 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0101 - recall: 0.8854 - precision: 0.8921 - mean_io_u: 0.6406 - accuracy: 0.9960 - auc: 0.9988\n",
      "Epoch 29: val_loss did not improve from 0.01048\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0101 - recall: 0.8855 - precision: 0.8922 - mean_io_u: 0.6406 - accuracy: 0.9960 - auc: 0.9988 - val_loss: 0.0107 - val_recall: 0.8642 - val_precision: 0.9010 - val_mean_io_u: 0.6381 - val_accuracy: 0.9958 - val_auc: 0.9978 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0104 - recall: 0.8808 - precision: 0.8895 - mean_io_u: 0.6293 - accuracy: 0.9959 - auc: 0.9986\n",
      "Epoch 30: val_loss did not improve from 0.01048\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0104 - recall: 0.8808 - precision: 0.8895 - mean_io_u: 0.6293 - accuracy: 0.9959 - auc: 0.9986 - val_loss: 0.0110 - val_recall: 0.8672 - val_precision: 0.8968 - val_mean_io_u: 0.6448 - val_accuracy: 0.9958 - val_auc: 0.9978 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0097 - recall: 0.8890 - precision: 0.8960 - mean_io_u: 0.6400 - accuracy: 0.9961 - auc: 0.9989\n",
      "Epoch 31: val_loss improved from 0.01048 to 0.01040, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.0097 - recall: 0.8890 - precision: 0.8960 - mean_io_u: 0.6400 - accuracy: 0.9961 - auc: 0.9989 - val_loss: 0.0104 - val_recall: 0.8770 - val_precision: 0.8982 - val_mean_io_u: 0.6374 - val_accuracy: 0.9960 - val_auc: 0.9979 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0094 - recall: 0.8922 - precision: 0.8988 - mean_io_u: 0.6469 - accuracy: 0.9962 - auc: 0.9990\n",
      "Epoch 32: val_loss improved from 0.01040 to 0.01026, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0094 - recall: 0.8922 - precision: 0.8988 - mean_io_u: 0.6469 - accuracy: 0.9962 - auc: 0.9990 - val_loss: 0.0103 - val_recall: 0.8729 - val_precision: 0.9022 - val_mean_io_u: 0.6517 - val_accuracy: 0.9960 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0095 - recall: 0.8903 - precision: 0.8977 - mean_io_u: 0.6360 - accuracy: 0.9962 - auc: 0.9990\n",
      "Epoch 33: val_loss improved from 0.01026 to 0.00952, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0095 - recall: 0.8904 - precision: 0.8977 - mean_io_u: 0.6360 - accuracy: 0.9962 - auc: 0.9990 - val_loss: 0.0095 - val_recall: 0.8873 - val_precision: 0.9060 - val_mean_io_u: 0.6553 - val_accuracy: 0.9963 - val_auc: 0.9983 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0090 - recall: 0.8949 - precision: 0.9017 - mean_io_u: 0.6493 - accuracy: 0.9963 - auc: 0.9991\n",
      "Epoch 34: val_loss improved from 0.00952 to 0.00916, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0090 - recall: 0.8949 - precision: 0.9016 - mean_io_u: 0.6493 - accuracy: 0.9963 - auc: 0.9991 - val_loss: 0.0092 - val_recall: 0.8894 - val_precision: 0.9067 - val_mean_io_u: 0.6463 - val_accuracy: 0.9964 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0090 - recall: 0.8946 - precision: 0.9021 - mean_io_u: 0.6501 - accuracy: 0.9964 - auc: 0.9991\n",
      "Epoch 35: val_loss did not improve from 0.00916\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0090 - recall: 0.8946 - precision: 0.9021 - mean_io_u: 0.6501 - accuracy: 0.9964 - auc: 0.9991 - val_loss: 0.0093 - val_recall: 0.8813 - val_precision: 0.9076 - val_mean_io_u: 0.6422 - val_accuracy: 0.9962 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0088 - recall: 0.8974 - precision: 0.9040 - mean_io_u: 0.6514 - accuracy: 0.9964 - auc: 0.9991\n",
      "Epoch 36: val_loss improved from 0.00916 to 0.00911, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0088 - recall: 0.8974 - precision: 0.9040 - mean_io_u: 0.6514 - accuracy: 0.9964 - auc: 0.9991 - val_loss: 0.0091 - val_recall: 0.8918 - val_precision: 0.9045 - val_mean_io_u: 0.6474 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0087 - recall: 0.8980 - precision: 0.9045 - mean_io_u: 0.6521 - accuracy: 0.9965 - auc: 0.9991\n",
      "Epoch 37: val_loss did not improve from 0.00911\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0087 - recall: 0.8980 - precision: 0.9045 - mean_io_u: 0.6521 - accuracy: 0.9965 - auc: 0.9991 - val_loss: 0.0093 - val_recall: 0.8867 - val_precision: 0.9071 - val_mean_io_u: 0.6540 - val_accuracy: 0.9963 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0085 - recall: 0.8991 - precision: 0.9059 - mean_io_u: 0.6565 - accuracy: 0.9965 - auc: 0.9991\n",
      "Epoch 38: val_loss improved from 0.00911 to 0.00888, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0085 - recall: 0.8991 - precision: 0.9060 - mean_io_u: 0.6565 - accuracy: 0.9965 - auc: 0.9991 - val_loss: 0.0089 - val_recall: 0.8979 - val_precision: 0.9040 - val_mean_io_u: 0.6637 - val_accuracy: 0.9964 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0085 - recall: 0.8999 - precision: 0.9055 - mean_io_u: 0.6555 - accuracy: 0.9965 - auc: 0.9991\n",
      "Epoch 39: val_loss improved from 0.00888 to 0.00886, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.0085 - recall: 0.8999 - precision: 0.9055 - mean_io_u: 0.6555 - accuracy: 0.9965 - auc: 0.9991 - val_loss: 0.0089 - val_recall: 0.8905 - val_precision: 0.9094 - val_mean_io_u: 0.6548 - val_accuracy: 0.9964 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0084 - recall: 0.8999 - precision: 0.9062 - mean_io_u: 0.6533 - accuracy: 0.9965 - auc: 0.9991\n",
      "Epoch 40: val_loss did not improve from 0.00886\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0084 - recall: 0.8998 - precision: 0.9062 - mean_io_u: 0.6534 - accuracy: 0.9965 - auc: 0.9991 - val_loss: 0.0089 - val_recall: 0.8917 - val_precision: 0.9095 - val_mean_io_u: 0.6657 - val_accuracy: 0.9964 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0085 - recall: 0.8991 - precision: 0.9061 - mean_io_u: 0.6462 - accuracy: 0.9965 - auc: 0.9991\n",
      "Epoch 41: val_loss improved from 0.00886 to 0.00880, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.0085 - recall: 0.8990 - precision: 0.9061 - mean_io_u: 0.6461 - accuracy: 0.9965 - auc: 0.9991 - val_loss: 0.0088 - val_recall: 0.8942 - val_precision: 0.9084 - val_mean_io_u: 0.6565 - val_accuracy: 0.9965 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0088 - recall: 0.8955 - precision: 0.9024 - mean_io_u: 0.6390 - accuracy: 0.9964 - auc: 0.9989\n",
      "Epoch 42: val_loss did not improve from 0.00880\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0088 - recall: 0.8955 - precision: 0.9024 - mean_io_u: 0.6390 - accuracy: 0.9964 - auc: 0.9989 - val_loss: 0.0108 - val_recall: 0.8691 - val_precision: 0.8886 - val_mean_io_u: 0.6229 - val_accuracy: 0.9957 - val_auc: 0.9969 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0087 - recall: 0.8954 - precision: 0.9030 - mean_io_u: 0.6271 - accuracy: 0.9964 - auc: 0.9990\n",
      "Epoch 43: val_loss did not improve from 0.00880\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0087 - recall: 0.8954 - precision: 0.9029 - mean_io_u: 0.6271 - accuracy: 0.9964 - auc: 0.9990 - val_loss: 0.0112 - val_recall: 0.8733 - val_precision: 0.8858 - val_mean_io_u: 0.6390 - val_accuracy: 0.9957 - val_auc: 0.9961 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0081 - recall: 0.9025 - precision: 0.9093 - mean_io_u: 0.6415 - accuracy: 0.9966 - auc: 0.9992\n",
      "Epoch 44: val_loss did not improve from 0.00880\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0081 - recall: 0.9026 - precision: 0.9093 - mean_io_u: 0.6415 - accuracy: 0.9966 - auc: 0.9992 - val_loss: 0.0088 - val_recall: 0.8965 - val_precision: 0.9062 - val_mean_io_u: 0.6513 - val_accuracy: 0.9965 - val_auc: 0.9984 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0079 - recall: 0.9044 - precision: 0.9115 - mean_io_u: 0.6463 - accuracy: 0.9967 - auc: 0.9992\n",
      "Epoch 45: val_loss improved from 0.00880 to 0.00849, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.0079 - recall: 0.9044 - precision: 0.9115 - mean_io_u: 0.6463 - accuracy: 0.9967 - auc: 0.9992 - val_loss: 0.0085 - val_recall: 0.9029 - val_precision: 0.9090 - val_mean_io_u: 0.6565 - val_accuracy: 0.9966 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0079 - recall: 0.9055 - precision: 0.9116 - mean_io_u: 0.6493 - accuracy: 0.9967 - auc: 0.9992\n",
      "Epoch 46: val_loss improved from 0.00849 to 0.00837, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0079 - recall: 0.9055 - precision: 0.9116 - mean_io_u: 0.6493 - accuracy: 0.9967 - auc: 0.9992 - val_loss: 0.0084 - val_recall: 0.9033 - val_precision: 0.9091 - val_mean_io_u: 0.6570 - val_accuracy: 0.9966 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0079 - recall: 0.9056 - precision: 0.9121 - mean_io_u: 0.6524 - accuracy: 0.9967 - auc: 0.9992\n",
      "Epoch 47: val_loss did not improve from 0.00837\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0079 - recall: 0.9056 - precision: 0.9121 - mean_io_u: 0.6524 - accuracy: 0.9967 - auc: 0.9992 - val_loss: 0.0084 - val_recall: 0.9027 - val_precision: 0.9084 - val_mean_io_u: 0.6578 - val_accuracy: 0.9966 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0078 - recall: 0.9064 - precision: 0.9124 - mean_io_u: 0.6541 - accuracy: 0.9967 - auc: 0.9992\n",
      "Epoch 48: val_loss did not improve from 0.00837\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0078 - recall: 0.9064 - precision: 0.9124 - mean_io_u: 0.6541 - accuracy: 0.9967 - auc: 0.9992 - val_loss: 0.0085 - val_recall: 0.9031 - val_precision: 0.9072 - val_mean_io_u: 0.6597 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0078 - recall: 0.9065 - precision: 0.9129 - mean_io_u: 0.6563 - accuracy: 0.9968 - auc: 0.9992\n",
      "Epoch 49: val_loss did not improve from 0.00837\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0078 - recall: 0.9065 - precision: 0.9129 - mean_io_u: 0.6563 - accuracy: 0.9968 - auc: 0.9992 - val_loss: 0.0084 - val_recall: 0.9023 - val_precision: 0.9079 - val_mean_io_u: 0.6582 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0077 - recall: 0.9074 - precision: 0.9131 - mean_io_u: 0.6575 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 50: val_loss did not improve from 0.00837\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0077 - recall: 0.9074 - precision: 0.9131 - mean_io_u: 0.6575 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9020 - val_precision: 0.9091 - val_mean_io_u: 0.6612 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0077 - recall: 0.9074 - precision: 0.9135 - mean_io_u: 0.6599 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 51: val_loss did not improve from 0.00837\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0077 - recall: 0.9074 - precision: 0.9135 - mean_io_u: 0.6599 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9013 - val_precision: 0.9093 - val_mean_io_u: 0.6642 - val_accuracy: 0.9966 - val_auc: 0.9984 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0077 - recall: 0.9071 - precision: 0.9143 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9992\n",
      "Epoch 52: val_loss did not improve from 0.00837\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0077 - recall: 0.9072 - precision: 0.9143 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9992 - val_loss: 0.0084 - val_recall: 0.9026 - val_precision: 0.9092 - val_mean_io_u: 0.6640 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0077 - recall: 0.9074 - precision: 0.9139 - mean_io_u: 0.6605 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 53: val_loss improved from 0.00837 to 0.00836, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0077 - recall: 0.9074 - precision: 0.9139 - mean_io_u: 0.6605 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9033 - val_precision: 0.9091 - val_mean_io_u: 0.6645 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0077 - recall: 0.9084 - precision: 0.9137 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 54: val_loss improved from 0.00836 to 0.00836, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0077 - recall: 0.9084 - precision: 0.9137 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9031 - val_precision: 0.9093 - val_mean_io_u: 0.6644 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0077 - recall: 0.9081 - precision: 0.9140 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 55: val_loss improved from 0.00836 to 0.00835, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.0077 - recall: 0.9081 - precision: 0.9140 - mean_io_u: 0.6606 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9034 - val_precision: 0.9092 - val_mean_io_u: 0.6647 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0077 - recall: 0.9080 - precision: 0.9140 - mean_io_u: 0.6609 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 56: val_loss improved from 0.00835 to 0.00835, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0077 - recall: 0.9080 - precision: 0.9140 - mean_io_u: 0.6609 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9033 - val_precision: 0.9092 - val_mean_io_u: 0.6648 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0077 - recall: 0.9078 - precision: 0.9142 - mean_io_u: 0.6611 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 57: val_loss improved from 0.00835 to 0.00834, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0077 - recall: 0.9078 - precision: 0.9141 - mean_io_u: 0.6611 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9034 - val_precision: 0.9093 - val_mean_io_u: 0.6653 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0077 - recall: 0.9082 - precision: 0.9141 - mean_io_u: 0.6614 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 58: val_loss did not improve from 0.00834\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0077 - recall: 0.9082 - precision: 0.9141 - mean_io_u: 0.6614 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9032 - val_precision: 0.9093 - val_mean_io_u: 0.6657 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0077 - recall: 0.9081 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 59: val_loss did not improve from 0.00834\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0077 - recall: 0.9081 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0084 - val_recall: 0.9031 - val_precision: 0.9093 - val_mean_io_u: 0.6648 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9083 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 60: val_loss improved from 0.00834 to 0.00834, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.0076 - recall: 0.9083 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9036 - val_precision: 0.9093 - val_mean_io_u: 0.6654 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9085 - precision: 0.9141 - mean_io_u: 0.6616 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 61: val_loss did not improve from 0.00834\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0076 - recall: 0.9085 - precision: 0.9141 - mean_io_u: 0.6616 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9033 - val_precision: 0.9094 - val_mean_io_u: 0.6654 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9080 - precision: 0.9141 - mean_io_u: 0.6616 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 62: val_loss improved from 0.00834 to 0.00831, saving model to ./iter_BCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_BCE.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0077 - recall: 0.9080 - precision: 0.9141 - mean_io_u: 0.6616 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9038 - val_precision: 0.9095 - val_mean_io_u: 0.6661 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0076 - recall: 0.9081 - precision: 0.9142 - mean_io_u: 0.6619 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 63: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0076 - recall: 0.9081 - precision: 0.9142 - mean_io_u: 0.6619 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9032 - val_precision: 0.9097 - val_mean_io_u: 0.6656 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9081 - precision: 0.9144 - mean_io_u: 0.6617 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 64: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0076 - recall: 0.9081 - precision: 0.9144 - mean_io_u: 0.6617 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9035 - val_precision: 0.9095 - val_mean_io_u: 0.6653 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9079 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 65: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0076 - recall: 0.9078 - precision: 0.9143 - mean_io_u: 0.6615 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9035 - val_precision: 0.9092 - val_mean_io_u: 0.6653 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9084 - precision: 0.9140 - mean_io_u: 0.6620 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 66: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0076 - recall: 0.9084 - precision: 0.9140 - mean_io_u: 0.6620 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9034 - val_precision: 0.9092 - val_mean_io_u: 0.6657 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9082 - precision: 0.9146 - mean_io_u: 0.6624 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 67: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0076 - recall: 0.9082 - precision: 0.9147 - mean_io_u: 0.6624 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9037 - val_precision: 0.9093 - val_mean_io_u: 0.6663 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9086 - precision: 0.9144 - mean_io_u: 0.6625 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 68: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0076 - recall: 0.9086 - precision: 0.9144 - mean_io_u: 0.6625 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9037 - val_precision: 0.9094 - val_mean_io_u: 0.6664 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9089 - precision: 0.9142 - mean_io_u: 0.6622 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 69: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0076 - recall: 0.9089 - precision: 0.9142 - mean_io_u: 0.6622 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9033 - val_precision: 0.9094 - val_mean_io_u: 0.6658 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0076 - recall: 0.9082 - precision: 0.9145 - mean_io_u: 0.6620 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 70: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0076 - recall: 0.9082 - precision: 0.9145 - mean_io_u: 0.6620 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9034 - val_precision: 0.9097 - val_mean_io_u: 0.6661 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0076 - recall: 0.9081 - precision: 0.9144 - mean_io_u: 0.6622 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 71: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0076 - recall: 0.9081 - precision: 0.9144 - mean_io_u: 0.6622 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9034 - val_precision: 0.9094 - val_mean_io_u: 0.6662 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0076 - recall: 0.9087 - precision: 0.9144 - mean_io_u: 0.6623 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 72: val_loss did not improve from 0.00831\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0076 - recall: 0.9087 - precision: 0.9144 - mean_io_u: 0.6623 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0083 - val_recall: 0.9033 - val_precision: 0.9098 - val_mean_io_u: 0.6663 - val_accuracy: 0.9966 - val_auc: 0.9985 - lr: 1.0000e-05\n",
      "Epoch 72: early stopping\n",
      "\n",
      "\n",
      " f    <keras.losses.BinaryCrossentropy object at 0x7f05ac041ee0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.8475 - recall_1: 0.5718 - precision_1: 0.0796 - mean_io_u_1: 0.4910 - accuracy: 0.8732 - auc: 0.7186\n",
      "Epoch 1: val_loss improved from inf to 0.53464, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 24s 322ms/step - loss: 0.8465 - recall_1: 0.5720 - precision_1: 0.0799 - mean_io_u_1: 0.4910 - accuracy: 0.8735 - auc: 0.7192 - val_loss: 0.5346 - val_recall_1: 0.0702 - val_precision_1: 0.4682 - val_mean_io_u_1: 0.4910 - val_accuracy: 0.9818 - val_auc: 0.7433 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4855 - recall_1: 0.7343 - precision_1: 0.5352 - mean_io_u_1: 0.4910 - accuracy: 0.9837 - auc: 0.9497\n",
      "Epoch 2: val_loss improved from 0.53464 to 0.38246, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.4852 - recall_1: 0.7345 - precision_1: 0.5354 - mean_io_u_1: 0.4910 - accuracy: 0.9837 - auc: 0.9496 - val_loss: 0.3825 - val_recall_1: 0.0282 - val_precision_1: 0.8405 - val_mean_io_u_1: 0.4910 - val_accuracy: 0.9824 - val_auc: 0.6968 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3221 - recall_1: 0.7923 - precision_1: 0.7027 - mean_io_u_1: 0.4912 - accuracy: 0.9902 - auc: 0.9577\n",
      "Epoch 3: val_loss improved from 0.38246 to 0.25162, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.3219 - recall_1: 0.7924 - precision_1: 0.7027 - mean_io_u_1: 0.4912 - accuracy: 0.9902 - auc: 0.9577 - val_loss: 0.2516 - val_recall_1: 0.0030 - val_precision_1: 0.8977 - val_mean_io_u_1: 0.4910 - val_accuracy: 0.9820 - val_auc: 0.8531 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2015 - recall_1: 0.7625 - precision_1: 0.7927 - mean_io_u_1: 0.4966 - accuracy: 0.9921 - auc: 0.9722\n",
      "Epoch 4: val_loss improved from 0.25162 to 0.16416, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.2013 - recall_1: 0.7624 - precision_1: 0.7929 - mean_io_u_1: 0.4967 - accuracy: 0.9921 - auc: 0.9722 - val_loss: 0.1642 - val_recall_1: 0.0695 - val_precision_1: 0.9704 - val_mean_io_u_1: 0.4910 - val_accuracy: 0.9832 - val_auc: 0.8917 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1311 - recall_1: 0.7533 - precision_1: 0.8245 - mean_io_u_1: 0.5123 - accuracy: 0.9927 - auc: 0.9835\n",
      "Epoch 5: val_loss improved from 0.16416 to 0.11437, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.1310 - recall_1: 0.7533 - precision_1: 0.8244 - mean_io_u_1: 0.5123 - accuracy: 0.9927 - auc: 0.9834 - val_loss: 0.1144 - val_recall_1: 0.2072 - val_precision_1: 0.9419 - val_mean_io_u_1: 0.4910 - val_accuracy: 0.9855 - val_auc: 0.9553 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0923 - recall_1: 0.7579 - precision_1: 0.8381 - mean_io_u_1: 0.5244 - accuracy: 0.9930 - auc: 0.9897\n",
      "Epoch 6: val_loss improved from 0.11437 to 0.08413, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0923 - recall_1: 0.7580 - precision_1: 0.8381 - mean_io_u_1: 0.5244 - accuracy: 0.9930 - auc: 0.9897 - val_loss: 0.0841 - val_recall_1: 0.2862 - val_precision_1: 0.9464 - val_mean_io_u_1: 0.4917 - val_accuracy: 0.9868 - val_auc: 0.9549 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0698 - recall_1: 0.7661 - precision_1: 0.8489 - mean_io_u_1: 0.5299 - accuracy: 0.9933 - auc: 0.9939\n",
      "Epoch 7: val_loss improved from 0.08413 to 0.06117, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0698 - recall_1: 0.7662 - precision_1: 0.8488 - mean_io_u_1: 0.5299 - accuracy: 0.9933 - auc: 0.9939 - val_loss: 0.0612 - val_recall_1: 0.4407 - val_precision_1: 0.9441 - val_mean_io_u_1: 0.4966 - val_accuracy: 0.9894 - val_auc: 0.9933 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0565 - recall_1: 0.7716 - precision_1: 0.8555 - mean_io_u_1: 0.5329 - accuracy: 0.9935 - auc: 0.9960\n",
      "Epoch 8: val_loss improved from 0.06117 to 0.05055, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.0565 - recall_1: 0.7716 - precision_1: 0.8555 - mean_io_u_1: 0.5329 - accuracy: 0.9935 - auc: 0.9960 - val_loss: 0.0505 - val_recall_1: 0.5934 - val_precision_1: 0.9072 - val_mean_io_u_1: 0.5117 - val_accuracy: 0.9916 - val_auc: 0.9948 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0477 - recall_1: 0.7830 - precision_1: 0.8600 - mean_io_u_1: 0.5358 - accuracy: 0.9938 - auc: 0.9968\n",
      "Epoch 9: val_loss improved from 0.05055 to 0.04231, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.0477 - recall_1: 0.7830 - precision_1: 0.8600 - mean_io_u_1: 0.5358 - accuracy: 0.9938 - auc: 0.9968 - val_loss: 0.0423 - val_recall_1: 0.6511 - val_precision_1: 0.9098 - val_mean_io_u_1: 0.5243 - val_accuracy: 0.9925 - val_auc: 0.9971 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0414 - recall_1: 0.7962 - precision_1: 0.8653 - mean_io_u_1: 0.5370 - accuracy: 0.9941 - auc: 0.9974\n",
      "Epoch 10: val_loss improved from 0.04231 to 0.04120, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.0414 - recall_1: 0.7962 - precision_1: 0.8653 - mean_io_u_1: 0.5370 - accuracy: 0.9941 - auc: 0.9974 - val_loss: 0.0412 - val_recall_1: 0.6666 - val_precision_1: 0.8699 - val_mean_io_u_1: 0.5305 - val_accuracy: 0.9922 - val_auc: 0.9952 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0372 - recall_1: 0.8062 - precision_1: 0.8683 - mean_io_u_1: 0.5381 - accuracy: 0.9943 - auc: 0.9974\n",
      "Epoch 11: val_loss improved from 0.04120 to 0.03313, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.0372 - recall_1: 0.8059 - precision_1: 0.8684 - mean_io_u_1: 0.5381 - accuracy: 0.9943 - auc: 0.9974 - val_loss: 0.0331 - val_recall_1: 0.7497 - val_precision_1: 0.9005 - val_mean_io_u_1: 0.5365 - val_accuracy: 0.9940 - val_auc: 0.9975 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0340 - recall_1: 0.8150 - precision_1: 0.8711 - mean_io_u_1: 0.5385 - accuracy: 0.9945 - auc: 0.9977\n",
      "Epoch 12: val_loss did not improve from 0.03313\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.0340 - recall_1: 0.8150 - precision_1: 0.8711 - mean_io_u_1: 0.5385 - accuracy: 0.9945 - auc: 0.9977 - val_loss: 0.0368 - val_recall_1: 0.7677 - val_precision_1: 0.8456 - val_mean_io_u_1: 0.5358 - val_accuracy: 0.9933 - val_auc: 0.9961 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0310 - recall_1: 0.8259 - precision_1: 0.8763 - mean_io_u_1: 0.5417 - accuracy: 0.9948 - auc: 0.9982\n",
      "Epoch 13: val_loss did not improve from 0.03313\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0310 - recall_1: 0.8258 - precision_1: 0.8763 - mean_io_u_1: 0.5417 - accuracy: 0.9948 - auc: 0.9982 - val_loss: 0.0402 - val_recall_1: 0.7338 - val_precision_1: 0.8110 - val_mean_io_u_1: 0.5313 - val_accuracy: 0.9921 - val_auc: 0.9953 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0289 - recall_1: 0.8324 - precision_1: 0.8798 - mean_io_u_1: 0.5449 - accuracy: 0.9949 - auc: 0.9984\n",
      "Epoch 14: val_loss improved from 0.03313 to 0.03099, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0289 - recall_1: 0.8324 - precision_1: 0.8798 - mean_io_u_1: 0.5449 - accuracy: 0.9949 - auc: 0.9984 - val_loss: 0.0310 - val_recall_1: 0.7932 - val_precision_1: 0.8640 - val_mean_io_u_1: 0.5387 - val_accuracy: 0.9940 - val_auc: 0.9971 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0270 - recall_1: 0.8426 - precision_1: 0.8835 - mean_io_u_1: 0.5467 - accuracy: 0.9952 - auc: 0.9984\n",
      "Epoch 15: val_loss improved from 0.03099 to 0.02793, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 19s 302ms/step - loss: 0.0270 - recall_1: 0.8426 - precision_1: 0.8835 - mean_io_u_1: 0.5467 - accuracy: 0.9952 - auc: 0.9984 - val_loss: 0.0279 - val_recall_1: 0.8148 - val_precision_1: 0.8841 - val_mean_io_u_1: 0.5586 - val_accuracy: 0.9947 - val_auc: 0.9972 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0255 - recall_1: 0.8469 - precision_1: 0.8870 - mean_io_u_1: 0.5503 - accuracy: 0.9953 - auc: 0.9985\n",
      "Epoch 16: val_loss improved from 0.02793 to 0.02469, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.0255 - recall_1: 0.8470 - precision_1: 0.8870 - mean_io_u_1: 0.5503 - accuracy: 0.9953 - auc: 0.9985 - val_loss: 0.0247 - val_recall_1: 0.8493 - val_precision_1: 0.8904 - val_mean_io_u_1: 0.5659 - val_accuracy: 0.9954 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0242 - recall_1: 0.8530 - precision_1: 0.8903 - mean_io_u_1: 0.5523 - accuracy: 0.9955 - auc: 0.9987\n",
      "Epoch 17: val_loss did not improve from 0.02469\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0242 - recall_1: 0.8530 - precision_1: 0.8903 - mean_io_u_1: 0.5523 - accuracy: 0.9955 - auc: 0.9987 - val_loss: 0.0258 - val_recall_1: 0.8522 - val_precision_1: 0.8782 - val_mean_io_u_1: 0.5652 - val_accuracy: 0.9952 - val_auc: 0.9983 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0230 - recall_1: 0.8586 - precision_1: 0.8934 - mean_io_u_1: 0.5562 - accuracy: 0.9956 - auc: 0.9990\n",
      "Epoch 18: val_loss did not improve from 0.02469\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0230 - recall_1: 0.8585 - precision_1: 0.8934 - mean_io_u_1: 0.5562 - accuracy: 0.9956 - auc: 0.9990 - val_loss: 0.0255 - val_recall_1: 0.8238 - val_precision_1: 0.8873 - val_mean_io_u_1: 0.5534 - val_accuracy: 0.9949 - val_auc: 0.9979 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0223 - recall_1: 0.8603 - precision_1: 0.8944 - mean_io_u_1: 0.5574 - accuracy: 0.9957 - auc: 0.9989\n",
      "Epoch 19: val_loss improved from 0.02469 to 0.02435, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0223 - recall_1: 0.8604 - precision_1: 0.8944 - mean_io_u_1: 0.5574 - accuracy: 0.9957 - auc: 0.9989 - val_loss: 0.0243 - val_recall_1: 0.8526 - val_precision_1: 0.8792 - val_mean_io_u_1: 0.5665 - val_accuracy: 0.9952 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0218 - recall_1: 0.8608 - precision_1: 0.8949 - mean_io_u_1: 0.5562 - accuracy: 0.9957 - auc: 0.9990\n",
      "Epoch 20: val_loss improved from 0.02435 to 0.02244, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0218 - recall_1: 0.8609 - precision_1: 0.8948 - mean_io_u_1: 0.5562 - accuracy: 0.9957 - auc: 0.9990 - val_loss: 0.0224 - val_recall_1: 0.8666 - val_precision_1: 0.8872 - val_mean_io_u_1: 0.5666 - val_accuracy: 0.9956 - val_auc: 0.9988 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0212 - recall_1: 0.8633 - precision_1: 0.8963 - mean_io_u_1: 0.5592 - accuracy: 0.9957 - auc: 0.9990\n",
      "Epoch 21: val_loss improved from 0.02244 to 0.02216, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.0212 - recall_1: 0.8633 - precision_1: 0.8963 - mean_io_u_1: 0.5592 - accuracy: 0.9957 - auc: 0.9990 - val_loss: 0.0222 - val_recall_1: 0.8541 - val_precision_1: 0.8938 - val_mean_io_u_1: 0.5815 - val_accuracy: 0.9955 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0204 - recall_1: 0.8693 - precision_1: 0.8989 - mean_io_u_1: 0.5600 - accuracy: 0.9959 - auc: 0.9990\n",
      "Epoch 22: val_loss improved from 0.02216 to 0.02050, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.0204 - recall_1: 0.8692 - precision_1: 0.8990 - mean_io_u_1: 0.5599 - accuracy: 0.9959 - auc: 0.9990 - val_loss: 0.0205 - val_recall_1: 0.8584 - val_precision_1: 0.9006 - val_mean_io_u_1: 0.5673 - val_accuracy: 0.9957 - val_auc: 0.9987 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0197 - recall_1: 0.8738 - precision_1: 0.9006 - mean_io_u_1: 0.5633 - accuracy: 0.9960 - auc: 0.9991\n",
      "Epoch 23: val_loss did not improve from 0.02050\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.0197 - recall_1: 0.8738 - precision_1: 0.9006 - mean_io_u_1: 0.5633 - accuracy: 0.9960 - auc: 0.9991 - val_loss: 0.0222 - val_recall_1: 0.8526 - val_precision_1: 0.8952 - val_mean_io_u_1: 0.5668 - val_accuracy: 0.9955 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0190 - recall_1: 0.8769 - precision_1: 0.9039 - mean_io_u_1: 0.5683 - accuracy: 0.9961 - auc: 0.9991\n",
      "Epoch 24: val_loss did not improve from 0.02050\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0190 - recall_1: 0.8770 - precision_1: 0.9039 - mean_io_u_1: 0.5683 - accuracy: 0.9961 - auc: 0.9991 - val_loss: 0.0208 - val_recall_1: 0.8485 - val_precision_1: 0.8999 - val_mean_io_u_1: 0.5685 - val_accuracy: 0.9956 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0187 - recall_1: 0.8786 - precision_1: 0.9045 - mean_io_u_1: 0.5685 - accuracy: 0.9961 - auc: 0.9991\n",
      "Epoch 25: val_loss improved from 0.02050 to 0.01996, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.0187 - recall_1: 0.8786 - precision_1: 0.9045 - mean_io_u_1: 0.5685 - accuracy: 0.9961 - auc: 0.9991 - val_loss: 0.0200 - val_recall_1: 0.8522 - val_precision_1: 0.9029 - val_mean_io_u_1: 0.5585 - val_accuracy: 0.9957 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0182 - recall_1: 0.8817 - precision_1: 0.9057 - mean_io_u_1: 0.5687 - accuracy: 0.9962 - auc: 0.9991\n",
      "Epoch 26: val_loss did not improve from 0.01996\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0182 - recall_1: 0.8817 - precision_1: 0.9057 - mean_io_u_1: 0.5687 - accuracy: 0.9962 - auc: 0.9991 - val_loss: 0.0208 - val_recall_1: 0.8519 - val_precision_1: 0.8980 - val_mean_io_u_1: 0.5734 - val_accuracy: 0.9956 - val_auc: 0.9977 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0179 - recall_1: 0.8827 - precision_1: 0.9072 - mean_io_u_1: 0.5718 - accuracy: 0.9963 - auc: 0.9991\n",
      "Epoch 27: val_loss did not improve from 0.01996\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0179 - recall_1: 0.8826 - precision_1: 0.9072 - mean_io_u_1: 0.5718 - accuracy: 0.9963 - auc: 0.9991 - val_loss: 0.0211 - val_recall_1: 0.8645 - val_precision_1: 0.8947 - val_mean_io_u_1: 0.5914 - val_accuracy: 0.9957 - val_auc: 0.9979 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0176 - recall_1: 0.8837 - precision_1: 0.9082 - mean_io_u_1: 0.5732 - accuracy: 0.9963 - auc: 0.9992\n",
      "Epoch 28: val_loss did not improve from 0.01996\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0176 - recall_1: 0.8837 - precision_1: 0.9082 - mean_io_u_1: 0.5732 - accuracy: 0.9963 - auc: 0.9992 - val_loss: 0.0214 - val_recall_1: 0.8517 - val_precision_1: 0.8908 - val_mean_io_u_1: 0.5648 - val_accuracy: 0.9954 - val_auc: 0.9977 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0173 - recall_1: 0.8861 - precision_1: 0.9089 - mean_io_u_1: 0.5754 - accuracy: 0.9963 - auc: 0.9992\n",
      "Epoch 29: val_loss did not improve from 0.01996\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0173 - recall_1: 0.8862 - precision_1: 0.9089 - mean_io_u_1: 0.5754 - accuracy: 0.9963 - auc: 0.9992 - val_loss: 0.0231 - val_recall_1: 0.8228 - val_precision_1: 0.8895 - val_mean_io_u_1: 0.5640 - val_accuracy: 0.9950 - val_auc: 0.9946 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0168 - recall_1: 0.8888 - precision_1: 0.9109 - mean_io_u_1: 0.5769 - accuracy: 0.9964 - auc: 0.9992\n",
      "Epoch 30: val_loss did not improve from 0.01996\n",
      "\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0168 - recall_1: 0.8888 - precision_1: 0.9108 - mean_io_u_1: 0.5769 - accuracy: 0.9964 - auc: 0.9992 - val_loss: 0.0216 - val_recall_1: 0.8398 - val_precision_1: 0.9009 - val_mean_io_u_1: 0.5734 - val_accuracy: 0.9954 - val_auc: 0.9954 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0161 - recall_1: 0.8946 - precision_1: 0.9140 - mean_io_u_1: 0.5823 - accuracy: 0.9966 - auc: 0.9993\n",
      "Epoch 31: val_loss improved from 0.01996 to 0.01784, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.0161 - recall_1: 0.8946 - precision_1: 0.9141 - mean_io_u_1: 0.5823 - accuracy: 0.9966 - auc: 0.9993 - val_loss: 0.0178 - val_recall_1: 0.8745 - val_precision_1: 0.9093 - val_mean_io_u_1: 0.5923 - val_accuracy: 0.9962 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0158 - recall_1: 0.8976 - precision_1: 0.9157 - mean_io_u_1: 0.5883 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 32: val_loss improved from 0.01784 to 0.01719, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.0158 - recall_1: 0.8976 - precision_1: 0.9157 - mean_io_u_1: 0.5883 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0172 - val_recall_1: 0.8866 - val_precision_1: 0.9107 - val_mean_io_u_1: 0.6025 - val_accuracy: 0.9964 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0157 - recall_1: 0.8976 - precision_1: 0.9168 - mean_io_u_1: 0.5908 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 33: val_loss improved from 0.01719 to 0.01686, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.0157 - recall_1: 0.8976 - precision_1: 0.9168 - mean_io_u_1: 0.5909 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0169 - val_recall_1: 0.8860 - val_precision_1: 0.9133 - val_mean_io_u_1: 0.5993 - val_accuracy: 0.9964 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0156 - recall_1: 0.8981 - precision_1: 0.9170 - mean_io_u_1: 0.5905 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 34: val_loss improved from 0.01686 to 0.01686, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.0156 - recall_1: 0.8980 - precision_1: 0.9169 - mean_io_u_1: 0.5904 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0169 - val_recall_1: 0.8881 - val_precision_1: 0.9126 - val_mean_io_u_1: 0.6000 - val_accuracy: 0.9964 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0156 - recall_1: 0.8992 - precision_1: 0.9169 - mean_io_u_1: 0.5909 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 35: val_loss did not improve from 0.01686\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0156 - recall_1: 0.8992 - precision_1: 0.9169 - mean_io_u_1: 0.5909 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0169 - val_recall_1: 0.8862 - val_precision_1: 0.9130 - val_mean_io_u_1: 0.5986 - val_accuracy: 0.9964 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0155 - recall_1: 0.8988 - precision_1: 0.9178 - mean_io_u_1: 0.5909 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 36: val_loss did not improve from 0.01686\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0155 - recall_1: 0.8988 - precision_1: 0.9178 - mean_io_u_1: 0.5909 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0170 - val_recall_1: 0.8820 - val_precision_1: 0.9140 - val_mean_io_u_1: 0.5998 - val_accuracy: 0.9964 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0155 - recall_1: 0.8992 - precision_1: 0.9178 - mean_io_u_1: 0.5932 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 37: val_loss did not improve from 0.01686\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0155 - recall_1: 0.8992 - precision_1: 0.9178 - mean_io_u_1: 0.5932 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0179 - val_recall_1: 0.8779 - val_precision_1: 0.9082 - val_mean_io_u_1: 0.5938 - val_accuracy: 0.9962 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0154 - recall_1: 0.8997 - precision_1: 0.9181 - mean_io_u_1: 0.5942 - accuracy: 0.9967 - auc: 0.9993\n",
      "Epoch 38: val_loss improved from 0.01686 to 0.01636, saving model to ./iter_wBCE-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-3.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.0154 - recall_1: 0.8997 - precision_1: 0.9182 - mean_io_u_1: 0.5942 - accuracy: 0.9967 - auc: 0.9993 - val_loss: 0.0164 - val_recall_1: 0.8889 - val_precision_1: 0.9164 - val_mean_io_u_1: 0.6041 - val_accuracy: 0.9965 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0153 - recall_1: 0.8998 - precision_1: 0.9183 - mean_io_u_1: 0.5934 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 39: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.0153 - recall_1: 0.8998 - precision_1: 0.9183 - mean_io_u_1: 0.5934 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0168 - val_recall_1: 0.8894 - val_precision_1: 0.9122 - val_mean_io_u_1: 0.6059 - val_accuracy: 0.9965 - val_auc: 0.9988 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0153 - recall_1: 0.9004 - precision_1: 0.9184 - mean_io_u_1: 0.5959 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 40: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0153 - recall_1: 0.9004 - precision_1: 0.9184 - mean_io_u_1: 0.5959 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0172 - val_recall_1: 0.8806 - val_precision_1: 0.9125 - val_mean_io_u_1: 0.6058 - val_accuracy: 0.9963 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0152 - recall_1: 0.9000 - precision_1: 0.9190 - mean_io_u_1: 0.5956 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 41: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0152 - recall_1: 0.8999 - precision_1: 0.9189 - mean_io_u_1: 0.5956 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0174 - val_recall_1: 0.8805 - val_precision_1: 0.9117 - val_mean_io_u_1: 0.6058 - val_accuracy: 0.9963 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0152 - recall_1: 0.9005 - precision_1: 0.9191 - mean_io_u_1: 0.5969 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 42: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0152 - recall_1: 0.9005 - precision_1: 0.9191 - mean_io_u_1: 0.5969 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0170 - val_recall_1: 0.8829 - val_precision_1: 0.9130 - val_mean_io_u_1: 0.6015 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0151 - recall_1: 0.9011 - precision_1: 0.9194 - mean_io_u_1: 0.5973 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 43: val_loss did not improve from 0.01636\n",
      "\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0151 - recall_1: 0.9011 - precision_1: 0.9194 - mean_io_u_1: 0.5974 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0171 - val_recall_1: 0.8873 - val_precision_1: 0.9112 - val_mean_io_u_1: 0.6087 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0150 - recall_1: 0.9017 - precision_1: 0.9198 - mean_io_u_1: 0.5980 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 44: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0150 - recall_1: 0.9018 - precision_1: 0.9198 - mean_io_u_1: 0.5980 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0170 - val_recall_1: 0.8871 - val_precision_1: 0.9118 - val_mean_io_u_1: 0.6064 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0150 - recall_1: 0.9021 - precision_1: 0.9199 - mean_io_u_1: 0.5980 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 45: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0150 - recall_1: 0.9021 - precision_1: 0.9199 - mean_io_u_1: 0.5980 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0171 - val_recall_1: 0.8865 - val_precision_1: 0.9117 - val_mean_io_u_1: 0.6071 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9197 - mean_io_u_1: 0.5981 - accuracy: 0.9968 - auc: 0.9994\n",
      "Epoch 46: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9197 - mean_io_u_1: 0.5981 - accuracy: 0.9968 - auc: 0.9994 - val_loss: 0.0170 - val_recall_1: 0.8876 - val_precision_1: 0.9115 - val_mean_io_u_1: 0.6078 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9197 - mean_io_u_1: 0.5983 - accuracy: 0.9968 - auc: 0.9993\n",
      "Epoch 47: val_loss did not improve from 0.01636\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9197 - mean_io_u_1: 0.5983 - accuracy: 0.9968 - auc: 0.9993 - val_loss: 0.0171 - val_recall_1: 0.8860 - val_precision_1: 0.9113 - val_mean_io_u_1: 0.6069 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9200 - mean_io_u_1: 0.5982 - accuracy: 0.9968 - auc: 0.9994\n",
      "Epoch 48: val_loss did not improve from 0.01636\n",
      "\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0150 - recall_1: 0.9022 - precision_1: 0.9200 - mean_io_u_1: 0.5982 - accuracy: 0.9968 - auc: 0.9994 - val_loss: 0.0173 - val_recall_1: 0.8854 - val_precision_1: 0.9104 - val_mean_io_u_1: 0.6069 - val_accuracy: 0.9964 - val_auc: 0.9987 - lr: 1.0000e-05\n",
      "Epoch 48: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f0484517820>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 1.3783 - recall_2: 0.6310 - precision_2: 0.1121 - mean_io_u_2: 0.4910 - accuracy: 0.9033 - auc: 0.7139\n",
      "Epoch 1: val_loss improved from inf to 0.62428, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 25s 336ms/step - loss: 1.3761 - recall_2: 0.6313 - precision_2: 0.1125 - mean_io_u_2: 0.4910 - accuracy: 0.9036 - auc: 0.7145 - val_loss: 0.6243 - val_recall_2: 0.1701 - val_precision_2: 0.7035 - val_mean_io_u_2: 0.4910 - val_accuracy: 0.9837 - val_auc: 0.5727 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.6768 - recall_2: 0.7864 - precision_2: 0.6096 - mean_io_u_2: 0.4910 - accuracy: 0.9871 - auc: 0.9094\n",
      "Epoch 2: val_loss improved from 0.62428 to 0.54193, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 298ms/step - loss: 0.6766 - recall_2: 0.7864 - precision_2: 0.6098 - mean_io_u_2: 0.4910 - accuracy: 0.9871 - auc: 0.9094 - val_loss: 0.5419 - val_recall_2: 0.2220 - val_precision_2: 0.8942 - val_mean_io_u_2: 0.4910 - val_accuracy: 0.9855 - val_auc: 0.7804 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.5330 - recall_2: 0.7834 - precision_2: 0.7253 - mean_io_u_2: 0.4911 - accuracy: 0.9907 - auc: 0.9259\n",
      "Epoch 3: val_loss improved from 0.54193 to 0.41704, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.5328 - recall_2: 0.7834 - precision_2: 0.7252 - mean_io_u_2: 0.4911 - accuracy: 0.9907 - auc: 0.9259 - val_loss: 0.4170 - val_recall_2: 0.2892 - val_precision_2: 0.8978 - val_mean_io_u_2: 0.4910 - val_accuracy: 0.9866 - val_auc: 0.8770 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3954 - recall_2: 0.7611 - precision_2: 0.7886 - mean_io_u_2: 0.4926 - accuracy: 0.9920 - auc: 0.9558\n",
      "Epoch 4: val_loss improved from 0.41704 to 0.29728, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.3952 - recall_2: 0.7611 - precision_2: 0.7888 - mean_io_u_2: 0.4926 - accuracy: 0.9920 - auc: 0.9559 - val_loss: 0.2973 - val_recall_2: 0.3897 - val_precision_2: 0.8905 - val_mean_io_u_2: 0.4910 - val_accuracy: 0.9881 - val_auc: 0.9498 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2785 - recall_2: 0.7442 - precision_2: 0.8247 - mean_io_u_2: 0.4980 - accuracy: 0.9925 - auc: 0.9724\n",
      "Epoch 5: val_loss improved from 0.29728 to 0.23307, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.2783 - recall_2: 0.7442 - precision_2: 0.8247 - mean_io_u_2: 0.4980 - accuracy: 0.9925 - auc: 0.9723 - val_loss: 0.2331 - val_recall_2: 0.7026 - val_precision_2: 0.8162 - val_mean_io_u_2: 0.4912 - val_accuracy: 0.9918 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1974 - recall_2: 0.7393 - precision_2: 0.8452 - mean_io_u_2: 0.5049 - accuracy: 0.9929 - auc: 0.9824\n",
      "Epoch 6: val_loss improved from 0.23307 to 0.17221, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.1974 - recall_2: 0.7393 - precision_2: 0.8452 - mean_io_u_2: 0.5049 - accuracy: 0.9929 - auc: 0.9824 - val_loss: 0.1722 - val_recall_2: 0.7083 - val_precision_2: 0.8345 - val_mean_io_u_2: 0.4947 - val_accuracy: 0.9922 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1485 - recall_2: 0.7447 - precision_2: 0.8535 - mean_io_u_2: 0.5101 - accuracy: 0.9931 - auc: 0.9886\n",
      "Epoch 7: val_loss improved from 0.17221 to 0.13775, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.1484 - recall_2: 0.7446 - precision_2: 0.8535 - mean_io_u_2: 0.5101 - accuracy: 0.9931 - auc: 0.9886 - val_loss: 0.1378 - val_recall_2: 0.7836 - val_precision_2: 0.8327 - val_mean_io_u_2: 0.5089 - val_accuracy: 0.9933 - val_auc: 0.9900 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1190 - recall_2: 0.7563 - precision_2: 0.8585 - mean_io_u_2: 0.5159 - accuracy: 0.9934 - auc: 0.9917\n",
      "Epoch 8: val_loss improved from 0.13775 to 0.10331, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.1189 - recall_2: 0.7563 - precision_2: 0.8587 - mean_io_u_2: 0.5159 - accuracy: 0.9934 - auc: 0.9918 - val_loss: 0.1033 - val_recall_2: 0.7704 - val_precision_2: 0.8558 - val_mean_io_u_2: 0.5111 - val_accuracy: 0.9935 - val_auc: 0.9940 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1016 - recall_2: 0.7647 - precision_2: 0.8605 - mean_io_u_2: 0.5199 - accuracy: 0.9935 - auc: 0.9936\n",
      "Epoch 9: val_loss improved from 0.10331 to 0.09776, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.1016 - recall_2: 0.7648 - precision_2: 0.8606 - mean_io_u_2: 0.5199 - accuracy: 0.9935 - auc: 0.9936 - val_loss: 0.0978 - val_recall_2: 0.7925 - val_precision_2: 0.8432 - val_mean_io_u_2: 0.5176 - val_accuracy: 0.9936 - val_auc: 0.9945 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0887 - recall_2: 0.7733 - precision_2: 0.8656 - mean_io_u_2: 0.5233 - accuracy: 0.9938 - auc: 0.9950\n",
      "Epoch 10: val_loss improved from 0.09776 to 0.08519, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.0887 - recall_2: 0.7733 - precision_2: 0.8656 - mean_io_u_2: 0.5233 - accuracy: 0.9938 - auc: 0.9950 - val_loss: 0.0852 - val_recall_2: 0.7831 - val_precision_2: 0.8640 - val_mean_io_u_2: 0.5340 - val_accuracy: 0.9939 - val_auc: 0.9942 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0801 - recall_2: 0.7814 - precision_2: 0.8700 - mean_io_u_2: 0.5271 - accuracy: 0.9940 - auc: 0.9960\n",
      "Epoch 11: val_loss improved from 0.08519 to 0.07166, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 21s 317ms/step - loss: 0.0800 - recall_2: 0.7812 - precision_2: 0.8701 - mean_io_u_2: 0.5271 - accuracy: 0.9940 - auc: 0.9960 - val_loss: 0.0717 - val_recall_2: 0.7557 - val_precision_2: 0.8874 - val_mean_io_u_2: 0.5190 - val_accuracy: 0.9939 - val_auc: 0.9952 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0747 - recall_2: 0.7844 - precision_2: 0.8723 - mean_io_u_2: 0.5275 - accuracy: 0.9940 - auc: 0.9965\n",
      "Epoch 12: val_loss did not improve from 0.07166\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0747 - recall_2: 0.7843 - precision_2: 0.8723 - mean_io_u_2: 0.5276 - accuracy: 0.9940 - auc: 0.9965 - val_loss: 0.0831 - val_recall_2: 0.8131 - val_precision_2: 0.8513 - val_mean_io_u_2: 0.5528 - val_accuracy: 0.9941 - val_auc: 0.9951 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0696 - recall_2: 0.8038 - precision_2: 0.8770 - mean_io_u_2: 0.5300 - accuracy: 0.9944 - auc: 0.9971\n",
      "Epoch 13: val_loss did not improve from 0.07166\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.0695 - recall_2: 0.8037 - precision_2: 0.8770 - mean_io_u_2: 0.5300 - accuracy: 0.9944 - auc: 0.9971 - val_loss: 0.0795 - val_recall_2: 0.7680 - val_precision_2: 0.8445 - val_mean_io_u_2: 0.5206 - val_accuracy: 0.9933 - val_auc: 0.9935 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0662 - recall_2: 0.8101 - precision_2: 0.8791 - mean_io_u_2: 0.5303 - accuracy: 0.9946 - auc: 0.9973\n",
      "Epoch 14: val_loss improved from 0.07166 to 0.06841, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.0662 - recall_2: 0.8101 - precision_2: 0.8791 - mean_io_u_2: 0.5303 - accuracy: 0.9946 - auc: 0.9973 - val_loss: 0.0684 - val_recall_2: 0.7979 - val_precision_2: 0.8738 - val_mean_io_u_2: 0.5358 - val_accuracy: 0.9943 - val_auc: 0.9949 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0635 - recall_2: 0.8159 - precision_2: 0.8814 - mean_io_u_2: 0.5315 - accuracy: 0.9947 - auc: 0.9975\n",
      "Epoch 15: val_loss improved from 0.06841 to 0.06783, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.0635 - recall_2: 0.8159 - precision_2: 0.8814 - mean_io_u_2: 0.5315 - accuracy: 0.9947 - auc: 0.9975 - val_loss: 0.0678 - val_recall_2: 0.8368 - val_precision_2: 0.8727 - val_mean_io_u_2: 0.5452 - val_accuracy: 0.9949 - val_auc: 0.9961 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0605 - recall_2: 0.8231 - precision_2: 0.8855 - mean_io_u_2: 0.5330 - accuracy: 0.9949 - auc: 0.9980\n",
      "Epoch 16: val_loss did not improve from 0.06783\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0605 - recall_2: 0.8231 - precision_2: 0.8854 - mean_io_u_2: 0.5330 - accuracy: 0.9949 - auc: 0.9980 - val_loss: 0.0814 - val_recall_2: 0.8492 - val_precision_2: 0.8433 - val_mean_io_u_2: 0.5493 - val_accuracy: 0.9944 - val_auc: 0.9963 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0583 - recall_2: 0.8317 - precision_2: 0.8875 - mean_io_u_2: 0.5344 - accuracy: 0.9951 - auc: 0.9981\n",
      "Epoch 17: val_loss improved from 0.06783 to 0.06140, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.0583 - recall_2: 0.8318 - precision_2: 0.8875 - mean_io_u_2: 0.5344 - accuracy: 0.9951 - auc: 0.9981 - val_loss: 0.0614 - val_recall_2: 0.8278 - val_precision_2: 0.8840 - val_mean_io_u_2: 0.5508 - val_accuracy: 0.9949 - val_auc: 0.9964 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0556 - recall_2: 0.8411 - precision_2: 0.8918 - mean_io_u_2: 0.5374 - accuracy: 0.9953 - auc: 0.9981\n",
      "Epoch 18: val_loss improved from 0.06140 to 0.05519, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.0556 - recall_2: 0.8411 - precision_2: 0.8919 - mean_io_u_2: 0.5374 - accuracy: 0.9953 - auc: 0.9981 - val_loss: 0.0552 - val_recall_2: 0.8427 - val_precision_2: 0.8949 - val_mean_io_u_2: 0.5537 - val_accuracy: 0.9954 - val_auc: 0.9977 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0536 - recall_2: 0.8451 - precision_2: 0.8948 - mean_io_u_2: 0.5396 - accuracy: 0.9954 - auc: 0.9981\n",
      "Epoch 19: val_loss did not improve from 0.05519\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0536 - recall_2: 0.8451 - precision_2: 0.8948 - mean_io_u_2: 0.5396 - accuracy: 0.9954 - auc: 0.9981 - val_loss: 0.0623 - val_recall_2: 0.8452 - val_precision_2: 0.8793 - val_mean_io_u_2: 0.5541 - val_accuracy: 0.9951 - val_auc: 0.9966 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0528 - recall_2: 0.8473 - precision_2: 0.8954 - mean_io_u_2: 0.5388 - accuracy: 0.9955 - auc: 0.9984\n",
      "Epoch 20: val_loss improved from 0.05519 to 0.05411, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.0528 - recall_2: 0.8473 - precision_2: 0.8954 - mean_io_u_2: 0.5388 - accuracy: 0.9955 - auc: 0.9984 - val_loss: 0.0541 - val_recall_2: 0.8602 - val_precision_2: 0.8937 - val_mean_io_u_2: 0.5655 - val_accuracy: 0.9956 - val_auc: 0.9977 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0517 - recall_2: 0.8512 - precision_2: 0.8964 - mean_io_u_2: 0.5418 - accuracy: 0.9955 - auc: 0.9986\n",
      "Epoch 21: val_loss improved from 0.05411 to 0.05211, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.0517 - recall_2: 0.8512 - precision_2: 0.8964 - mean_io_u_2: 0.5418 - accuracy: 0.9955 - auc: 0.9986 - val_loss: 0.0521 - val_recall_2: 0.8369 - val_precision_2: 0.9023 - val_mean_io_u_2: 0.5441 - val_accuracy: 0.9954 - val_auc: 0.9973 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0502 - recall_2: 0.8559 - precision_2: 0.8987 - mean_io_u_2: 0.5424 - accuracy: 0.9957 - auc: 0.9987\n",
      "Epoch 22: val_loss did not improve from 0.05211\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0502 - recall_2: 0.8559 - precision_2: 0.8987 - mean_io_u_2: 0.5424 - accuracy: 0.9957 - auc: 0.9987 - val_loss: 0.0532 - val_recall_2: 0.8150 - val_precision_2: 0.8975 - val_mean_io_u_2: 0.5510 - val_accuracy: 0.9950 - val_auc: 0.9971 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0492 - recall_2: 0.8604 - precision_2: 0.9003 - mean_io_u_2: 0.5426 - accuracy: 0.9958 - auc: 0.9988\n",
      "Epoch 23: val_loss did not improve from 0.05211\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0492 - recall_2: 0.8604 - precision_2: 0.9003 - mean_io_u_2: 0.5426 - accuracy: 0.9958 - auc: 0.9988 - val_loss: 0.0577 - val_recall_2: 0.8472 - val_precision_2: 0.8883 - val_mean_io_u_2: 0.5684 - val_accuracy: 0.9953 - val_auc: 0.9972 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0505 - recall_2: 0.8524 - precision_2: 0.8972 - mean_io_u_2: 0.5327 - accuracy: 0.9956 - auc: 0.9984\n",
      "Epoch 24: val_loss did not improve from 0.05211\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0505 - recall_2: 0.8524 - precision_2: 0.8972 - mean_io_u_2: 0.5327 - accuracy: 0.9956 - auc: 0.9984 - val_loss: 0.0524 - val_recall_2: 0.8470 - val_precision_2: 0.8931 - val_mean_io_u_2: 0.5427 - val_accuracy: 0.9954 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0479 - recall_2: 0.8631 - precision_2: 0.9017 - mean_io_u_2: 0.5435 - accuracy: 0.9958 - auc: 0.9988\n",
      "Epoch 25: val_loss improved from 0.05211 to 0.04996, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.0479 - recall_2: 0.8631 - precision_2: 0.9017 - mean_io_u_2: 0.5436 - accuracy: 0.9958 - auc: 0.9988 - val_loss: 0.0500 - val_recall_2: 0.8209 - val_precision_2: 0.9033 - val_mean_io_u_2: 0.5523 - val_accuracy: 0.9952 - val_auc: 0.9967 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0461 - recall_2: 0.8677 - precision_2: 0.9053 - mean_io_u_2: 0.5487 - accuracy: 0.9960 - auc: 0.9988\n",
      "Epoch 26: val_loss did not improve from 0.04996\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.0461 - recall_2: 0.8677 - precision_2: 0.9053 - mean_io_u_2: 0.5487 - accuracy: 0.9960 - auc: 0.9988 - val_loss: 0.0504 - val_recall_2: 0.8262 - val_precision_2: 0.8994 - val_mean_io_u_2: 0.5599 - val_accuracy: 0.9952 - val_auc: 0.9970 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0451 - recall_2: 0.8723 - precision_2: 0.9069 - mean_io_u_2: 0.5521 - accuracy: 0.9961 - auc: 0.9988\n",
      "Epoch 27: val_loss improved from 0.04996 to 0.04781, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 286ms/step - loss: 0.0451 - recall_2: 0.8723 - precision_2: 0.9069 - mean_io_u_2: 0.5521 - accuracy: 0.9961 - auc: 0.9988 - val_loss: 0.0478 - val_recall_2: 0.8685 - val_precision_2: 0.9036 - val_mean_io_u_2: 0.5670 - val_accuracy: 0.9960 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0442 - recall_2: 0.8741 - precision_2: 0.9084 - mean_io_u_2: 0.5540 - accuracy: 0.9961 - auc: 0.9989\n",
      "Epoch 28: val_loss did not improve from 0.04781\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0442 - recall_2: 0.8741 - precision_2: 0.9084 - mean_io_u_2: 0.5540 - accuracy: 0.9961 - auc: 0.9989 - val_loss: 0.0565 - val_recall_2: 0.8497 - val_precision_2: 0.8864 - val_mean_io_u_2: 0.5617 - val_accuracy: 0.9953 - val_auc: 0.9967 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0441 - recall_2: 0.8751 - precision_2: 0.9083 - mean_io_u_2: 0.5549 - accuracy: 0.9962 - auc: 0.9989\n",
      "Epoch 29: val_loss did not improve from 0.04781\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.0441 - recall_2: 0.8751 - precision_2: 0.9083 - mean_io_u_2: 0.5549 - accuracy: 0.9962 - auc: 0.9989 - val_loss: 0.0677 - val_recall_2: 0.8257 - val_precision_2: 0.8694 - val_mean_io_u_2: 0.5491 - val_accuracy: 0.9946 - val_auc: 0.9945 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0429 - recall_2: 0.8788 - precision_2: 0.9105 - mean_io_u_2: 0.5563 - accuracy: 0.9963 - auc: 0.9989\n",
      "Epoch 30: val_loss did not improve from 0.04781\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0429 - recall_2: 0.8789 - precision_2: 0.9105 - mean_io_u_2: 0.5563 - accuracy: 0.9963 - auc: 0.9989 - val_loss: 0.0653 - val_recall_2: 0.8007 - val_precision_2: 0.8708 - val_mean_io_u_2: 0.5500 - val_accuracy: 0.9943 - val_auc: 0.9932 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0426 - recall_2: 0.8785 - precision_2: 0.9111 - mean_io_u_2: 0.5575 - accuracy: 0.9963 - auc: 0.9989\n",
      "Epoch 31: val_loss did not improve from 0.04781\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0425 - recall_2: 0.8786 - precision_2: 0.9111 - mean_io_u_2: 0.5575 - accuracy: 0.9963 - auc: 0.9989 - val_loss: 0.0522 - val_recall_2: 0.8560 - val_precision_2: 0.8957 - val_mean_io_u_2: 0.5734 - val_accuracy: 0.9956 - val_auc: 0.9972 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0420 - recall_2: 0.8816 - precision_2: 0.9118 - mean_io_u_2: 0.5572 - accuracy: 0.9963 - auc: 0.9989\n",
      "Epoch 32: val_loss did not improve from 0.04781\n",
      "\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0421 - recall_2: 0.8816 - precision_2: 0.9118 - mean_io_u_2: 0.5572 - accuracy: 0.9963 - auc: 0.9989 - val_loss: 0.0564 - val_recall_2: 0.8437 - val_precision_2: 0.8883 - val_mean_io_u_2: 0.5642 - val_accuracy: 0.9953 - val_auc: 0.9963 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0406 - recall_2: 0.8889 - precision_2: 0.9144 - mean_io_u_2: 0.5617 - accuracy: 0.9965 - auc: 0.9990\n",
      "Epoch 33: val_loss improved from 0.04781 to 0.04184, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 290ms/step - loss: 0.0406 - recall_2: 0.8888 - precision_2: 0.9144 - mean_io_u_2: 0.5617 - accuracy: 0.9965 - auc: 0.9990 - val_loss: 0.0418 - val_recall_2: 0.8888 - val_precision_2: 0.9132 - val_mean_io_u_2: 0.5733 - val_accuracy: 0.9965 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0400 - recall_2: 0.8905 - precision_2: 0.9155 - mean_io_u_2: 0.5636 - accuracy: 0.9965 - auc: 0.9990\n",
      "Epoch 34: val_loss improved from 0.04184 to 0.04145, saving model to ./iter_wBCE-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-10.model/assets\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.0400 - recall_2: 0.8904 - precision_2: 0.9155 - mean_io_u_2: 0.5636 - accuracy: 0.9965 - auc: 0.9990 - val_loss: 0.0415 - val_recall_2: 0.8871 - val_precision_2: 0.9147 - val_mean_io_u_2: 0.5717 - val_accuracy: 0.9965 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0398 - recall_2: 0.8908 - precision_2: 0.9161 - mean_io_u_2: 0.5652 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 35: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.0398 - recall_2: 0.8908 - precision_2: 0.9161 - mean_io_u_2: 0.5652 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0417 - val_recall_2: 0.8900 - val_precision_2: 0.9134 - val_mean_io_u_2: 0.5742 - val_accuracy: 0.9965 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0394 - recall_2: 0.8911 - precision_2: 0.9173 - mean_io_u_2: 0.5663 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 36: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0394 - recall_2: 0.8911 - precision_2: 0.9173 - mean_io_u_2: 0.5663 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0419 - val_recall_2: 0.8893 - val_precision_2: 0.9132 - val_mean_io_u_2: 0.5759 - val_accuracy: 0.9965 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0394 - recall_2: 0.8914 - precision_2: 0.9171 - mean_io_u_2: 0.5673 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 37: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0394 - recall_2: 0.8914 - precision_2: 0.9171 - mean_io_u_2: 0.5673 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0465 - val_recall_2: 0.8817 - val_precision_2: 0.9049 - val_mean_io_u_2: 0.5743 - val_accuracy: 0.9962 - val_auc: 0.9982 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0391 - recall_2: 0.8913 - precision_2: 0.9175 - mean_io_u_2: 0.5689 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 38: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0391 - recall_2: 0.8914 - precision_2: 0.9176 - mean_io_u_2: 0.5689 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0420 - val_recall_2: 0.8918 - val_precision_2: 0.9126 - val_mean_io_u_2: 0.5814 - val_accuracy: 0.9965 - val_auc: 0.9987 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0390 - recall_2: 0.8914 - precision_2: 0.9180 - mean_io_u_2: 0.5698 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 39: val_loss did not improve from 0.04145\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0390 - recall_2: 0.8915 - precision_2: 0.9180 - mean_io_u_2: 0.5698 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0512 - val_recall_2: 0.8749 - val_precision_2: 0.8973 - val_mean_io_u_2: 0.5785 - val_accuracy: 0.9959 - val_auc: 0.9977 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0389 - recall_2: 0.8926 - precision_2: 0.9180 - mean_io_u_2: 0.5702 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 40: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0389 - recall_2: 0.8927 - precision_2: 0.9180 - mean_io_u_2: 0.5702 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0460 - val_recall_2: 0.8823 - val_precision_2: 0.9067 - val_mean_io_u_2: 0.5782 - val_accuracy: 0.9962 - val_auc: 0.9982 - lr: 1.0000e-05\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0388 - recall_2: 0.8924 - precision_2: 0.9184 - mean_io_u_2: 0.5701 - accuracy: 0.9966 - auc: 0.9991\n",
      "Epoch 41: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0388 - recall_2: 0.8923 - precision_2: 0.9184 - mean_io_u_2: 0.5701 - accuracy: 0.9966 - auc: 0.9991 - val_loss: 0.0426 - val_recall_2: 0.8907 - val_precision_2: 0.9118 - val_mean_io_u_2: 0.5796 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0388 - recall_2: 0.8929 - precision_2: 0.9182 - mean_io_u_2: 0.5702 - accuracy: 0.9966 - auc: 0.9991\n",
      "Epoch 42: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0389 - recall_2: 0.8929 - precision_2: 0.9182 - mean_io_u_2: 0.5702 - accuracy: 0.9966 - auc: 0.9991 - val_loss: 0.0426 - val_recall_2: 0.8904 - val_precision_2: 0.9119 - val_mean_io_u_2: 0.5796 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0388 - recall_2: 0.8930 - precision_2: 0.9185 - mean_io_u_2: 0.5701 - accuracy: 0.9966 - auc: 0.9991\n",
      "Epoch 43: val_loss did not improve from 0.04145\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.0388 - recall_2: 0.8930 - precision_2: 0.9185 - mean_io_u_2: 0.5701 - accuracy: 0.9966 - auc: 0.9991 - val_loss: 0.0427 - val_recall_2: 0.8903 - val_precision_2: 0.9119 - val_mean_io_u_2: 0.5788 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0388 - recall_2: 0.8929 - precision_2: 0.9184 - mean_io_u_2: 0.5703 - accuracy: 0.9966 - auc: 0.9991\n",
      "Epoch 44: val_loss did not improve from 0.04145\n",
      "\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0388 - recall_2: 0.8929 - precision_2: 0.9184 - mean_io_u_2: 0.5703 - accuracy: 0.9966 - auc: 0.9991 - val_loss: 0.0426 - val_recall_2: 0.8909 - val_precision_2: 0.9120 - val_mean_io_u_2: 0.5794 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 44: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f041c6f1430>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 2.6459 - recall_3: 0.5579 - precision_3: 0.0664 - mean_io_u_3: 0.4910 - accuracy: 0.8507 - auc: 0.6259\n",
      "Epoch 1: val_loss improved from inf to 0.61911, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 24s 317ms/step - loss: 2.6398 - recall_3: 0.5583 - precision_3: 0.0667 - mean_io_u_3: 0.4910 - accuracy: 0.8512 - auc: 0.6264 - val_loss: 0.6191 - val_recall_3: 0.1122 - val_precision_3: 0.8058 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9835 - val_auc: 0.6277 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7976 - recall_3: 0.6959 - precision_3: 0.5720 - mean_io_u_3: 0.4910 - accuracy: 0.9851 - auc: 0.8249\n",
      "Epoch 2: val_loss improved from 0.61911 to 0.56234, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 18s 279ms/step - loss: 0.7975 - recall_3: 0.6959 - precision_3: 0.5720 - mean_io_u_3: 0.4910 - accuracy: 0.9851 - auc: 0.8250 - val_loss: 0.5623 - val_recall_3: 0.0858 - val_precision_3: 0.9046 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9834 - val_auc: 0.6790 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7116 - recall_3: 0.6992 - precision_3: 0.6269 - mean_io_u_3: 0.4910 - accuracy: 0.9871 - auc: 0.8608\n",
      "Epoch 3: val_loss improved from 0.56234 to 0.48401, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 18s 286ms/step - loss: 0.7115 - recall_3: 0.6992 - precision_3: 0.6269 - mean_io_u_3: 0.4910 - accuracy: 0.9871 - auc: 0.8608 - val_loss: 0.4840 - val_recall_3: 0.0511 - val_precision_3: 0.9475 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9828 - val_auc: 0.7235 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.6188 - recall_3: 0.6914 - precision_3: 0.6763 - mean_io_u_3: 0.4910 - accuracy: 0.9885 - auc: 0.8899\n",
      "Epoch 4: val_loss improved from 0.48401 to 0.32555, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 18s 280ms/step - loss: 0.6187 - recall_3: 0.6916 - precision_3: 0.6765 - mean_io_u_3: 0.4910 - accuracy: 0.9885 - auc: 0.8901 - val_loss: 0.3255 - val_recall_3: 0.0063 - val_precision_3: 0.9691 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9821 - val_auc: 0.5810 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.5183 - recall_3: 0.7377 - precision_3: 0.7417 - mean_io_u_3: 0.4910 - accuracy: 0.9906 - auc: 0.9326\n",
      "Epoch 5: val_loss did not improve from 0.32555\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.5181 - recall_3: 0.7375 - precision_3: 0.7418 - mean_io_u_3: 0.4910 - accuracy: 0.9906 - auc: 0.9325 - val_loss: 0.3338 - val_recall_3: 0.2064 - val_precision_3: 0.9542 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9855 - val_auc: 0.5205 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4172 - recall_3: 0.7434 - precision_3: 0.7880 - mean_io_u_3: 0.4910 - accuracy: 0.9918 - auc: 0.9537\n",
      "Epoch 6: val_loss improved from 0.32555 to 0.24443, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.4170 - recall_3: 0.7434 - precision_3: 0.7881 - mean_io_u_3: 0.4910 - accuracy: 0.9918 - auc: 0.9537 - val_loss: 0.2444 - val_recall_3: 0.1880 - val_precision_3: 0.9441 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9852 - val_auc: 0.6568 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3322 - recall_3: 0.7458 - precision_3: 0.8155 - mean_io_u_3: 0.4910 - accuracy: 0.9924 - auc: 0.9653\n",
      "Epoch 7: val_loss improved from 0.24443 to 0.20081, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.3322 - recall_3: 0.7458 - precision_3: 0.8155 - mean_io_u_3: 0.4910 - accuracy: 0.9924 - auc: 0.9653 - val_loss: 0.2008 - val_recall_3: 0.2737 - val_precision_3: 0.9311 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9865 - val_auc: 0.6911 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2638 - recall_3: 0.7468 - precision_3: 0.8369 - mean_io_u_3: 0.4911 - accuracy: 0.9928 - auc: 0.9736\n",
      "Epoch 8: val_loss improved from 0.20081 to 0.15968, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.2638 - recall_3: 0.7468 - precision_3: 0.8369 - mean_io_u_3: 0.4911 - accuracy: 0.9928 - auc: 0.9736 - val_loss: 0.1597 - val_recall_3: 0.2000 - val_precision_3: 0.9421 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9854 - val_auc: 0.8474 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2147 - recall_3: 0.7451 - precision_3: 0.8499 - mean_io_u_3: 0.4912 - accuracy: 0.9930 - auc: 0.9807\n",
      "Epoch 9: val_loss improved from 0.15968 to 0.14279, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.2147 - recall_3: 0.7451 - precision_3: 0.8499 - mean_io_u_3: 0.4912 - accuracy: 0.9930 - auc: 0.9807 - val_loss: 0.1428 - val_recall_3: 0.2742 - val_precision_3: 0.9175 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9865 - val_auc: 0.8245 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1793 - recall_3: 0.7469 - precision_3: 0.8604 - mean_io_u_3: 0.4912 - accuracy: 0.9933 - auc: 0.9865\n",
      "Epoch 10: val_loss improved from 0.14279 to 0.13993, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.1793 - recall_3: 0.7469 - precision_3: 0.8604 - mean_io_u_3: 0.4912 - accuracy: 0.9933 - auc: 0.9865 - val_loss: 0.1399 - val_recall_3: 0.5027 - val_precision_3: 0.9061 - val_mean_io_u_3: 0.4911 - val_accuracy: 0.9901 - val_auc: 0.9345 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1548 - recall_3: 0.7543 - precision_3: 0.8670 - mean_io_u_3: 0.4911 - accuracy: 0.9935 - auc: 0.9891\n",
      "Epoch 11: val_loss improved from 0.13993 to 0.12186, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.1548 - recall_3: 0.7540 - precision_3: 0.8671 - mean_io_u_3: 0.4911 - accuracy: 0.9935 - auc: 0.9891 - val_loss: 0.1219 - val_recall_3: 0.5803 - val_precision_3: 0.9280 - val_mean_io_u_3: 0.4910 - val_accuracy: 0.9916 - val_auc: 0.9754 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1377 - recall_3: 0.7542 - precision_3: 0.8724 - mean_io_u_3: 0.4911 - accuracy: 0.9936 - auc: 0.9910\n",
      "Epoch 12: val_loss did not improve from 0.12186\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.1377 - recall_3: 0.7542 - precision_3: 0.8724 - mean_io_u_3: 0.4911 - accuracy: 0.9936 - auc: 0.9908 - val_loss: 0.1490 - val_recall_3: 0.7930 - val_precision_3: 0.8486 - val_mean_io_u_3: 0.4928 - val_accuracy: 0.9937 - val_auc: 0.9924 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1257 - recall_3: 0.7669 - precision_3: 0.8757 - mean_io_u_3: 0.4911 - accuracy: 0.9938 - auc: 0.9928\n",
      "Epoch 13: val_loss did not improve from 0.12186\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.1257 - recall_3: 0.7669 - precision_3: 0.8757 - mean_io_u_3: 0.4911 - accuracy: 0.9938 - auc: 0.9928 - val_loss: 0.1267 - val_recall_3: 0.7901 - val_precision_3: 0.8682 - val_mean_io_u_3: 0.4917 - val_accuracy: 0.9941 - val_auc: 0.9925 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1158 - recall_3: 0.7753 - precision_3: 0.8800 - mean_io_u_3: 0.4911 - accuracy: 0.9940 - auc: 0.9934\n",
      "Epoch 14: val_loss did not improve from 0.12186\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.1158 - recall_3: 0.7752 - precision_3: 0.8800 - mean_io_u_3: 0.4911 - accuracy: 0.9940 - auc: 0.9934 - val_loss: 0.1250 - val_recall_3: 0.7933 - val_precision_3: 0.8646 - val_mean_io_u_3: 0.4914 - val_accuracy: 0.9940 - val_auc: 0.9935 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1092 - recall_3: 0.7823 - precision_3: 0.8824 - mean_io_u_3: 0.4911 - accuracy: 0.9942 - auc: 0.9949\n",
      "Epoch 15: val_loss improved from 0.12186 to 0.11631, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.1092 - recall_3: 0.7823 - precision_3: 0.8824 - mean_io_u_3: 0.4911 - accuracy: 0.9942 - auc: 0.9949 - val_loss: 0.1163 - val_recall_3: 0.8184 - val_precision_3: 0.8659 - val_mean_io_u_3: 0.4934 - val_accuracy: 0.9944 - val_auc: 0.9960 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1029 - recall_3: 0.7924 - precision_3: 0.8864 - mean_io_u_3: 0.4911 - accuracy: 0.9944 - auc: 0.9957\n",
      "Epoch 16: val_loss did not improve from 0.11631\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1029 - recall_3: 0.7926 - precision_3: 0.8862 - mean_io_u_3: 0.4911 - accuracy: 0.9944 - auc: 0.9957 - val_loss: 0.1291 - val_recall_3: 0.8265 - val_precision_3: 0.8516 - val_mean_io_u_3: 0.4917 - val_accuracy: 0.9943 - val_auc: 0.9962 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0982 - recall_3: 0.8008 - precision_3: 0.8885 - mean_io_u_3: 0.4911 - accuracy: 0.9946 - auc: 0.9965\n",
      "Epoch 17: val_loss did not improve from 0.11631\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0982 - recall_3: 0.8008 - precision_3: 0.8885 - mean_io_u_3: 0.4911 - accuracy: 0.9946 - auc: 0.9965 - val_loss: 0.1197 - val_recall_3: 0.8419 - val_precision_3: 0.8594 - val_mean_io_u_3: 0.4930 - val_accuracy: 0.9947 - val_auc: 0.9962 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0948 - recall_3: 0.8075 - precision_3: 0.8902 - mean_io_u_3: 0.4911 - accuracy: 0.9947 - auc: 0.9965\n",
      "Epoch 18: val_loss improved from 0.11631 to 0.10213, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0948 - recall_3: 0.8075 - precision_3: 0.8903 - mean_io_u_3: 0.4911 - accuracy: 0.9947 - auc: 0.9966 - val_loss: 0.1021 - val_recall_3: 0.8222 - val_precision_3: 0.8804 - val_mean_io_u_3: 0.4917 - val_accuracy: 0.9948 - val_auc: 0.9964 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0923 - recall_3: 0.8153 - precision_3: 0.8912 - mean_io_u_3: 0.4911 - accuracy: 0.9949 - auc: 0.9973\n",
      "Epoch 19: val_loss improved from 0.10213 to 0.09797, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.0923 - recall_3: 0.8154 - precision_3: 0.8912 - mean_io_u_3: 0.4911 - accuracy: 0.9949 - auc: 0.9973 - val_loss: 0.0980 - val_recall_3: 0.8471 - val_precision_3: 0.8815 - val_mean_io_u_3: 0.4914 - val_accuracy: 0.9952 - val_auc: 0.9973 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0890 - recall_3: 0.8203 - precision_3: 0.8941 - mean_io_u_3: 0.4912 - accuracy: 0.9950 - auc: 0.9971\n",
      "Epoch 20: val_loss did not improve from 0.09797\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.0890 - recall_3: 0.8204 - precision_3: 0.8940 - mean_io_u_3: 0.4912 - accuracy: 0.9950 - auc: 0.9971 - val_loss: 0.1043 - val_recall_3: 0.8443 - val_precision_3: 0.8700 - val_mean_io_u_3: 0.4925 - val_accuracy: 0.9949 - val_auc: 0.9970 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0865 - recall_3: 0.8264 - precision_3: 0.8957 - mean_io_u_3: 0.4912 - accuracy: 0.9951 - auc: 0.9974\n",
      "Epoch 21: val_loss did not improve from 0.09797\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0865 - recall_3: 0.8265 - precision_3: 0.8956 - mean_io_u_3: 0.4912 - accuracy: 0.9951 - auc: 0.9974 - val_loss: 0.1153 - val_recall_3: 0.8590 - val_precision_3: 0.8617 - val_mean_io_u_3: 0.4925 - val_accuracy: 0.9950 - val_auc: 0.9968 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0854 - recall_3: 0.8333 - precision_3: 0.8958 - mean_io_u_3: 0.4912 - accuracy: 0.9952 - auc: 0.9977\n",
      "Epoch 22: val_loss improved from 0.09797 to 0.08700, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.0854 - recall_3: 0.8333 - precision_3: 0.8958 - mean_io_u_3: 0.4912 - accuracy: 0.9952 - auc: 0.9977 - val_loss: 0.0870 - val_recall_3: 0.8386 - val_precision_3: 0.8961 - val_mean_io_u_3: 0.4922 - val_accuracy: 0.9953 - val_auc: 0.9968 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0827 - recall_3: 0.8394 - precision_3: 0.8984 - mean_io_u_3: 0.4913 - accuracy: 0.9954 - auc: 0.9979\n",
      "Epoch 23: val_loss did not improve from 0.08700\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0827 - recall_3: 0.8394 - precision_3: 0.8984 - mean_io_u_3: 0.4913 - accuracy: 0.9954 - auc: 0.9979 - val_loss: 0.0939 - val_recall_3: 0.8459 - val_precision_3: 0.8846 - val_mean_io_u_3: 0.4927 - val_accuracy: 0.9952 - val_auc: 0.9973 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0810 - recall_3: 0.8422 - precision_3: 0.8998 - mean_io_u_3: 0.4913 - accuracy: 0.9955 - auc: 0.9979\n",
      "Epoch 24: val_loss improved from 0.08700 to 0.08424, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0810 - recall_3: 0.8423 - precision_3: 0.8998 - mean_io_u_3: 0.4913 - accuracy: 0.9955 - auc: 0.9979 - val_loss: 0.0842 - val_recall_3: 0.8596 - val_precision_3: 0.8957 - val_mean_io_u_3: 0.4921 - val_accuracy: 0.9957 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0795 - recall_3: 0.8451 - precision_3: 0.9013 - mean_io_u_3: 0.4913 - accuracy: 0.9955 - auc: 0.9979\n",
      "Epoch 25: val_loss did not improve from 0.08424\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.0795 - recall_3: 0.8450 - precision_3: 0.9013 - mean_io_u_3: 0.4913 - accuracy: 0.9955 - auc: 0.9979 - val_loss: 0.0853 - val_recall_3: 0.8653 - val_precision_3: 0.8925 - val_mean_io_u_3: 0.4936 - val_accuracy: 0.9957 - val_auc: 0.9979 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0775 - recall_3: 0.8518 - precision_3: 0.9034 - mean_io_u_3: 0.4915 - accuracy: 0.9957 - auc: 0.9979\n",
      "Epoch 26: val_loss improved from 0.08424 to 0.08410, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0775 - recall_3: 0.8517 - precision_3: 0.9034 - mean_io_u_3: 0.4915 - accuracy: 0.9957 - auc: 0.9979 - val_loss: 0.0841 - val_recall_3: 0.8648 - val_precision_3: 0.8932 - val_mean_io_u_3: 0.4922 - val_accuracy: 0.9957 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0753 - recall_3: 0.8565 - precision_3: 0.9057 - mean_io_u_3: 0.4916 - accuracy: 0.9958 - auc: 0.9982\n",
      "Epoch 27: val_loss improved from 0.08410 to 0.08407, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.0753 - recall_3: 0.8565 - precision_3: 0.9057 - mean_io_u_3: 0.4916 - accuracy: 0.9958 - auc: 0.9982 - val_loss: 0.0841 - val_recall_3: 0.8504 - val_precision_3: 0.8967 - val_mean_io_u_3: 0.4927 - val_accuracy: 0.9955 - val_auc: 0.9976 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0750 - recall_3: 0.8553 - precision_3: 0.9058 - mean_io_u_3: 0.4916 - accuracy: 0.9958 - auc: 0.9984\n",
      "Epoch 28: val_loss improved from 0.08407 to 0.07972, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.0750 - recall_3: 0.8553 - precision_3: 0.9058 - mean_io_u_3: 0.4916 - accuracy: 0.9958 - auc: 0.9984 - val_loss: 0.0797 - val_recall_3: 0.8585 - val_precision_3: 0.8994 - val_mean_io_u_3: 0.4935 - val_accuracy: 0.9957 - val_auc: 0.9982 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0739 - recall_3: 0.8559 - precision_3: 0.9070 - mean_io_u_3: 0.4917 - accuracy: 0.9958 - auc: 0.9986\n",
      "Epoch 29: val_loss improved from 0.07972 to 0.07801, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.0739 - recall_3: 0.8559 - precision_3: 0.9070 - mean_io_u_3: 0.4917 - accuracy: 0.9958 - auc: 0.9986 - val_loss: 0.0780 - val_recall_3: 0.8685 - val_precision_3: 0.9001 - val_mean_io_u_3: 0.4932 - val_accuracy: 0.9959 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0711 - recall_3: 0.8645 - precision_3: 0.9099 - mean_io_u_3: 0.4922 - accuracy: 0.9960 - auc: 0.9988\n",
      "Epoch 30: val_loss improved from 0.07801 to 0.07131, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0711 - recall_3: 0.8645 - precision_3: 0.9099 - mean_io_u_3: 0.4922 - accuracy: 0.9960 - auc: 0.9988 - val_loss: 0.0713 - val_recall_3: 0.8599 - val_precision_3: 0.9118 - val_mean_io_u_3: 0.4928 - val_accuracy: 0.9960 - val_auc: 0.9987 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0695 - recall_3: 0.8656 - precision_3: 0.9122 - mean_io_u_3: 0.4928 - accuracy: 0.9961 - auc: 0.9988\n",
      "Epoch 31: val_loss improved from 0.07131 to 0.06924, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.0695 - recall_3: 0.8657 - precision_3: 0.9122 - mean_io_u_3: 0.4928 - accuracy: 0.9961 - auc: 0.9988 - val_loss: 0.0692 - val_recall_3: 0.8601 - val_precision_3: 0.9151 - val_mean_io_u_3: 0.4943 - val_accuracy: 0.9960 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0700 - recall_3: 0.8631 - precision_3: 0.9117 - mean_io_u_3: 0.4924 - accuracy: 0.9960 - auc: 0.9987\n",
      "Epoch 32: val_loss did not improve from 0.06924\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0700 - recall_3: 0.8632 - precision_3: 0.9117 - mean_io_u_3: 0.4924 - accuracy: 0.9960 - auc: 0.9987 - val_loss: 0.0741 - val_recall_3: 0.8570 - val_precision_3: 0.9080 - val_mean_io_u_3: 0.4941 - val_accuracy: 0.9959 - val_auc: 0.9983 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0687 - recall_3: 0.8681 - precision_3: 0.9125 - mean_io_u_3: 0.4924 - accuracy: 0.9961 - auc: 0.9988\n",
      "Epoch 33: val_loss did not improve from 0.06924\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0687 - recall_3: 0.8681 - precision_3: 0.9125 - mean_io_u_3: 0.4924 - accuracy: 0.9961 - auc: 0.9988 - val_loss: 0.0774 - val_recall_3: 0.8688 - val_precision_3: 0.9038 - val_mean_io_u_3: 0.4934 - val_accuracy: 0.9960 - val_auc: 0.9981 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0672 - recall_3: 0.8708 - precision_3: 0.9145 - mean_io_u_3: 0.4931 - accuracy: 0.9962 - auc: 0.9988\n",
      "Epoch 34: val_loss improved from 0.06924 to 0.06911, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.0672 - recall_3: 0.8707 - precision_3: 0.9145 - mean_io_u_3: 0.4931 - accuracy: 0.9962 - auc: 0.9988 - val_loss: 0.0691 - val_recall_3: 0.8619 - val_precision_3: 0.9146 - val_mean_io_u_3: 0.4968 - val_accuracy: 0.9961 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0661 - recall_3: 0.8732 - precision_3: 0.9158 - mean_io_u_3: 0.4933 - accuracy: 0.9963 - auc: 0.9988\n",
      "Epoch 35: val_loss improved from 0.06911 to 0.06587, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.0662 - recall_3: 0.8732 - precision_3: 0.9158 - mean_io_u_3: 0.4933 - accuracy: 0.9963 - auc: 0.9988 - val_loss: 0.0659 - val_recall_3: 0.8633 - val_precision_3: 0.9187 - val_mean_io_u_3: 0.4940 - val_accuracy: 0.9962 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0654 - recall_3: 0.8737 - precision_3: 0.9166 - mean_io_u_3: 0.4937 - accuracy: 0.9963 - auc: 0.9988\n",
      "Epoch 36: val_loss did not improve from 0.06587\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0654 - recall_3: 0.8736 - precision_3: 0.9166 - mean_io_u_3: 0.4937 - accuracy: 0.9963 - auc: 0.9988 - val_loss: 0.0744 - val_recall_3: 0.8656 - val_precision_3: 0.9083 - val_mean_io_u_3: 0.4948 - val_accuracy: 0.9960 - val_auc: 0.9979 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0650 - recall_3: 0.8726 - precision_3: 0.9172 - mean_io_u_3: 0.4936 - accuracy: 0.9963 - auc: 0.9988\n",
      "Epoch 37: val_loss did not improve from 0.06587\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0650 - recall_3: 0.8726 - precision_3: 0.9172 - mean_io_u_3: 0.4936 - accuracy: 0.9963 - auc: 0.9988 - val_loss: 0.0755 - val_recall_3: 0.8803 - val_precision_3: 0.9032 - val_mean_io_u_3: 0.4980 - val_accuracy: 0.9961 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0640 - recall_3: 0.8768 - precision_3: 0.9178 - mean_io_u_3: 0.4943 - accuracy: 0.9964 - auc: 0.9988\n",
      "Epoch 38: val_loss did not improve from 0.06587\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0640 - recall_3: 0.8769 - precision_3: 0.9178 - mean_io_u_3: 0.4943 - accuracy: 0.9964 - auc: 0.9989 - val_loss: 0.0702 - val_recall_3: 0.8744 - val_precision_3: 0.9103 - val_mean_io_u_3: 0.4971 - val_accuracy: 0.9962 - val_auc: 0.9986 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0628 - recall_3: 0.8791 - precision_3: 0.9193 - mean_io_u_3: 0.4951 - accuracy: 0.9964 - auc: 0.9989\n",
      "Epoch 39: val_loss did not improve from 0.06587\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0628 - recall_3: 0.8791 - precision_3: 0.9193 - mean_io_u_3: 0.4951 - accuracy: 0.9964 - auc: 0.9989 - val_loss: 0.0706 - val_recall_3: 0.8780 - val_precision_3: 0.9103 - val_mean_io_u_3: 0.5003 - val_accuracy: 0.9962 - val_auc: 0.9985 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0624 - recall_3: 0.8787 - precision_3: 0.9201 - mean_io_u_3: 0.4951 - accuracy: 0.9964 - auc: 0.9989\n",
      "Epoch 40: val_loss did not improve from 0.06587\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0624 - recall_3: 0.8787 - precision_3: 0.9201 - mean_io_u_3: 0.4951 - accuracy: 0.9964 - auc: 0.9989 - val_loss: 0.0710 - val_recall_3: 0.8740 - val_precision_3: 0.9104 - val_mean_io_u_3: 0.4975 - val_accuracy: 0.9962 - val_auc: 0.9984 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0607 - recall_3: 0.8876 - precision_3: 0.9213 - mean_io_u_3: 0.4963 - accuracy: 0.9966 - auc: 0.9990\n",
      "Epoch 41: val_loss improved from 0.06587 to 0.06345, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.0607 - recall_3: 0.8875 - precision_3: 0.9213 - mean_io_u_3: 0.4963 - accuracy: 0.9966 - auc: 0.9990 - val_loss: 0.0634 - val_recall_3: 0.8765 - val_precision_3: 0.9210 - val_mean_io_u_3: 0.4972 - val_accuracy: 0.9964 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0593 - recall_3: 0.8902 - precision_3: 0.9231 - mean_io_u_3: 0.4974 - accuracy: 0.9967 - auc: 0.9990\n",
      "Epoch 42: val_loss did not improve from 0.06345\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0593 - recall_3: 0.8902 - precision_3: 0.9230 - mean_io_u_3: 0.4974 - accuracy: 0.9967 - auc: 0.9990 - val_loss: 0.0647 - val_recall_3: 0.8814 - val_precision_3: 0.9188 - val_mean_io_u_3: 0.4990 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0588 - recall_3: 0.8911 - precision_3: 0.9238 - mean_io_u_3: 0.4986 - accuracy: 0.9967 - auc: 0.9989\n",
      "Epoch 43: val_loss did not improve from 0.06345\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0588 - recall_3: 0.8911 - precision_3: 0.9239 - mean_io_u_3: 0.4985 - accuracy: 0.9967 - auc: 0.9989 - val_loss: 0.0641 - val_recall_3: 0.8803 - val_precision_3: 0.9199 - val_mean_io_u_3: 0.4993 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0584 - recall_3: 0.8911 - precision_3: 0.9244 - mean_io_u_3: 0.4989 - accuracy: 0.9967 - auc: 0.9990\n",
      "Epoch 44: val_loss improved from 0.06345 to 0.06341, saving model to ./iter_wBCE-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-17.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.0584 - recall_3: 0.8911 - precision_3: 0.9244 - mean_io_u_3: 0.4989 - accuracy: 0.9967 - auc: 0.9990 - val_loss: 0.0634 - val_recall_3: 0.8797 - val_precision_3: 0.9210 - val_mean_io_u_3: 0.5002 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0580 - recall_3: 0.8909 - precision_3: 0.9250 - mean_io_u_3: 0.4999 - accuracy: 0.9967 - auc: 0.9990\n",
      "Epoch 45: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0580 - recall_3: 0.8908 - precision_3: 0.9250 - mean_io_u_3: 0.4999 - accuracy: 0.9967 - auc: 0.9990 - val_loss: 0.0648 - val_recall_3: 0.8830 - val_precision_3: 0.9188 - val_mean_io_u_3: 0.5016 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0576 - recall_3: 0.8913 - precision_3: 0.9256 - mean_io_u_3: 0.5002 - accuracy: 0.9968 - auc: 0.9989\n",
      "Epoch 46: val_loss did not improve from 0.06341\n",
      "\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0577 - recall_3: 0.8913 - precision_3: 0.9256 - mean_io_u_3: 0.5003 - accuracy: 0.9968 - auc: 0.9989 - val_loss: 0.0658 - val_recall_3: 0.8829 - val_precision_3: 0.9176 - val_mean_io_u_3: 0.5025 - val_accuracy: 0.9965 - val_auc: 0.9985 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0576 - recall_3: 0.8918 - precision_3: 0.9255 - mean_io_u_3: 0.5009 - accuracy: 0.9968 - auc: 0.9989\n",
      "Epoch 47: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0576 - recall_3: 0.8918 - precision_3: 0.9255 - mean_io_u_3: 0.5009 - accuracy: 0.9968 - auc: 0.9989 - val_loss: 0.0655 - val_recall_3: 0.8846 - val_precision_3: 0.9178 - val_mean_io_u_3: 0.5032 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0573 - recall_3: 0.8920 - precision_3: 0.9260 - mean_io_u_3: 0.5009 - accuracy: 0.9968 - auc: 0.9989\n",
      "Epoch 48: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0573 - recall_3: 0.8921 - precision_3: 0.9260 - mean_io_u_3: 0.5009 - accuracy: 0.9968 - auc: 0.9989 - val_loss: 0.0658 - val_recall_3: 0.8852 - val_precision_3: 0.9172 - val_mean_io_u_3: 0.5037 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0572 - recall_3: 0.8923 - precision_3: 0.9260 - mean_io_u_3: 0.5008 - accuracy: 0.9968 - auc: 0.9989\n",
      "Epoch 49: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0572 - recall_3: 0.8923 - precision_3: 0.9260 - mean_io_u_3: 0.5008 - accuracy: 0.9968 - auc: 0.9989 - val_loss: 0.0659 - val_recall_3: 0.8854 - val_precision_3: 0.9172 - val_mean_io_u_3: 0.5039 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0573 - recall_3: 0.8922 - precision_3: 0.9258 - mean_io_u_3: 0.5008 - accuracy: 0.9968 - auc: 0.9990\n",
      "Epoch 50: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0573 - recall_3: 0.8921 - precision_3: 0.9258 - mean_io_u_3: 0.5008 - accuracy: 0.9968 - auc: 0.9990 - val_loss: 0.0657 - val_recall_3: 0.8850 - val_precision_3: 0.9174 - val_mean_io_u_3: 0.5040 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0572 - recall_3: 0.8923 - precision_3: 0.9260 - mean_io_u_3: 0.5011 - accuracy: 0.9968 - auc: 0.9990\n",
      "Epoch 51: val_loss did not improve from 0.06341\n",
      "\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.0572 - recall_3: 0.8923 - precision_3: 0.9260 - mean_io_u_3: 0.5011 - accuracy: 0.9968 - auc: 0.9990 - val_loss: 0.0661 - val_recall_3: 0.8860 - val_precision_3: 0.9168 - val_mean_io_u_3: 0.5044 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0571 - recall_3: 0.8920 - precision_3: 0.9261 - mean_io_u_3: 0.5010 - accuracy: 0.9968 - auc: 0.9990\n",
      "Epoch 52: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.0572 - recall_3: 0.8920 - precision_3: 0.9261 - mean_io_u_3: 0.5010 - accuracy: 0.9968 - auc: 0.9990 - val_loss: 0.0663 - val_recall_3: 0.8860 - val_precision_3: 0.9165 - val_mean_io_u_3: 0.5046 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0571 - recall_3: 0.8919 - precision_3: 0.9263 - mean_io_u_3: 0.5011 - accuracy: 0.9968 - auc: 0.9990\n",
      "Epoch 53: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0571 - recall_3: 0.8918 - precision_3: 0.9263 - mean_io_u_3: 0.5011 - accuracy: 0.9968 - auc: 0.9990 - val_loss: 0.0659 - val_recall_3: 0.8855 - val_precision_3: 0.9171 - val_mean_io_u_3: 0.5045 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0570 - recall_3: 0.8924 - precision_3: 0.9262 - mean_io_u_3: 0.5013 - accuracy: 0.9968 - auc: 0.9989\n",
      "Epoch 54: val_loss did not improve from 0.06341\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0570 - recall_3: 0.8924 - precision_3: 0.9262 - mean_io_u_3: 0.5013 - accuracy: 0.9968 - auc: 0.9989 - val_loss: 0.0662 - val_recall_3: 0.8859 - val_precision_3: 0.9166 - val_mean_io_u_3: 0.5045 - val_accuracy: 0.9965 - val_auc: 0.9986 - lr: 1.0000e-05\n",
      "Epoch 54: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f03e0362820>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.6007 - recall_4: 0.4876 - precision_4: 0.0950 - mean_io_u_4: 0.4918 - accuracy: 0.9071 - auc: 0.5784\n",
      "Epoch 1: val_loss improved from inf to 0.25347, saving model to ./iter_wBCE-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-25.model/assets\n",
      "65/65 [==============================] - 25s 331ms/step - loss: 2.6007 - recall_4: 0.4876 - precision_4: 0.0950 - mean_io_u_4: 0.4918 - accuracy: 0.9071 - auc: 0.5784 - val_loss: 0.2535 - val_recall_4: 0.0340 - val_precision_4: 0.7778 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9824 - val_auc: 0.5646 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7652 - recall_4: 0.4781 - precision_4: 0.6304 - mean_io_u_4: 0.4910 - accuracy: 0.9855 - auc: 0.7141\n",
      "Epoch 2: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.7651 - recall_4: 0.4782 - precision_4: 0.6304 - mean_io_u_4: 0.4910 - accuracy: 0.9855 - auc: 0.7143 - val_loss: 0.6504 - val_recall_4: 0.3140 - val_precision_4: 0.8148 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9863 - val_auc: 0.7537 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7188 - recall_4: 0.5361 - precision_4: 0.6537 - mean_io_u_4: 0.4910 - accuracy: 0.9865 - auc: 0.8197\n",
      "Epoch 3: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.7189 - recall_4: 0.5363 - precision_4: 0.6536 - mean_io_u_4: 0.4910 - accuracy: 0.9865 - auc: 0.8198 - val_loss: 0.5808 - val_recall_4: 0.3233 - val_precision_4: 0.8357 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9867 - val_auc: 0.7826 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6779 - recall_4: 0.6294 - precision_4: 0.6795 - mean_io_u_4: 0.4910 - accuracy: 0.9880 - auc: 0.8775\n",
      "Epoch 4: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 198ms/step - loss: 0.6779 - recall_4: 0.6294 - precision_4: 0.6795 - mean_io_u_4: 0.4910 - accuracy: 0.9880 - auc: 0.8775 - val_loss: 0.5214 - val_recall_4: 0.3610 - val_precision_4: 0.8314 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9872 - val_auc: 0.8751 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.6159 - recall_4: 0.7041 - precision_4: 0.7087 - mean_io_u_4: 0.4910 - accuracy: 0.9895 - auc: 0.9012\n",
      "Epoch 5: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 195ms/step - loss: 0.6158 - recall_4: 0.7041 - precision_4: 0.7088 - mean_io_u_4: 0.4910 - accuracy: 0.9895 - auc: 0.9012 - val_loss: 0.4755 - val_recall_4: 0.4028 - val_precision_4: 0.7927 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9873 - val_auc: 0.9090 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5194 - recall_4: 0.7454 - precision_4: 0.7663 - mean_io_u_4: 0.4910 - accuracy: 0.9913 - auc: 0.9141\n",
      "Epoch 6: val_loss did not improve from 0.25347\n",
      "\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 0.5194 - recall_4: 0.7454 - precision_4: 0.7663 - mean_io_u_4: 0.4910 - accuracy: 0.9913 - auc: 0.9141 - val_loss: 0.4317 - val_recall_4: 0.5312 - val_precision_4: 0.8392 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9897 - val_auc: 0.9187 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4659 - recall_4: 0.7626 - precision_4: 0.7940 - mean_io_u_4: 0.4910 - accuracy: 0.9922 - auc: 0.9277\n",
      "Epoch 7: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 0.4659 - recall_4: 0.7626 - precision_4: 0.7940 - mean_io_u_4: 0.4910 - accuracy: 0.9922 - auc: 0.9277 - val_loss: 0.4087 - val_recall_4: 0.5658 - val_precision_4: 0.8663 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9906 - val_auc: 0.9097 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4556 - recall_4: 0.7666 - precision_4: 0.7987 - mean_io_u_4: 0.4910 - accuracy: 0.9923 - auc: 0.9282\n",
      "Epoch 8: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 0.4556 - recall_4: 0.7666 - precision_4: 0.7987 - mean_io_u_4: 0.4910 - accuracy: 0.9923 - auc: 0.9282 - val_loss: 0.4146 - val_recall_4: 0.6731 - val_precision_4: 0.8612 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9921 - val_auc: 0.9285 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4456 - recall_4: 0.7673 - precision_4: 0.8037 - mean_io_u_4: 0.4910 - accuracy: 0.9924 - auc: 0.9290\n",
      "Epoch 9: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 196ms/step - loss: 0.4456 - recall_4: 0.7673 - precision_4: 0.8037 - mean_io_u_4: 0.4910 - accuracy: 0.9924 - auc: 0.9290 - val_loss: 0.4188 - val_recall_4: 0.7386 - val_precision_4: 0.8424 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9928 - val_auc: 0.9381 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4364 - recall_4: 0.7713 - precision_4: 0.8073 - mean_io_u_4: 0.4910 - accuracy: 0.9926 - auc: 0.9322\n",
      "Epoch 10: val_loss did not improve from 0.25347\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.4364 - recall_4: 0.7713 - precision_4: 0.8073 - mean_io_u_4: 0.4910 - accuracy: 0.9926 - auc: 0.9322 - val_loss: 0.4003 - val_recall_4: 0.7172 - val_precision_4: 0.8510 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9926 - val_auc: 0.9247 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4248 - recall_4: 0.7745 - precision_4: 0.8135 - mean_io_u_4: 0.4910 - accuracy: 0.9927 - auc: 0.9340\n",
      "Epoch 11: val_loss did not improve from 0.25347\n",
      "\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.4248 - recall_4: 0.7744 - precision_4: 0.8135 - mean_io_u_4: 0.4910 - accuracy: 0.9927 - auc: 0.9339 - val_loss: 0.4038 - val_recall_4: 0.7650 - val_precision_4: 0.8340 - val_mean_io_u_4: 0.4910 - val_accuracy: 0.9930 - val_auc: 0.9365 - lr: 1.0000e-04\n",
      "Epoch 11: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f04645280d0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 4.4887 - recall_5: 0.4257 - precision_5: 0.0628 - mean_io_u_5: 0.4910 - accuracy: 0.8751 - auc: 0.5115\n",
      "Epoch 1: val_loss improved from inf to 0.88744, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 25s 339ms/step - loss: 4.4768 - recall_5: 0.4257 - precision_5: 0.0630 - mean_io_u_5: 0.4910 - accuracy: 0.8755 - auc: 0.5117 - val_loss: 0.8874 - val_recall_5: 0.2759 - val_precision_5: 0.4959 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9819 - val_auc: 0.6190 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9157 - recall_5: 0.4723 - precision_5: 0.6335 - mean_io_u_5: 0.4910 - accuracy: 0.9856 - auc: 0.6897\n",
      "Epoch 2: val_loss improved from 0.88744 to 0.69790, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.9157 - recall_5: 0.4723 - precision_5: 0.6335 - mean_io_u_5: 0.4910 - accuracy: 0.9856 - auc: 0.6897 - val_loss: 0.6979 - val_recall_5: 0.1790 - val_precision_5: 0.8092 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9844 - val_auc: 0.5364 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.8464 - recall_5: 0.4978 - precision_5: 0.6845 - mean_io_u_5: 0.4910 - accuracy: 0.9868 - auc: 0.7662\n",
      "Epoch 3: val_loss improved from 0.69790 to 0.65846, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.8463 - recall_5: 0.4979 - precision_5: 0.6845 - mean_io_u_5: 0.4910 - accuracy: 0.9868 - auc: 0.7662 - val_loss: 0.6585 - val_recall_5: 0.2065 - val_precision_5: 0.9225 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9854 - val_auc: 0.6624 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7888 - recall_5: 0.5344 - precision_5: 0.7253 - mean_io_u_5: 0.4910 - accuracy: 0.9880 - auc: 0.8389\n",
      "Epoch 4: val_loss improved from 0.65846 to 0.59337, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.7889 - recall_5: 0.5347 - precision_5: 0.7254 - mean_io_u_5: 0.4910 - accuracy: 0.9880 - auc: 0.8390 - val_loss: 0.5934 - val_recall_5: 0.1848 - val_precision_5: 0.9470 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9851 - val_auc: 0.7376 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.8501 - recall_5: 0.7477 - precision_5: 0.7149 - mean_io_u_5: 0.4910 - accuracy: 0.9901 - auc: 0.8896\n",
      "Epoch 5: val_loss did not improve from 0.59337\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.8499 - recall_5: 0.7477 - precision_5: 0.7150 - mean_io_u_5: 0.4910 - accuracy: 0.9901 - auc: 0.8895 - val_loss: 0.6562 - val_recall_5: 0.5232 - val_precision_5: 0.8676 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9900 - val_auc: 0.9226 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7103 - recall_5: 0.7748 - precision_5: 0.7943 - mean_io_u_5: 0.4910 - accuracy: 0.9923 - auc: 0.8949\n",
      "Epoch 6: val_loss improved from 0.59337 to 0.54570, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.7101 - recall_5: 0.7748 - precision_5: 0.7944 - mean_io_u_5: 0.4910 - accuracy: 0.9923 - auc: 0.8949 - val_loss: 0.5457 - val_recall_5: 0.5783 - val_precision_5: 0.9058 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9913 - val_auc: 0.9425 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6055 - recall_5: 0.7707 - precision_5: 0.8234 - mean_io_u_5: 0.4911 - accuracy: 0.9929 - auc: 0.9213\n",
      "Epoch 7: val_loss improved from 0.54570 to 0.53489, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.6055 - recall_5: 0.7707 - precision_5: 0.8234 - mean_io_u_5: 0.4911 - accuracy: 0.9929 - auc: 0.9213 - val_loss: 0.5349 - val_recall_5: 0.7679 - val_precision_5: 0.8319 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9930 - val_auc: 0.9655 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5156 - recall_5: 0.7682 - precision_5: 0.8425 - mean_io_u_5: 0.4916 - accuracy: 0.9932 - auc: 0.9437\n",
      "Epoch 8: val_loss improved from 0.53489 to 0.45649, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.5156 - recall_5: 0.7682 - precision_5: 0.8425 - mean_io_u_5: 0.4916 - accuracy: 0.9932 - auc: 0.9437 - val_loss: 0.4565 - val_recall_5: 0.7797 - val_precision_5: 0.8401 - val_mean_io_u_5: 0.4910 - val_accuracy: 0.9934 - val_auc: 0.9707 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4385 - recall_5: 0.7643 - precision_5: 0.8557 - mean_io_u_5: 0.4932 - accuracy: 0.9934 - auc: 0.9584\n",
      "Epoch 9: val_loss improved from 0.45649 to 0.39374, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.4384 - recall_5: 0.7644 - precision_5: 0.8557 - mean_io_u_5: 0.4932 - accuracy: 0.9934 - auc: 0.9585 - val_loss: 0.3937 - val_recall_5: 0.7674 - val_precision_5: 0.8545 - val_mean_io_u_5: 0.4940 - val_accuracy: 0.9935 - val_auc: 0.9752 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3770 - recall_5: 0.7667 - precision_5: 0.8655 - mean_io_u_5: 0.4954 - accuracy: 0.9936 - auc: 0.9701\n",
      "Epoch 10: val_loss did not improve from 0.39374\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.3770 - recall_5: 0.7667 - precision_5: 0.8655 - mean_io_u_5: 0.4954 - accuracy: 0.9936 - auc: 0.9701 - val_loss: 0.4054 - val_recall_5: 0.8047 - val_precision_5: 0.8460 - val_mean_io_u_5: 0.5092 - val_accuracy: 0.9938 - val_auc: 0.9652 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3307 - recall_5: 0.7741 - precision_5: 0.8712 - mean_io_u_5: 0.4978 - accuracy: 0.9939 - auc: 0.9766\n",
      "Epoch 11: val_loss improved from 0.39374 to 0.31471, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.3305 - recall_5: 0.7739 - precision_5: 0.8713 - mean_io_u_5: 0.4978 - accuracy: 0.9939 - auc: 0.9766 - val_loss: 0.3147 - val_recall_5: 0.7831 - val_precision_5: 0.8762 - val_mean_io_u_5: 0.5038 - val_accuracy: 0.9941 - val_auc: 0.9797 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2957 - recall_5: 0.7741 - precision_5: 0.8770 - mean_io_u_5: 0.4988 - accuracy: 0.9940 - auc: 0.9808\n",
      "Epoch 12: val_loss did not improve from 0.31471\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.2956 - recall_5: 0.7741 - precision_5: 0.8770 - mean_io_u_5: 0.4988 - accuracy: 0.9940 - auc: 0.9807 - val_loss: 0.3339 - val_recall_5: 0.8303 - val_precision_5: 0.8534 - val_mean_io_u_5: 0.5213 - val_accuracy: 0.9944 - val_auc: 0.9839 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2699 - recall_5: 0.7854 - precision_5: 0.8807 - mean_io_u_5: 0.4999 - accuracy: 0.9942 - auc: 0.9853\n",
      "Epoch 13: val_loss improved from 0.31471 to 0.30798, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.2698 - recall_5: 0.7853 - precision_5: 0.8808 - mean_io_u_5: 0.4999 - accuracy: 0.9942 - auc: 0.9852 - val_loss: 0.3080 - val_recall_5: 0.8102 - val_precision_5: 0.8601 - val_mean_io_u_5: 0.5122 - val_accuracy: 0.9942 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2526 - recall_5: 0.7971 - precision_5: 0.8823 - mean_io_u_5: 0.4991 - accuracy: 0.9944 - auc: 0.9875\n",
      "Epoch 14: val_loss improved from 0.30798 to 0.24251, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.2526 - recall_5: 0.7971 - precision_5: 0.8823 - mean_io_u_5: 0.4991 - accuracy: 0.9944 - auc: 0.9875 - val_loss: 0.2425 - val_recall_5: 0.8093 - val_precision_5: 0.8881 - val_mean_io_u_5: 0.5127 - val_accuracy: 0.9947 - val_auc: 0.9883 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2368 - recall_5: 0.7995 - precision_5: 0.8853 - mean_io_u_5: 0.4990 - accuracy: 0.9945 - auc: 0.9890\n",
      "Epoch 15: val_loss did not improve from 0.24251\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2368 - recall_5: 0.7995 - precision_5: 0.8853 - mean_io_u_5: 0.4990 - accuracy: 0.9945 - auc: 0.9890 - val_loss: 0.2447 - val_recall_5: 0.8234 - val_precision_5: 0.8799 - val_mean_io_u_5: 0.5049 - val_accuracy: 0.9948 - val_auc: 0.9868 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2249 - recall_5: 0.8074 - precision_5: 0.8879 - mean_io_u_5: 0.4984 - accuracy: 0.9947 - auc: 0.9909\n",
      "Epoch 16: val_loss did not improve from 0.24251\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.2250 - recall_5: 0.8076 - precision_5: 0.8878 - mean_io_u_5: 0.4984 - accuracy: 0.9947 - auc: 0.9909 - val_loss: 0.2655 - val_recall_5: 0.8404 - val_precision_5: 0.8646 - val_mean_io_u_5: 0.5087 - val_accuracy: 0.9947 - val_auc: 0.9924 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2126 - recall_5: 0.8168 - precision_5: 0.8913 - mean_io_u_5: 0.4986 - accuracy: 0.9949 - auc: 0.9925\n",
      "Epoch 17: val_loss did not improve from 0.24251\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.2126 - recall_5: 0.8169 - precision_5: 0.8914 - mean_io_u_5: 0.4986 - accuracy: 0.9949 - auc: 0.9926 - val_loss: 0.2568 - val_recall_5: 0.8279 - val_precision_5: 0.8685 - val_mean_io_u_5: 0.5067 - val_accuracy: 0.9946 - val_auc: 0.9895 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2049 - recall_5: 0.8235 - precision_5: 0.8927 - mean_io_u_5: 0.4982 - accuracy: 0.9950 - auc: 0.9941\n",
      "Epoch 18: val_loss improved from 0.24251 to 0.19881, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.2049 - recall_5: 0.8235 - precision_5: 0.8928 - mean_io_u_5: 0.4982 - accuracy: 0.9950 - auc: 0.9941 - val_loss: 0.1988 - val_recall_5: 0.8370 - val_precision_5: 0.9002 - val_mean_io_u_5: 0.5043 - val_accuracy: 0.9954 - val_auc: 0.9936 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1965 - recall_5: 0.8318 - precision_5: 0.8959 - mean_io_u_5: 0.4976 - accuracy: 0.9952 - auc: 0.9950\n",
      "Epoch 19: val_loss did not improve from 0.19881\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1965 - recall_5: 0.8318 - precision_5: 0.8959 - mean_io_u_5: 0.4976 - accuracy: 0.9952 - auc: 0.9950 - val_loss: 0.2336 - val_recall_5: 0.8291 - val_precision_5: 0.8799 - val_mean_io_u_5: 0.5014 - val_accuracy: 0.9949 - val_auc: 0.9902 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1920 - recall_5: 0.8316 - precision_5: 0.8970 - mean_io_u_5: 0.4969 - accuracy: 0.9952 - auc: 0.9952\n",
      "Epoch 20: val_loss improved from 0.19881 to 0.19176, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.1920 - recall_5: 0.8316 - precision_5: 0.8970 - mean_io_u_5: 0.4969 - accuracy: 0.9952 - auc: 0.9952 - val_loss: 0.1918 - val_recall_5: 0.8414 - val_precision_5: 0.8974 - val_mean_io_u_5: 0.5041 - val_accuracy: 0.9954 - val_auc: 0.9935 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1890 - recall_5: 0.8355 - precision_5: 0.8970 - mean_io_u_5: 0.4953 - accuracy: 0.9953 - auc: 0.9959\n",
      "Epoch 21: val_loss did not improve from 0.19176\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1890 - recall_5: 0.8355 - precision_5: 0.8970 - mean_io_u_5: 0.4953 - accuracy: 0.9953 - auc: 0.9959 - val_loss: 0.2205 - val_recall_5: 0.8408 - val_precision_5: 0.8850 - val_mean_io_u_5: 0.5008 - val_accuracy: 0.9952 - val_auc: 0.9930 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1836 - recall_5: 0.8388 - precision_5: 0.8989 - mean_io_u_5: 0.4961 - accuracy: 0.9954 - auc: 0.9962\n",
      "Epoch 22: val_loss improved from 0.19176 to 0.17716, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.1836 - recall_5: 0.8388 - precision_5: 0.8989 - mean_io_u_5: 0.4961 - accuracy: 0.9954 - auc: 0.9962 - val_loss: 0.1772 - val_recall_5: 0.8354 - val_precision_5: 0.9043 - val_mean_io_u_5: 0.4974 - val_accuracy: 0.9954 - val_auc: 0.9948 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1807 - recall_5: 0.8453 - precision_5: 0.9000 - mean_io_u_5: 0.4954 - accuracy: 0.9955 - auc: 0.9967\n",
      "Epoch 23: val_loss did not improve from 0.17716\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1807 - recall_5: 0.8454 - precision_5: 0.8999 - mean_io_u_5: 0.4954 - accuracy: 0.9955 - auc: 0.9967 - val_loss: 0.2296 - val_recall_5: 0.8555 - val_precision_5: 0.8770 - val_mean_io_u_5: 0.5009 - val_accuracy: 0.9952 - val_auc: 0.9949 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1744 - recall_5: 0.8490 - precision_5: 0.9029 - mean_io_u_5: 0.4962 - accuracy: 0.9956 - auc: 0.9972\n",
      "Epoch 24: val_loss did not improve from 0.17716\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.1744 - recall_5: 0.8490 - precision_5: 0.9029 - mean_io_u_5: 0.4962 - accuracy: 0.9956 - auc: 0.9972 - val_loss: 0.1896 - val_recall_5: 0.8506 - val_precision_5: 0.8978 - val_mean_io_u_5: 0.4965 - val_accuracy: 0.9956 - val_auc: 0.9931 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1722 - recall_5: 0.8535 - precision_5: 0.9037 - mean_io_u_5: 0.4960 - accuracy: 0.9957 - auc: 0.9972\n",
      "Epoch 25: val_loss did not improve from 0.17716\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1721 - recall_5: 0.8535 - precision_5: 0.9038 - mean_io_u_5: 0.4960 - accuracy: 0.9957 - auc: 0.9972 - val_loss: 0.1786 - val_recall_5: 0.8528 - val_precision_5: 0.9007 - val_mean_io_u_5: 0.5033 - val_accuracy: 0.9957 - val_auc: 0.9959 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1662 - recall_5: 0.8588 - precision_5: 0.9067 - mean_io_u_5: 0.4972 - accuracy: 0.9959 - auc: 0.9972\n",
      "Epoch 26: val_loss did not improve from 0.17716\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1662 - recall_5: 0.8588 - precision_5: 0.9067 - mean_io_u_5: 0.4972 - accuracy: 0.9959 - auc: 0.9972 - val_loss: 0.1939 - val_recall_5: 0.8508 - val_precision_5: 0.8949 - val_mean_io_u_5: 0.5008 - val_accuracy: 0.9955 - val_auc: 0.9947 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1642 - recall_5: 0.8606 - precision_5: 0.9075 - mean_io_u_5: 0.4976 - accuracy: 0.9959 - auc: 0.9975\n",
      "Epoch 27: val_loss improved from 0.17716 to 0.17042, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.1642 - recall_5: 0.8606 - precision_5: 0.9075 - mean_io_u_5: 0.4976 - accuracy: 0.9959 - auc: 0.9975 - val_loss: 0.1704 - val_recall_5: 0.8616 - val_precision_5: 0.9077 - val_mean_io_u_5: 0.5009 - val_accuracy: 0.9959 - val_auc: 0.9965 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1602 - recall_5: 0.8620 - precision_5: 0.9097 - mean_io_u_5: 0.4978 - accuracy: 0.9960 - auc: 0.9979\n",
      "Epoch 28: val_loss did not improve from 0.17042\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1602 - recall_5: 0.8620 - precision_5: 0.9097 - mean_io_u_5: 0.4978 - accuracy: 0.9960 - auc: 0.9979 - val_loss: 0.1977 - val_recall_5: 0.8658 - val_precision_5: 0.8879 - val_mean_io_u_5: 0.5023 - val_accuracy: 0.9956 - val_auc: 0.9965 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1588 - recall_5: 0.8639 - precision_5: 0.9099 - mean_io_u_5: 0.4980 - accuracy: 0.9960 - auc: 0.9980\n",
      "Epoch 29: val_loss improved from 0.17042 to 0.16043, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 311ms/step - loss: 0.1588 - recall_5: 0.8639 - precision_5: 0.9099 - mean_io_u_5: 0.4980 - accuracy: 0.9960 - auc: 0.9980 - val_loss: 0.1604 - val_recall_5: 0.8647 - val_precision_5: 0.9101 - val_mean_io_u_5: 0.5003 - val_accuracy: 0.9960 - val_auc: 0.9980 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1567 - recall_5: 0.8670 - precision_5: 0.9107 - mean_io_u_5: 0.4980 - accuracy: 0.9961 - auc: 0.9979\n",
      "Epoch 30: val_loss did not improve from 0.16043\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1567 - recall_5: 0.8670 - precision_5: 0.9107 - mean_io_u_5: 0.4980 - accuracy: 0.9961 - auc: 0.9979 - val_loss: 0.1654 - val_recall_5: 0.8642 - val_precision_5: 0.9084 - val_mean_io_u_5: 0.5043 - val_accuracy: 0.9960 - val_auc: 0.9972 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1539 - recall_5: 0.8677 - precision_5: 0.9124 - mean_io_u_5: 0.4988 - accuracy: 0.9961 - auc: 0.9979\n",
      "Epoch 31: val_loss did not improve from 0.16043\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1539 - recall_5: 0.8677 - precision_5: 0.9124 - mean_io_u_5: 0.4988 - accuracy: 0.9961 - auc: 0.9979 - val_loss: 0.1756 - val_recall_5: 0.8639 - val_precision_5: 0.9058 - val_mean_io_u_5: 0.5063 - val_accuracy: 0.9959 - val_auc: 0.9947 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1518 - recall_5: 0.8714 - precision_5: 0.9133 - mean_io_u_5: 0.4995 - accuracy: 0.9962 - auc: 0.9981\n",
      "Epoch 32: val_loss did not improve from 0.16043\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1518 - recall_5: 0.8715 - precision_5: 0.9132 - mean_io_u_5: 0.4995 - accuracy: 0.9962 - auc: 0.9981 - val_loss: 0.1779 - val_recall_5: 0.8640 - val_precision_5: 0.9024 - val_mean_io_u_5: 0.5054 - val_accuracy: 0.9959 - val_auc: 0.9943 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1493 - recall_5: 0.8721 - precision_5: 0.9147 - mean_io_u_5: 0.5003 - accuracy: 0.9962 - auc: 0.9980\n",
      "Epoch 33: val_loss did not improve from 0.16043\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1493 - recall_5: 0.8721 - precision_5: 0.9147 - mean_io_u_5: 0.5003 - accuracy: 0.9962 - auc: 0.9980 - val_loss: 0.1823 - val_recall_5: 0.8609 - val_precision_5: 0.9028 - val_mean_io_u_5: 0.5066 - val_accuracy: 0.9958 - val_auc: 0.9950 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1469 - recall_5: 0.8750 - precision_5: 0.9157 - mean_io_u_5: 0.5009 - accuracy: 0.9963 - auc: 0.9981\n",
      "Epoch 34: val_loss did not improve from 0.16043\n",
      "\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1470 - recall_5: 0.8750 - precision_5: 0.9156 - mean_io_u_5: 0.5009 - accuracy: 0.9963 - auc: 0.9981 - val_loss: 0.1615 - val_recall_5: 0.8581 - val_precision_5: 0.9096 - val_mean_io_u_5: 0.5040 - val_accuracy: 0.9959 - val_auc: 0.9969 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1428 - recall_5: 0.8837 - precision_5: 0.9173 - mean_io_u_5: 0.5015 - accuracy: 0.9965 - auc: 0.9985\n",
      "Epoch 35: val_loss improved from 0.16043 to 0.15165, saving model to ./iter_wBCE-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wBCE-40.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.1428 - recall_5: 0.8837 - precision_5: 0.9173 - mean_io_u_5: 0.5015 - accuracy: 0.9965 - auc: 0.9985 - val_loss: 0.1516 - val_recall_5: 0.8846 - val_precision_5: 0.9140 - val_mean_io_u_5: 0.5050 - val_accuracy: 0.9964 - val_auc: 0.9983 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1408 - recall_5: 0.8861 - precision_5: 0.9184 - mean_io_u_5: 0.5031 - accuracy: 0.9965 - auc: 0.9986\n",
      "Epoch 36: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1408 - recall_5: 0.8861 - precision_5: 0.9184 - mean_io_u_5: 0.5031 - accuracy: 0.9965 - auc: 0.9986 - val_loss: 0.1542 - val_recall_5: 0.8811 - val_precision_5: 0.9154 - val_mean_io_u_5: 0.5053 - val_accuracy: 0.9964 - val_auc: 0.9972 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1391 - recall_5: 0.8856 - precision_5: 0.9197 - mean_io_u_5: 0.5038 - accuracy: 0.9965 - auc: 0.9986\n",
      "Epoch 37: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1391 - recall_5: 0.8855 - precision_5: 0.9197 - mean_io_u_5: 0.5038 - accuracy: 0.9965 - auc: 0.9986 - val_loss: 0.1603 - val_recall_5: 0.8844 - val_precision_5: 0.9115 - val_mean_io_u_5: 0.5062 - val_accuracy: 0.9964 - val_auc: 0.9969 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1388 - recall_5: 0.8866 - precision_5: 0.9199 - mean_io_u_5: 0.5048 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 38: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.1387 - recall_5: 0.8867 - precision_5: 0.9199 - mean_io_u_5: 0.5048 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1542 - val_recall_5: 0.8834 - val_precision_5: 0.9152 - val_mean_io_u_5: 0.5075 - val_accuracy: 0.9964 - val_auc: 0.9972 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1377 - recall_5: 0.8860 - precision_5: 0.9205 - mean_io_u_5: 0.5049 - accuracy: 0.9966 - auc: 0.9985\n",
      "Epoch 39: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.1377 - recall_5: 0.8860 - precision_5: 0.9205 - mean_io_u_5: 0.5049 - accuracy: 0.9966 - auc: 0.9985 - val_loss: 0.1566 - val_recall_5: 0.8826 - val_precision_5: 0.9146 - val_mean_io_u_5: 0.5075 - val_accuracy: 0.9964 - val_auc: 0.9968 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1371 - recall_5: 0.8861 - precision_5: 0.9209 - mean_io_u_5: 0.5053 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 40: val_loss did not improve from 0.15165\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.1371 - recall_5: 0.8861 - precision_5: 0.9209 - mean_io_u_5: 0.5053 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1571 - val_recall_5: 0.8824 - val_precision_5: 0.9140 - val_mean_io_u_5: 0.5076 - val_accuracy: 0.9964 - val_auc: 0.9970 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1357 - recall_5: 0.8868 - precision_5: 0.9219 - mean_io_u_5: 0.5049 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 41: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 199ms/step - loss: 0.1358 - recall_5: 0.8867 - precision_5: 0.9219 - mean_io_u_5: 0.5049 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1581 - val_recall_5: 0.8829 - val_precision_5: 0.9132 - val_mean_io_u_5: 0.5078 - val_accuracy: 0.9964 - val_auc: 0.9969 - lr: 1.0000e-05\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1363 - recall_5: 0.8875 - precision_5: 0.9214 - mean_io_u_5: 0.5052 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 42: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.1363 - recall_5: 0.8874 - precision_5: 0.9213 - mean_io_u_5: 0.5052 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1594 - val_recall_5: 0.8821 - val_precision_5: 0.9125 - val_mean_io_u_5: 0.5081 - val_accuracy: 0.9963 - val_auc: 0.9968 - lr: 1.0000e-05\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1363 - recall_5: 0.8877 - precision_5: 0.9214 - mean_io_u_5: 0.5054 - accuracy: 0.9966 - auc: 0.9987\n",
      "Epoch 43: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 200ms/step - loss: 0.1363 - recall_5: 0.8877 - precision_5: 0.9214 - mean_io_u_5: 0.5054 - accuracy: 0.9966 - auc: 0.9987 - val_loss: 0.1589 - val_recall_5: 0.8809 - val_precision_5: 0.9126 - val_mean_io_u_5: 0.5080 - val_accuracy: 0.9963 - val_auc: 0.9967 - lr: 1.0000e-05\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1357 - recall_5: 0.8873 - precision_5: 0.9217 - mean_io_u_5: 0.5054 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 44: val_loss did not improve from 0.15165\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1356 - recall_5: 0.8873 - precision_5: 0.9218 - mean_io_u_5: 0.5054 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1589 - val_recall_5: 0.8824 - val_precision_5: 0.9126 - val_mean_io_u_5: 0.5085 - val_accuracy: 0.9964 - val_auc: 0.9968 - lr: 1.0000e-05\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1359 - recall_5: 0.8878 - precision_5: 0.9217 - mean_io_u_5: 0.5057 - accuracy: 0.9966 - auc: 0.9986\n",
      "Epoch 45: val_loss did not improve from 0.15165\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.1359 - recall_5: 0.8877 - precision_5: 0.9217 - mean_io_u_5: 0.5057 - accuracy: 0.9966 - auc: 0.9986 - val_loss: 0.1590 - val_recall_5: 0.8824 - val_precision_5: 0.9124 - val_mean_io_u_5: 0.5088 - val_accuracy: 0.9964 - val_auc: 0.9968 - lr: 1.0000e-05\n",
      "Epoch 45: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f04a41668b0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.8556 - recall_6: 0.9771 - precision_6: 0.0855 - mean_io_u_6: 0.5441 - accuracy: 0.8112 - auc: 0.9252\n",
      "Epoch 1: val_loss improved from inf to 0.81842, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 25s 335ms/step - loss: 0.8556 - recall_6: 0.9771 - precision_6: 0.0855 - mean_io_u_6: 0.5441 - accuracy: 0.8112 - auc: 0.9252 - val_loss: 0.8184 - val_recall_6: 0.3025 - val_precision_6: 0.1411 - val_mean_io_u_6: 0.4912 - val_accuracy: 0.9542 - val_auc: 0.7703 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.7116 - recall_6: 0.9841 - precision_6: 0.2273 - mean_io_u_6: 0.6014 - accuracy: 0.9394 - auc: 0.9629\n",
      "Epoch 2: val_loss did not improve from 0.81842\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.7113 - recall_6: 0.9840 - precision_6: 0.2274 - mean_io_u_6: 0.6016 - accuracy: 0.9395 - auc: 0.9629 - val_loss: 0.9649 - val_recall_6: 0.4340 - val_precision_6: 0.0175 - val_mean_io_u_6: 0.4925 - val_accuracy: 0.5507 - val_auc: 0.5230 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5290 - recall_6: 0.9624 - precision_6: 0.3785 - mean_io_u_6: 0.6911 - accuracy: 0.9708 - auc: 0.9620\n",
      "Epoch 3: val_loss did not improve from 0.81842\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.5290 - recall_6: 0.9624 - precision_6: 0.3785 - mean_io_u_6: 0.6911 - accuracy: 0.9708 - auc: 0.9620 - val_loss: 0.9905 - val_recall_6: 0.1974 - val_precision_6: 0.0048 - val_mean_io_u_6: 0.1571 - val_accuracy: 0.2536 - val_auc: 0.2126 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3711 - recall_6: 0.9186 - precision_6: 0.5350 - mean_io_u_6: 0.7516 - accuracy: 0.9841 - auc: 0.9532\n",
      "Epoch 4: val_loss did not improve from 0.81842\n",
      "65/65 [==============================] - 13s 201ms/step - loss: 0.3709 - recall_6: 0.9186 - precision_6: 0.5352 - mean_io_u_6: 0.7517 - accuracy: 0.9842 - auc: 0.9532 - val_loss: 0.9944 - val_recall_6: 0.1092 - val_precision_6: 0.0029 - val_mean_io_u_6: 0.1619 - val_accuracy: 0.3030 - val_auc: 0.1989 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3041 - recall_6: 0.8876 - precision_6: 0.6033 - mean_io_u_6: 0.7677 - accuracy: 0.9875 - auc: 0.9461\n",
      "Epoch 5: val_loss improved from 0.81842 to 0.51114, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.3042 - recall_6: 0.8875 - precision_6: 0.6033 - mean_io_u_6: 0.7677 - accuracy: 0.9875 - auc: 0.9460 - val_loss: 0.5111 - val_recall_6: 0.4219 - val_precision_6: 0.5813 - val_mean_io_u_6: 0.6430 - val_accuracy: 0.9841 - val_auc: 0.7265 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2823 - recall_6: 0.8775 - precision_6: 0.6258 - mean_io_u_6: 0.7750 - accuracy: 0.9883 - auc: 0.9423\n",
      "Epoch 6: val_loss improved from 0.51114 to 0.34912, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 0.2822 - recall_6: 0.8775 - precision_6: 0.6258 - mean_io_u_6: 0.7750 - accuracy: 0.9883 - auc: 0.9423 - val_loss: 0.3491 - val_recall_6: 0.6607 - val_precision_6: 0.6409 - val_mean_io_u_6: 0.7087 - val_accuracy: 0.9872 - val_auc: 0.8465 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2725 - recall_6: 0.8751 - precision_6: 0.6347 - mean_io_u_6: 0.7803 - accuracy: 0.9887 - auc: 0.9409\n",
      "Epoch 7: val_loss improved from 0.34912 to 0.28503, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.2725 - recall_6: 0.8751 - precision_6: 0.6347 - mean_io_u_6: 0.7803 - accuracy: 0.9887 - auc: 0.9409 - val_loss: 0.2850 - val_recall_6: 0.7938 - val_precision_6: 0.6509 - val_mean_io_u_6: 0.7410 - val_accuracy: 0.9886 - val_auc: 0.9076 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2668 - recall_6: 0.8726 - precision_6: 0.6410 - mean_io_u_6: 0.7836 - accuracy: 0.9889 - auc: 0.9395\n",
      "Epoch 8: val_loss did not improve from 0.28503\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 0.2668 - recall_6: 0.8726 - precision_6: 0.6410 - mean_io_u_6: 0.7836 - accuracy: 0.9889 - auc: 0.9395 - val_loss: 0.3135 - val_recall_6: 0.7220 - val_precision_6: 0.6548 - val_mean_io_u_6: 0.7191 - val_accuracy: 0.9881 - val_auc: 0.8762 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2631 - recall_6: 0.8686 - precision_6: 0.6466 - mean_io_u_6: 0.7853 - accuracy: 0.9891 - auc: 0.9374\n",
      "Epoch 9: val_loss improved from 0.28503 to 0.26225, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.2631 - recall_6: 0.8687 - precision_6: 0.6467 - mean_io_u_6: 0.7854 - accuracy: 0.9891 - auc: 0.9375 - val_loss: 0.2623 - val_recall_6: 0.8357 - val_precision_6: 0.6605 - val_mean_io_u_6: 0.7734 - val_accuracy: 0.9893 - val_auc: 0.9213 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2591 - recall_6: 0.8697 - precision_6: 0.6503 - mean_io_u_6: 0.7874 - accuracy: 0.9892 - auc: 0.9377\n",
      "Epoch 10: val_loss improved from 0.26225 to 0.24965, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 317ms/step - loss: 0.2591 - recall_6: 0.8698 - precision_6: 0.6504 - mean_io_u_6: 0.7874 - accuracy: 0.9892 - auc: 0.9377 - val_loss: 0.2496 - val_recall_6: 0.8513 - val_precision_6: 0.6711 - val_mean_io_u_6: 0.7843 - val_accuracy: 0.9898 - val_auc: 0.9290 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2553 - recall_6: 0.8725 - precision_6: 0.6537 - mean_io_u_6: 0.7894 - accuracy: 0.9894 - auc: 0.9391\n",
      "Epoch 11: val_loss did not improve from 0.24965\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2553 - recall_6: 0.8725 - precision_6: 0.6537 - mean_io_u_6: 0.7894 - accuracy: 0.9894 - auc: 0.9391 - val_loss: 0.2718 - val_recall_6: 0.7871 - val_precision_6: 0.6778 - val_mean_io_u_6: 0.7593 - val_accuracy: 0.9894 - val_auc: 0.9011 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2552 - recall_6: 0.8704 - precision_6: 0.6544 - mean_io_u_6: 0.7897 - accuracy: 0.9894 - auc: 0.9374\n",
      "Epoch 12: val_loss did not improve from 0.24965\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2552 - recall_6: 0.8704 - precision_6: 0.6544 - mean_io_u_6: 0.7897 - accuracy: 0.9894 - auc: 0.9374 - val_loss: 0.2539 - val_recall_6: 0.8469 - val_precision_6: 0.6670 - val_mean_io_u_6: 0.7800 - val_accuracy: 0.9896 - val_auc: 0.9272 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2516 - recall_6: 0.8707 - precision_6: 0.6592 - mean_io_u_6: 0.7913 - accuracy: 0.9896 - auc: 0.9380\n",
      "Epoch 13: val_loss improved from 0.24965 to 0.24537, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.2516 - recall_6: 0.8707 - precision_6: 0.6592 - mean_io_u_6: 0.7913 - accuracy: 0.9896 - auc: 0.9380 - val_loss: 0.2454 - val_recall_6: 0.8623 - val_precision_6: 0.6712 - val_mean_io_u_6: 0.7897 - val_accuracy: 0.9899 - val_auc: 0.9346 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2504 - recall_6: 0.8702 - precision_6: 0.6608 - mean_io_u_6: 0.7919 - accuracy: 0.9896 - auc: 0.9376\n",
      "Epoch 14: val_loss did not improve from 0.24537\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2505 - recall_6: 0.8701 - precision_6: 0.6607 - mean_io_u_6: 0.7918 - accuracy: 0.9896 - auc: 0.9375 - val_loss: 0.2500 - val_recall_6: 0.8720 - val_precision_6: 0.6582 - val_mean_io_u_6: 0.7904 - val_accuracy: 0.9895 - val_auc: 0.9371 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2473 - recall_6: 0.8738 - precision_6: 0.6633 - mean_io_u_6: 0.7938 - accuracy: 0.9897 - auc: 0.9394\n",
      "Epoch 15: val_loss did not improve from 0.24537\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2473 - recall_6: 0.8738 - precision_6: 0.6633 - mean_io_u_6: 0.7938 - accuracy: 0.9897 - auc: 0.9394 - val_loss: 0.2547 - val_recall_6: 0.8387 - val_precision_6: 0.6711 - val_mean_io_u_6: 0.7833 - val_accuracy: 0.9897 - val_auc: 0.9234 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2465 - recall_6: 0.8743 - precision_6: 0.6638 - mean_io_u_6: 0.7941 - accuracy: 0.9898 - auc: 0.9397\n",
      "Epoch 16: val_loss did not improve from 0.24537\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2465 - recall_6: 0.8743 - precision_6: 0.6638 - mean_io_u_6: 0.7941 - accuracy: 0.9898 - auc: 0.9397 - val_loss: 0.2500 - val_recall_6: 0.8416 - val_precision_6: 0.6767 - val_mean_io_u_6: 0.7868 - val_accuracy: 0.9899 - val_auc: 0.9241 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2434 - recall_6: 0.8749 - precision_6: 0.6682 - mean_io_u_6: 0.7961 - accuracy: 0.9899 - auc: 0.9403\n",
      "Epoch 17: val_loss improved from 0.24537 to 0.23826, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.2434 - recall_6: 0.8749 - precision_6: 0.6682 - mean_io_u_6: 0.7961 - accuracy: 0.9899 - auc: 0.9403 - val_loss: 0.2383 - val_recall_6: 0.8585 - val_precision_6: 0.6850 - val_mean_io_u_6: 0.7958 - val_accuracy: 0.9903 - val_auc: 0.9328 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2405 - recall_6: 0.8784 - precision_6: 0.6706 - mean_io_u_6: 0.7979 - accuracy: 0.9900 - auc: 0.9419\n",
      "Epoch 18: val_loss improved from 0.23826 to 0.23366, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.2405 - recall_6: 0.8784 - precision_6: 0.6706 - mean_io_u_6: 0.7979 - accuracy: 0.9900 - auc: 0.9419 - val_loss: 0.2337 - val_recall_6: 0.8842 - val_precision_6: 0.6767 - val_mean_io_u_6: 0.8021 - val_accuracy: 0.9903 - val_auc: 0.9445 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2374 - recall_6: 0.8819 - precision_6: 0.6733 - mean_io_u_6: 0.7997 - accuracy: 0.9902 - auc: 0.9439\n",
      "Epoch 19: val_loss did not improve from 0.23366\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2374 - recall_6: 0.8819 - precision_6: 0.6733 - mean_io_u_6: 0.7997 - accuracy: 0.9902 - auc: 0.9439 - val_loss: 0.2352 - val_recall_6: 0.8707 - val_precision_6: 0.6825 - val_mean_io_u_6: 0.8007 - val_accuracy: 0.9904 - val_auc: 0.9377 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2366 - recall_6: 0.8801 - precision_6: 0.6754 - mean_io_u_6: 0.8001 - accuracy: 0.9902 - auc: 0.9430\n",
      "Epoch 20: val_loss did not improve from 0.23366\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2365 - recall_6: 0.8802 - precision_6: 0.6755 - mean_io_u_6: 0.8001 - accuracy: 0.9902 - auc: 0.9430 - val_loss: 0.2461 - val_recall_6: 0.8509 - val_precision_6: 0.6775 - val_mean_io_u_6: 0.7914 - val_accuracy: 0.9900 - val_auc: 0.9290 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2340 - recall_6: 0.8844 - precision_6: 0.6768 - mean_io_u_6: 0.8021 - accuracy: 0.9903 - auc: 0.9448\n",
      "Epoch 21: val_loss did not improve from 0.23366\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2340 - recall_6: 0.8844 - precision_6: 0.6768 - mean_io_u_6: 0.8021 - accuracy: 0.9903 - auc: 0.9448 - val_loss: 0.2358 - val_recall_6: 0.8587 - val_precision_6: 0.6886 - val_mean_io_u_6: 0.7980 - val_accuracy: 0.9904 - val_auc: 0.9323 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2314 - recall_6: 0.8854 - precision_6: 0.6802 - mean_io_u_6: 0.8036 - accuracy: 0.9904 - auc: 0.9452\n",
      "Epoch 22: val_loss improved from 0.23366 to 0.22893, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.2314 - recall_6: 0.8854 - precision_6: 0.6802 - mean_io_u_6: 0.8036 - accuracy: 0.9904 - auc: 0.9452 - val_loss: 0.2289 - val_recall_6: 0.8812 - val_precision_6: 0.6857 - val_mean_io_u_6: 0.8031 - val_accuracy: 0.9906 - val_auc: 0.9435 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2307 - recall_6: 0.8866 - precision_6: 0.6804 - mean_io_u_6: 0.8043 - accuracy: 0.9905 - auc: 0.9457\n",
      "Epoch 23: val_loss improved from 0.22893 to 0.22852, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.2307 - recall_6: 0.8867 - precision_6: 0.6805 - mean_io_u_6: 0.8044 - accuracy: 0.9905 - auc: 0.9457 - val_loss: 0.2285 - val_recall_6: 0.8874 - val_precision_6: 0.6826 - val_mean_io_u_6: 0.8058 - val_accuracy: 0.9905 - val_auc: 0.9449 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2278 - recall_6: 0.8894 - precision_6: 0.6833 - mean_io_u_6: 0.8063 - accuracy: 0.9906 - auc: 0.9471\n",
      "Epoch 24: val_loss improved from 0.22852 to 0.22520, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.2278 - recall_6: 0.8894 - precision_6: 0.6833 - mean_io_u_6: 0.8063 - accuracy: 0.9906 - auc: 0.9471 - val_loss: 0.2252 - val_recall_6: 0.8965 - val_precision_6: 0.6824 - val_mean_io_u_6: 0.8089 - val_accuracy: 0.9906 - val_auc: 0.9500 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2256 - recall_6: 0.8937 - precision_6: 0.6842 - mean_io_u_6: 0.8080 - accuracy: 0.9907 - auc: 0.9493\n",
      "Epoch 25: val_loss did not improve from 0.22520\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2257 - recall_6: 0.8936 - precision_6: 0.6841 - mean_io_u_6: 0.8079 - accuracy: 0.9906 - auc: 0.9493 - val_loss: 0.2334 - val_recall_6: 0.8594 - val_precision_6: 0.6922 - val_mean_io_u_6: 0.7989 - val_accuracy: 0.9906 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2229 - recall_6: 0.8945 - precision_6: 0.6878 - mean_io_u_6: 0.8092 - accuracy: 0.9908 - auc: 0.9501\n",
      "Epoch 26: val_loss did not improve from 0.22520\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2229 - recall_6: 0.8945 - precision_6: 0.6878 - mean_io_u_6: 0.8092 - accuracy: 0.9908 - auc: 0.9501 - val_loss: 0.2624 - val_recall_6: 0.8166 - val_precision_6: 0.6728 - val_mean_io_u_6: 0.7812 - val_accuracy: 0.9895 - val_auc: 0.9103 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2213 - recall_6: 0.8974 - precision_6: 0.6885 - mean_io_u_6: 0.8110 - accuracy: 0.9908 - auc: 0.9509\n",
      "Epoch 27: val_loss improved from 0.22520 to 0.22424, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.2213 - recall_6: 0.8974 - precision_6: 0.6886 - mean_io_u_6: 0.8111 - accuracy: 0.9908 - auc: 0.9509 - val_loss: 0.2242 - val_recall_6: 0.8717 - val_precision_6: 0.6990 - val_mean_io_u_6: 0.8062 - val_accuracy: 0.9909 - val_auc: 0.9382 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2205 - recall_6: 0.8950 - precision_6: 0.6913 - mean_io_u_6: 0.8111 - accuracy: 0.9909 - auc: 0.9499\n",
      "Epoch 28: val_loss did not improve from 0.22424\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2204 - recall_6: 0.8950 - precision_6: 0.6913 - mean_io_u_6: 0.8111 - accuracy: 0.9909 - auc: 0.9499 - val_loss: 0.2692 - val_recall_6: 0.8003 - val_precision_6: 0.6725 - val_mean_io_u_6: 0.7741 - val_accuracy: 0.9894 - val_auc: 0.9039 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2166 - recall_6: 0.8997 - precision_6: 0.6945 - mean_io_u_6: 0.8139 - accuracy: 0.9911 - auc: 0.9523\n",
      "Epoch 29: val_loss improved from 0.22424 to 0.21668, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.2166 - recall_6: 0.8997 - precision_6: 0.6945 - mean_io_u_6: 0.8139 - accuracy: 0.9911 - auc: 0.9523 - val_loss: 0.2167 - val_recall_6: 0.8830 - val_precision_6: 0.7040 - val_mean_io_u_6: 0.8123 - val_accuracy: 0.9912 - val_auc: 0.9437 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2140 - recall_6: 0.9010 - precision_6: 0.6977 - mean_io_u_6: 0.8154 - accuracy: 0.9912 - auc: 0.9530\n",
      "Epoch 30: val_loss did not improve from 0.21668\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2140 - recall_6: 0.9010 - precision_6: 0.6977 - mean_io_u_6: 0.8154 - accuracy: 0.9912 - auc: 0.9530 - val_loss: 0.2224 - val_recall_6: 0.8762 - val_precision_6: 0.6991 - val_mean_io_u_6: 0.8074 - val_accuracy: 0.9910 - val_auc: 0.9405 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2136 - recall_6: 0.9010 - precision_6: 0.6983 - mean_io_u_6: 0.8157 - accuracy: 0.9912 - auc: 0.9530\n",
      "Epoch 31: val_loss did not improve from 0.21668\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2136 - recall_6: 0.9011 - precision_6: 0.6983 - mean_io_u_6: 0.8157 - accuracy: 0.9912 - auc: 0.9530 - val_loss: 0.2210 - val_recall_6: 0.8760 - val_precision_6: 0.7014 - val_mean_io_u_6: 0.8081 - val_accuracy: 0.9910 - val_auc: 0.9405 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2132 - recall_6: 0.9015 - precision_6: 0.6985 - mean_io_u_6: 0.8161 - accuracy: 0.9912 - auc: 0.9529\n",
      "Epoch 32: val_loss did not improve from 0.21668\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2132 - recall_6: 0.9015 - precision_6: 0.6985 - mean_io_u_6: 0.8161 - accuracy: 0.9912 - auc: 0.9530 - val_loss: 0.2173 - val_recall_6: 0.8831 - val_precision_6: 0.7030 - val_mean_io_u_6: 0.8115 - val_accuracy: 0.9912 - val_auc: 0.9442 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2107 - recall_6: 0.9047 - precision_6: 0.7007 - mean_io_u_6: 0.8182 - accuracy: 0.9913 - auc: 0.9546\n",
      "Epoch 33: val_loss improved from 0.21668 to 0.20777, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 318ms/step - loss: 0.2107 - recall_6: 0.9046 - precision_6: 0.7006 - mean_io_u_6: 0.8182 - accuracy: 0.9913 - auc: 0.9546 - val_loss: 0.2078 - val_recall_6: 0.9051 - val_precision_6: 0.7045 - val_mean_io_u_6: 0.8199 - val_accuracy: 0.9914 - val_auc: 0.9541 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2097 - recall_6: 0.9039 - precision_6: 0.7025 - mean_io_u_6: 0.8188 - accuracy: 0.9914 - auc: 0.9540\n",
      "Epoch 34: val_loss did not improve from 0.20777\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2098 - recall_6: 0.9039 - precision_6: 0.7024 - mean_io_u_6: 0.8188 - accuracy: 0.9914 - auc: 0.9540 - val_loss: 0.2170 - val_recall_6: 0.8911 - val_precision_6: 0.6984 - val_mean_io_u_6: 0.8135 - val_accuracy: 0.9911 - val_auc: 0.9468 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2081 - recall_6: 0.9074 - precision_6: 0.7030 - mean_io_u_6: 0.8200 - accuracy: 0.9914 - auc: 0.9556\n",
      "Epoch 35: val_loss did not improve from 0.20777\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2081 - recall_6: 0.9074 - precision_6: 0.7030 - mean_io_u_6: 0.8200 - accuracy: 0.9914 - auc: 0.9556 - val_loss: 0.2360 - val_recall_6: 0.8662 - val_precision_6: 0.6834 - val_mean_io_u_6: 0.8001 - val_accuracy: 0.9904 - val_auc: 0.9347 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2085 - recall_6: 0.9063 - precision_6: 0.7029 - mean_io_u_6: 0.8201 - accuracy: 0.9914 - auc: 0.9549\n",
      "Epoch 36: val_loss did not improve from 0.20777\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2085 - recall_6: 0.9063 - precision_6: 0.7030 - mean_io_u_6: 0.8201 - accuracy: 0.9914 - auc: 0.9549 - val_loss: 0.2159 - val_recall_6: 0.8883 - val_precision_6: 0.7019 - val_mean_io_u_6: 0.8140 - val_accuracy: 0.9912 - val_auc: 0.9457 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2049 - recall_6: 0.9092 - precision_6: 0.7070 - mean_io_u_6: 0.8223 - accuracy: 0.9916 - auc: 0.9565\n",
      "Epoch 37: val_loss improved from 0.20777 to 0.20459, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.2049 - recall_6: 0.9092 - precision_6: 0.7069 - mean_io_u_6: 0.8223 - accuracy: 0.9916 - auc: 0.9564 - val_loss: 0.2046 - val_recall_6: 0.9007 - val_precision_6: 0.7123 - val_mean_io_u_6: 0.8204 - val_accuracy: 0.9917 - val_auc: 0.9525 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2060 - recall_6: 0.9072 - precision_6: 0.7064 - mean_io_u_6: 0.8217 - accuracy: 0.9915 - auc: 0.9554\n",
      "Epoch 38: val_loss did not improve from 0.20459\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2060 - recall_6: 0.9072 - precision_6: 0.7065 - mean_io_u_6: 0.8217 - accuracy: 0.9915 - auc: 0.9554 - val_loss: 0.2152 - val_recall_6: 0.8800 - val_precision_6: 0.7084 - val_mean_io_u_6: 0.8121 - val_accuracy: 0.9913 - val_auc: 0.9422 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2076 - recall_6: 0.9066 - precision_6: 0.7041 - mean_io_u_6: 0.8205 - accuracy: 0.9915 - auc: 0.9551\n",
      "Epoch 39: val_loss did not improve from 0.20459\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2076 - recall_6: 0.9066 - precision_6: 0.7042 - mean_io_u_6: 0.8205 - accuracy: 0.9915 - auc: 0.9551 - val_loss: 0.2081 - val_recall_6: 0.8986 - val_precision_6: 0.7080 - val_mean_io_u_6: 0.8193 - val_accuracy: 0.9915 - val_auc: 0.9507 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2029 - recall_6: 0.9100 - precision_6: 0.7095 - mean_io_u_6: 0.8238 - accuracy: 0.9917 - auc: 0.9567\n",
      "Epoch 40: val_loss did not improve from 0.20459\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2029 - recall_6: 0.9100 - precision_6: 0.7095 - mean_io_u_6: 0.8238 - accuracy: 0.9917 - auc: 0.9567 - val_loss: 0.2070 - val_recall_6: 0.8956 - val_precision_6: 0.7116 - val_mean_io_u_6: 0.8196 - val_accuracy: 0.9916 - val_auc: 0.9495 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2026 - recall_6: 0.9103 - precision_6: 0.7098 - mean_io_u_6: 0.8242 - accuracy: 0.9917 - auc: 0.9569\n",
      "Epoch 41: val_loss improved from 0.20459 to 0.20082, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.2026 - recall_6: 0.9103 - precision_6: 0.7098 - mean_io_u_6: 0.8242 - accuracy: 0.9917 - auc: 0.9569 - val_loss: 0.2008 - val_recall_6: 0.8997 - val_precision_6: 0.7190 - val_mean_io_u_6: 0.8227 - val_accuracy: 0.9919 - val_auc: 0.9523 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2008 - recall_6: 0.9130 - precision_6: 0.7109 - mean_io_u_6: 0.8256 - accuracy: 0.9917 - auc: 0.9580\n",
      "Epoch 42: val_loss did not improve from 0.20082\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2009 - recall_6: 0.9130 - precision_6: 0.7109 - mean_io_u_6: 0.8256 - accuracy: 0.9917 - auc: 0.9580 - val_loss: 0.2115 - val_recall_6: 0.8915 - val_precision_6: 0.7070 - val_mean_io_u_6: 0.8163 - val_accuracy: 0.9914 - val_auc: 0.9474 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1999 - recall_6: 0.9124 - precision_6: 0.7129 - mean_io_u_6: 0.8262 - accuracy: 0.9918 - auc: 0.9578\n",
      "Epoch 43: val_loss did not improve from 0.20082\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1999 - recall_6: 0.9124 - precision_6: 0.7129 - mean_io_u_6: 0.8262 - accuracy: 0.9918 - auc: 0.9578 - val_loss: 0.2042 - val_recall_6: 0.8945 - val_precision_6: 0.7168 - val_mean_io_u_6: 0.8209 - val_accuracy: 0.9917 - val_auc: 0.9493 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1975 - recall_6: 0.9140 - precision_6: 0.7155 - mean_io_u_6: 0.8277 - accuracy: 0.9919 - auc: 0.9587\n",
      "Epoch 44: val_loss did not improve from 0.20082\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1975 - recall_6: 0.9141 - precision_6: 0.7156 - mean_io_u_6: 0.8277 - accuracy: 0.9919 - auc: 0.9587 - val_loss: 0.2375 - val_recall_6: 0.8368 - val_precision_6: 0.7004 - val_mean_io_u_6: 0.7953 - val_accuracy: 0.9906 - val_auc: 0.9214 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1978 - recall_6: 0.9140 - precision_6: 0.7152 - mean_io_u_6: 0.8276 - accuracy: 0.9919 - auc: 0.9586\n",
      "Epoch 45: val_loss did not improve from 0.20082\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.1978 - recall_6: 0.9140 - precision_6: 0.7152 - mean_io_u_6: 0.8276 - accuracy: 0.9919 - auc: 0.9586 - val_loss: 0.2120 - val_recall_6: 0.8910 - val_precision_6: 0.7065 - val_mean_io_u_6: 0.8169 - val_accuracy: 0.9914 - val_auc: 0.9472 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1965 - recall_6: 0.9156 - precision_6: 0.7163 - mean_io_u_6: 0.8285 - accuracy: 0.9919 - auc: 0.9595\n",
      "Epoch 46: val_loss improved from 0.20082 to 0.19959, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.1965 - recall_6: 0.9156 - precision_6: 0.7162 - mean_io_u_6: 0.8285 - accuracy: 0.9919 - auc: 0.9594 - val_loss: 0.1996 - val_recall_6: 0.9024 - val_precision_6: 0.7193 - val_mean_io_u_6: 0.8253 - val_accuracy: 0.9919 - val_auc: 0.9524 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1966 - recall_6: 0.9152 - precision_6: 0.7164 - mean_io_u_6: 0.8286 - accuracy: 0.9919 - auc: 0.9591\n",
      "Epoch 47: val_loss improved from 0.19959 to 0.19872, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 287ms/step - loss: 0.1966 - recall_6: 0.9151 - precision_6: 0.7163 - mean_io_u_6: 0.8286 - accuracy: 0.9919 - auc: 0.9591 - val_loss: 0.1987 - val_recall_6: 0.9015 - val_precision_6: 0.7212 - val_mean_io_u_6: 0.8256 - val_accuracy: 0.9919 - val_auc: 0.9526 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1961 - recall_6: 0.9148 - precision_6: 0.7174 - mean_io_u_6: 0.8288 - accuracy: 0.9920 - auc: 0.9588\n",
      "Epoch 48: val_loss did not improve from 0.19872\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1961 - recall_6: 0.9148 - precision_6: 0.7174 - mean_io_u_6: 0.8288 - accuracy: 0.9920 - auc: 0.9588 - val_loss: 0.2025 - val_recall_6: 0.8993 - val_precision_6: 0.7165 - val_mean_io_u_6: 0.8238 - val_accuracy: 0.9918 - val_auc: 0.9508 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1955 - recall_6: 0.9154 - precision_6: 0.7178 - mean_io_u_6: 0.8293 - accuracy: 0.9920 - auc: 0.9590\n",
      "Epoch 49: val_loss did not improve from 0.19872\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1956 - recall_6: 0.9153 - precision_6: 0.7178 - mean_io_u_6: 0.8293 - accuracy: 0.9920 - auc: 0.9590 - val_loss: 0.2108 - val_recall_6: 0.8883 - val_precision_6: 0.7102 - val_mean_io_u_6: 0.8172 - val_accuracy: 0.9915 - val_auc: 0.9458 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1957 - recall_6: 0.9148 - precision_6: 0.7180 - mean_io_u_6: 0.8292 - accuracy: 0.9920 - auc: 0.9588\n",
      "Epoch 50: val_loss did not improve from 0.19872\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1957 - recall_6: 0.9148 - precision_6: 0.7179 - mean_io_u_6: 0.8292 - accuracy: 0.9920 - auc: 0.9588 - val_loss: 0.2249 - val_recall_6: 0.8693 - val_precision_6: 0.6995 - val_mean_io_u_6: 0.8076 - val_accuracy: 0.9909 - val_auc: 0.9366 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1947 - recall_6: 0.9162 - precision_6: 0.7187 - mean_io_u_6: 0.8300 - accuracy: 0.9920 - auc: 0.9594\n",
      "Epoch 51: val_loss did not improve from 0.19872\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1948 - recall_6: 0.9161 - precision_6: 0.7186 - mean_io_u_6: 0.8299 - accuracy: 0.9920 - auc: 0.9594 - val_loss: 0.2030 - val_recall_6: 0.8963 - val_precision_6: 0.7175 - val_mean_io_u_6: 0.8223 - val_accuracy: 0.9918 - val_auc: 0.9497 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1937 - recall_6: 0.9169 - precision_6: 0.7197 - mean_io_u_6: 0.8308 - accuracy: 0.9921 - auc: 0.9598\n",
      "Epoch 52: val_loss did not improve from 0.19872\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1937 - recall_6: 0.9170 - precision_6: 0.7197 - mean_io_u_6: 0.8308 - accuracy: 0.9921 - auc: 0.9598 - val_loss: 0.2285 - val_recall_6: 0.8654 - val_precision_6: 0.6961 - val_mean_io_u_6: 0.8042 - val_accuracy: 0.9908 - val_auc: 0.9348 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1903 - recall_6: 0.9199 - precision_6: 0.7233 - mean_io_u_6: 0.8331 - accuracy: 0.9922 - auc: 0.9613\n",
      "Epoch 53: val_loss did not improve from 0.19872\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1903 - recall_6: 0.9199 - precision_6: 0.7233 - mean_io_u_6: 0.8331 - accuracy: 0.9922 - auc: 0.9613 - val_loss: 0.2130 - val_recall_6: 0.8805 - val_precision_6: 0.7116 - val_mean_io_u_6: 0.8149 - val_accuracy: 0.9914 - val_auc: 0.9422 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1878 - recall_6: 0.9212 - precision_6: 0.7264 - mean_io_u_6: 0.8347 - accuracy: 0.9923 - auc: 0.9620\n",
      "Epoch 54: val_loss improved from 0.19872 to 0.19392, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 294ms/step - loss: 0.1878 - recall_6: 0.9212 - precision_6: 0.7264 - mean_io_u_6: 0.8347 - accuracy: 0.9923 - auc: 0.9620 - val_loss: 0.1939 - val_recall_6: 0.9117 - val_precision_6: 0.7226 - val_mean_io_u_6: 0.8300 - val_accuracy: 0.9921 - val_auc: 0.9571 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1873 - recall_6: 0.9217 - precision_6: 0.7270 - mean_io_u_6: 0.8351 - accuracy: 0.9924 - auc: 0.9622\n",
      "Epoch 55: val_loss did not improve from 0.19392\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1873 - recall_6: 0.9217 - precision_6: 0.7270 - mean_io_u_6: 0.8351 - accuracy: 0.9924 - auc: 0.9622 - val_loss: 0.1948 - val_recall_6: 0.9104 - val_precision_6: 0.7220 - val_mean_io_u_6: 0.8294 - val_accuracy: 0.9921 - val_auc: 0.9566 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1869 - recall_6: 0.9222 - precision_6: 0.7274 - mean_io_u_6: 0.8355 - accuracy: 0.9924 - auc: 0.9624\n",
      "Epoch 56: val_loss did not improve from 0.19392\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1869 - recall_6: 0.9222 - precision_6: 0.7274 - mean_io_u_6: 0.8355 - accuracy: 0.9924 - auc: 0.9624 - val_loss: 0.2376 - val_recall_6: 0.8347 - val_precision_6: 0.7018 - val_mean_io_u_6: 0.7967 - val_accuracy: 0.9906 - val_auc: 0.9199 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1867 - recall_6: 0.9226 - precision_6: 0.7274 - mean_io_u_6: 0.8356 - accuracy: 0.9924 - auc: 0.9626\n",
      "Epoch 57: val_loss did not improve from 0.19392\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1867 - recall_6: 0.9226 - precision_6: 0.7274 - mean_io_u_6: 0.8356 - accuracy: 0.9924 - auc: 0.9626 - val_loss: 0.1963 - val_recall_6: 0.9127 - val_precision_6: 0.7182 - val_mean_io_u_6: 0.8289 - val_accuracy: 0.9920 - val_auc: 0.9575 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1862 - recall_6: 0.9233 - precision_6: 0.7278 - mean_io_u_6: 0.8359 - accuracy: 0.9924 - auc: 0.9630\n",
      "Epoch 58: val_loss improved from 0.19392 to 0.19350, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 288ms/step - loss: 0.1862 - recall_6: 0.9233 - precision_6: 0.7278 - mean_io_u_6: 0.8359 - accuracy: 0.9924 - auc: 0.9630 - val_loss: 0.1935 - val_recall_6: 0.9149 - val_precision_6: 0.7212 - val_mean_io_u_6: 0.8308 - val_accuracy: 0.9921 - val_auc: 0.9587 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1861 - recall_6: 0.9227 - precision_6: 0.7283 - mean_io_u_6: 0.8359 - accuracy: 0.9924 - auc: 0.9627\n",
      "Epoch 59: val_loss improved from 0.19350 to 0.19229, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 18s 275ms/step - loss: 0.1861 - recall_6: 0.9227 - precision_6: 0.7283 - mean_io_u_6: 0.8359 - accuracy: 0.9924 - auc: 0.9627 - val_loss: 0.1923 - val_recall_6: 0.9180 - val_precision_6: 0.7213 - val_mean_io_u_6: 0.8318 - val_accuracy: 0.9921 - val_auc: 0.9601 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1860 - recall_6: 0.9240 - precision_6: 0.7277 - mean_io_u_6: 0.8361 - accuracy: 0.9924 - auc: 0.9633\n",
      "Epoch 60: val_loss did not improve from 0.19229\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1860 - recall_6: 0.9240 - precision_6: 0.7277 - mean_io_u_6: 0.8361 - accuracy: 0.9924 - auc: 0.9633 - val_loss: 0.2079 - val_recall_6: 0.8891 - val_precision_6: 0.7143 - val_mean_io_u_6: 0.8187 - val_accuracy: 0.9916 - val_auc: 0.9466 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1855 - recall_6: 0.9237 - precision_6: 0.7286 - mean_io_u_6: 0.8363 - accuracy: 0.9924 - auc: 0.9632\n",
      "Epoch 61: val_loss did not improve from 0.19229\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1855 - recall_6: 0.9237 - precision_6: 0.7286 - mean_io_u_6: 0.8363 - accuracy: 0.9924 - auc: 0.9632 - val_loss: 0.1930 - val_recall_6: 0.9139 - val_precision_6: 0.7226 - val_mean_io_u_6: 0.8307 - val_accuracy: 0.9921 - val_auc: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1855 - recall_6: 0.9241 - precision_6: 0.7285 - mean_io_u_6: 0.8364 - accuracy: 0.9924 - auc: 0.9634\n",
      "Epoch 62: val_loss improved from 0.19229 to 0.19189, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 291ms/step - loss: 0.1855 - recall_6: 0.9241 - precision_6: 0.7284 - mean_io_u_6: 0.8364 - accuracy: 0.9924 - auc: 0.9634 - val_loss: 0.1919 - val_recall_6: 0.9165 - val_precision_6: 0.7228 - val_mean_io_u_6: 0.8319 - val_accuracy: 0.9922 - val_auc: 0.9595 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1853 - recall_6: 0.9223 - precision_6: 0.7298 - mean_io_u_6: 0.8363 - accuracy: 0.9924 - auc: 0.9626\n",
      "Epoch 63: val_loss did not improve from 0.19189\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1853 - recall_6: 0.9223 - precision_6: 0.7298 - mean_io_u_6: 0.8363 - accuracy: 0.9924 - auc: 0.9626 - val_loss: 0.1938 - val_recall_6: 0.9138 - val_precision_6: 0.7215 - val_mean_io_u_6: 0.8304 - val_accuracy: 0.9921 - val_auc: 0.9583 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1852 - recall_6: 0.9237 - precision_6: 0.7292 - mean_io_u_6: 0.8365 - accuracy: 0.9924 - auc: 0.9633\n",
      "Epoch 64: val_loss improved from 0.19189 to 0.19186, saving model to ./iter_diceLoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_diceLoss.model/assets\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 0.1851 - recall_6: 0.9238 - precision_6: 0.7292 - mean_io_u_6: 0.8366 - accuracy: 0.9924 - auc: 0.9633 - val_loss: 0.1919 - val_recall_6: 0.9151 - val_precision_6: 0.7238 - val_mean_io_u_6: 0.8317 - val_accuracy: 0.9922 - val_auc: 0.9589 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1852 - recall_6: 0.9225 - precision_6: 0.7299 - mean_io_u_6: 0.8364 - accuracy: 0.9925 - auc: 0.9626\n",
      "Epoch 65: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.1852 - recall_6: 0.9225 - precision_6: 0.7299 - mean_io_u_6: 0.8363 - accuracy: 0.9925 - auc: 0.9626 - val_loss: 0.1931 - val_recall_6: 0.9138 - val_precision_6: 0.7225 - val_mean_io_u_6: 0.8308 - val_accuracy: 0.9921 - val_auc: 0.9582 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1850 - recall_6: 0.9241 - precision_6: 0.7293 - mean_io_u_6: 0.8367 - accuracy: 0.9925 - auc: 0.9634\n",
      "Epoch 66: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1850 - recall_6: 0.9240 - precision_6: 0.7293 - mean_io_u_6: 0.8367 - accuracy: 0.9924 - auc: 0.9634 - val_loss: 0.1946 - val_recall_6: 0.9098 - val_precision_6: 0.7226 - val_mean_io_u_6: 0.8292 - val_accuracy: 0.9921 - val_auc: 0.9565 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1848 - recall_6: 0.9233 - precision_6: 0.7300 - mean_io_u_6: 0.8367 - accuracy: 0.9925 - auc: 0.9631\n",
      "Epoch 67: val_loss did not improve from 0.19186\n",
      "\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1848 - recall_6: 0.9233 - precision_6: 0.7301 - mean_io_u_6: 0.8367 - accuracy: 0.9925 - auc: 0.9631 - val_loss: 0.1992 - val_recall_6: 0.9040 - val_precision_6: 0.7189 - val_mean_io_u_6: 0.8257 - val_accuracy: 0.9919 - val_auc: 0.9536 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1844 - recall_6: 0.9236 - precision_6: 0.7305 - mean_io_u_6: 0.8369 - accuracy: 0.9925 - auc: 0.9633\n",
      "Epoch 68: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1844 - recall_6: 0.9236 - precision_6: 0.7305 - mean_io_u_6: 0.8369 - accuracy: 0.9925 - auc: 0.9633 - val_loss: 0.2046 - val_recall_6: 0.8943 - val_precision_6: 0.7163 - val_mean_io_u_6: 0.8214 - val_accuracy: 0.9917 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1842 - recall_6: 0.9241 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635\n",
      "Epoch 69: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.1842 - recall_6: 0.9241 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635 - val_loss: 0.2052 - val_recall_6: 0.8939 - val_precision_6: 0.7157 - val_mean_io_u_6: 0.8210 - val_accuracy: 0.9917 - val_auc: 0.9488 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1841 - recall_6: 0.9239 - precision_6: 0.7308 - mean_io_u_6: 0.8371 - accuracy: 0.9925 - auc: 0.9634\n",
      "Epoch 70: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1841 - recall_6: 0.9239 - precision_6: 0.7307 - mean_io_u_6: 0.8371 - accuracy: 0.9925 - auc: 0.9634 - val_loss: 0.2031 - val_recall_6: 0.8974 - val_precision_6: 0.7168 - val_mean_io_u_6: 0.8227 - val_accuracy: 0.9918 - val_auc: 0.9505 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1840 - recall_6: 0.9241 - precision_6: 0.7309 - mean_io_u_6: 0.8373 - accuracy: 0.9925 - auc: 0.9635\n",
      "Epoch 71: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1840 - recall_6: 0.9241 - precision_6: 0.7309 - mean_io_u_6: 0.8373 - accuracy: 0.9925 - auc: 0.9635 - val_loss: 0.2013 - val_recall_6: 0.8996 - val_precision_6: 0.7182 - val_mean_io_u_6: 0.8240 - val_accuracy: 0.9918 - val_auc: 0.9515 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1842 - recall_6: 0.9241 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635\n",
      "Epoch 72: val_loss did not improve from 0.19186\n",
      "\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1842 - recall_6: 0.9241 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635 - val_loss: 0.2027 - val_recall_6: 0.8976 - val_precision_6: 0.7174 - val_mean_io_u_6: 0.8230 - val_accuracy: 0.9918 - val_auc: 0.9506 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1840 - recall_6: 0.9242 - precision_6: 0.7308 - mean_io_u_6: 0.8373 - accuracy: 0.9925 - auc: 0.9635\n",
      "Epoch 73: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1839 - recall_6: 0.9242 - precision_6: 0.7308 - mean_io_u_6: 0.8373 - accuracy: 0.9925 - auc: 0.9635 - val_loss: 0.2041 - val_recall_6: 0.8956 - val_precision_6: 0.7163 - val_mean_io_u_6: 0.8219 - val_accuracy: 0.9917 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1842 - recall_6: 0.9243 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635\n",
      "Epoch 74: val_loss did not improve from 0.19186\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1842 - recall_6: 0.9243 - precision_6: 0.7305 - mean_io_u_6: 0.8372 - accuracy: 0.9925 - auc: 0.9635 - val_loss: 0.1993 - val_recall_6: 0.9036 - val_precision_6: 0.7189 - val_mean_io_u_6: 0.8257 - val_accuracy: 0.9919 - val_auc: 0.9534 - lr: 1.0000e-05\n",
      "Epoch 74: early stopping\n",
      "\n",
      "\n",
      " f    <function diceLoss.<locals>.f at 0x7f048473e820>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 1.1724 - recall_7: 0.9762 - precision_7: 0.0955 - mean_io_u_7: 0.5354 - accuracy: 0.8330 - auc: 0.9317\n",
      "Epoch 1: val_loss improved from inf to 0.93535, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 25s 338ms/step - loss: 1.1718 - recall_7: 0.9762 - precision_7: 0.0957 - mean_io_u_7: 0.5355 - accuracy: 0.8333 - auc: 0.9318 - val_loss: 0.9354 - val_recall_7: 0.7121 - val_precision_7: 0.1681 - val_mean_io_u_7: 0.5478 - val_accuracy: 0.9313 - val_auc: 0.8783 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.8455 - recall_7: 0.9873 - precision_7: 0.2161 - mean_io_u_7: 0.5867 - accuracy: 0.9352 - auc: 0.9623\n",
      "Epoch 2: val_loss improved from 0.93535 to 0.70588, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.8452 - recall_7: 0.9872 - precision_7: 0.2162 - mean_io_u_7: 0.5868 - accuracy: 0.9353 - auc: 0.9623 - val_loss: 0.7059 - val_recall_7: 0.5870 - val_precision_7: 0.2521 - val_mean_io_u_7: 0.5405 - val_accuracy: 0.9612 - val_auc: 0.7937 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.5671 - recall_7: 0.9667 - precision_7: 0.4116 - mean_io_u_7: 0.7007 - accuracy: 0.9745 - auc: 0.9675\n",
      "Epoch 3: val_loss did not improve from 0.70588\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 0.5671 - recall_7: 0.9667 - precision_7: 0.4116 - mean_io_u_7: 0.7007 - accuracy: 0.9745 - auc: 0.9675 - val_loss: 0.9118 - val_recall_7: 0.1236 - val_precision_7: 0.6366 - val_mean_io_u_7: 0.4918 - val_accuracy: 0.9829 - val_auc: 0.2987 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3231 - recall_7: 0.9068 - precision_7: 0.6536 - mean_io_u_7: 0.8081 - accuracy: 0.9897 - auc: 0.9476\n",
      "Epoch 4: val_loss did not improve from 0.70588\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.3231 - recall_7: 0.9068 - precision_7: 0.6536 - mean_io_u_7: 0.8081 - accuracy: 0.9897 - auc: 0.9476 - val_loss: 0.8737 - val_recall_7: 0.4067 - val_precision_7: 0.8159 - val_mean_io_u_7: 0.6151 - val_accuracy: 0.9876 - val_auc: 0.5262 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2390 - recall_7: 0.8739 - precision_7: 0.7374 - mean_io_u_7: 0.8317 - accuracy: 0.9921 - auc: 0.9424\n",
      "Epoch 5: val_loss improved from 0.70588 to 0.32469, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.2391 - recall_7: 0.8738 - precision_7: 0.7373 - mean_io_u_7: 0.8316 - accuracy: 0.9921 - auc: 0.9423 - val_loss: 0.3247 - val_recall_7: 0.5571 - val_precision_7: 0.8811 - val_mean_io_u_7: 0.7127 - val_accuracy: 0.9907 - val_auc: 0.7941 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2129 - recall_7: 0.8621 - precision_7: 0.7655 - mean_io_u_7: 0.8377 - accuracy: 0.9928 - auc: 0.9362\n",
      "Epoch 6: val_loss improved from 0.32469 to 0.21426, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.2129 - recall_7: 0.8622 - precision_7: 0.7655 - mean_io_u_7: 0.8377 - accuracy: 0.9928 - auc: 0.9362 - val_loss: 0.2143 - val_recall_7: 0.7731 - val_precision_7: 0.8139 - val_mean_io_u_7: 0.8113 - val_accuracy: 0.9927 - val_auc: 0.8938 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2014 - recall_7: 0.8580 - precision_7: 0.7784 - mean_io_u_7: 0.8407 - accuracy: 0.9930 - auc: 0.9336\n",
      "Epoch 7: val_loss improved from 0.21426 to 0.20957, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 0.2014 - recall_7: 0.8580 - precision_7: 0.7784 - mean_io_u_7: 0.8407 - accuracy: 0.9930 - auc: 0.9336 - val_loss: 0.2096 - val_recall_7: 0.7959 - val_precision_7: 0.7996 - val_mean_io_u_7: 0.8198 - val_accuracy: 0.9927 - val_auc: 0.9032 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1961 - recall_7: 0.8555 - precision_7: 0.7841 - mean_io_u_7: 0.8419 - accuracy: 0.9932 - auc: 0.9320\n",
      "Epoch 8: val_loss improved from 0.20957 to 0.18274, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1961 - recall_7: 0.8555 - precision_7: 0.7841 - mean_io_u_7: 0.8419 - accuracy: 0.9932 - auc: 0.9320 - val_loss: 0.1827 - val_recall_7: 0.8412 - val_precision_7: 0.8074 - val_mean_io_u_7: 0.8431 - val_accuracy: 0.9935 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1922 - recall_7: 0.8535 - precision_7: 0.7895 - mean_io_u_7: 0.8433 - accuracy: 0.9933 - auc: 0.9303\n",
      "Epoch 9: val_loss did not improve from 0.18274\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1922 - recall_7: 0.8535 - precision_7: 0.7895 - mean_io_u_7: 0.8433 - accuracy: 0.9933 - auc: 0.9303 - val_loss: 0.2109 - val_recall_7: 0.8178 - val_precision_7: 0.7770 - val_mean_io_u_7: 0.8253 - val_accuracy: 0.9925 - val_auc: 0.9109 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1897 - recall_7: 0.8533 - precision_7: 0.7918 - mean_io_u_7: 0.8441 - accuracy: 0.9933 - auc: 0.9299\n",
      "Epoch 10: val_loss improved from 0.18274 to 0.17591, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.1897 - recall_7: 0.8534 - precision_7: 0.7919 - mean_io_u_7: 0.8442 - accuracy: 0.9933 - auc: 0.9299 - val_loss: 0.1759 - val_recall_7: 0.8761 - val_precision_7: 0.7903 - val_mean_io_u_7: 0.8528 - val_accuracy: 0.9936 - val_auc: 0.9392 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1841 - recall_7: 0.8563 - precision_7: 0.7980 - mean_io_u_7: 0.8476 - accuracy: 0.9935 - auc: 0.9315\n",
      "Epoch 11: val_loss improved from 0.17591 to 0.17319, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 307ms/step - loss: 0.1841 - recall_7: 0.8563 - precision_7: 0.7980 - mean_io_u_7: 0.8476 - accuracy: 0.9935 - auc: 0.9315 - val_loss: 0.1732 - val_recall_7: 0.8603 - val_precision_7: 0.8080 - val_mean_io_u_7: 0.8535 - val_accuracy: 0.9938 - val_auc: 0.9320 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1811 - recall_7: 0.8554 - precision_7: 0.8030 - mean_io_u_7: 0.8491 - accuracy: 0.9936 - auc: 0.9310\n",
      "Epoch 12: val_loss did not improve from 0.17319\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1811 - recall_7: 0.8554 - precision_7: 0.8030 - mean_io_u_7: 0.8491 - accuracy: 0.9936 - auc: 0.9310 - val_loss: 0.1981 - val_recall_7: 0.8076 - val_precision_7: 0.8101 - val_mean_io_u_7: 0.8319 - val_accuracy: 0.9931 - val_auc: 0.9073 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1778 - recall_7: 0.8579 - precision_7: 0.8059 - mean_io_u_7: 0.8511 - accuracy: 0.9937 - auc: 0.9318\n",
      "Epoch 13: val_loss did not improve from 0.17319\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1777 - recall_7: 0.8579 - precision_7: 0.8059 - mean_io_u_7: 0.8511 - accuracy: 0.9937 - auc: 0.9319 - val_loss: 0.1735 - val_recall_7: 0.8557 - val_precision_7: 0.8115 - val_mean_io_u_7: 0.8523 - val_accuracy: 0.9938 - val_auc: 0.9302 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1758 - recall_7: 0.8576 - precision_7: 0.8091 - mean_io_u_7: 0.8523 - accuracy: 0.9938 - auc: 0.9315\n",
      "Epoch 14: val_loss did not improve from 0.17319\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1758 - recall_7: 0.8576 - precision_7: 0.8091 - mean_io_u_7: 0.8523 - accuracy: 0.9938 - auc: 0.9315 - val_loss: 0.1965 - val_recall_7: 0.8097 - val_precision_7: 0.8112 - val_mean_io_u_7: 0.8337 - val_accuracy: 0.9932 - val_auc: 0.9078 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1733 - recall_7: 0.8600 - precision_7: 0.8110 - mean_io_u_7: 0.8540 - accuracy: 0.9939 - auc: 0.9327\n",
      "Epoch 15: val_loss did not improve from 0.17319\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1733 - recall_7: 0.8600 - precision_7: 0.8110 - mean_io_u_7: 0.8540 - accuracy: 0.9939 - auc: 0.9327 - val_loss: 0.1910 - val_recall_7: 0.8374 - val_precision_7: 0.7960 - val_mean_io_u_7: 0.8402 - val_accuracy: 0.9932 - val_auc: 0.9205 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1698 - recall_7: 0.8634 - precision_7: 0.8139 - mean_io_u_7: 0.8564 - accuracy: 0.9940 - auc: 0.9345\n",
      "Epoch 16: val_loss did not improve from 0.17319\n",
      "\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1698 - recall_7: 0.8634 - precision_7: 0.8139 - mean_io_u_7: 0.8564 - accuracy: 0.9940 - auc: 0.9345 - val_loss: 0.2229 - val_recall_7: 0.7787 - val_precision_7: 0.7914 - val_mean_io_u_7: 0.8151 - val_accuracy: 0.9923 - val_auc: 0.8925 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1607 - recall_7: 0.8674 - precision_7: 0.8268 - mean_io_u_7: 0.8628 - accuracy: 0.9943 - auc: 0.9367\n",
      "Epoch 17: val_loss improved from 0.17319 to 0.17120, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.1606 - recall_7: 0.8675 - precision_7: 0.8268 - mean_io_u_7: 0.8628 - accuracy: 0.9943 - auc: 0.9368 - val_loss: 0.1712 - val_recall_7: 0.8530 - val_precision_7: 0.8184 - val_mean_io_u_7: 0.8543 - val_accuracy: 0.9939 - val_auc: 0.9288 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1573 - recall_7: 0.8704 - precision_7: 0.8302 - mean_io_u_7: 0.8653 - accuracy: 0.9945 - auc: 0.9382\n",
      "Epoch 18: val_loss improved from 0.17120 to 0.15527, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1573 - recall_7: 0.8704 - precision_7: 0.8302 - mean_io_u_7: 0.8653 - accuracy: 0.9945 - auc: 0.9382 - val_loss: 0.1553 - val_recall_7: 0.8665 - val_precision_7: 0.8358 - val_mean_io_u_7: 0.8661 - val_accuracy: 0.9945 - val_auc: 0.9360 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1553 - recall_7: 0.8715 - precision_7: 0.8329 - mean_io_u_7: 0.8667 - accuracy: 0.9945 - auc: 0.9389\n",
      "Epoch 19: val_loss did not improve from 0.15527\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.1551 - recall_7: 0.8716 - precision_7: 0.8330 - mean_io_u_7: 0.8668 - accuracy: 0.9945 - auc: 0.9390 - val_loss: 0.1606 - val_recall_7: 0.8618 - val_precision_7: 0.8308 - val_mean_io_u_7: 0.8623 - val_accuracy: 0.9943 - val_auc: 0.9334 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1544 - recall_7: 0.8727 - precision_7: 0.8334 - mean_io_u_7: 0.8674 - accuracy: 0.9946 - auc: 0.9395\n",
      "Epoch 20: val_loss improved from 0.15527 to 0.14919, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.1544 - recall_7: 0.8727 - precision_7: 0.8334 - mean_io_u_7: 0.8675 - accuracy: 0.9946 - auc: 0.9395 - val_loss: 0.1492 - val_recall_7: 0.8807 - val_precision_7: 0.8349 - val_mean_io_u_7: 0.8717 - val_accuracy: 0.9947 - val_auc: 0.9429 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1537 - recall_7: 0.8740 - precision_7: 0.8335 - mean_io_u_7: 0.8680 - accuracy: 0.9946 - auc: 0.9401\n",
      "Epoch 21: val_loss improved from 0.14919 to 0.14757, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.1537 - recall_7: 0.8741 - precision_7: 0.8335 - mean_io_u_7: 0.8680 - accuracy: 0.9946 - auc: 0.9401 - val_loss: 0.1476 - val_recall_7: 0.8758 - val_precision_7: 0.8424 - val_mean_io_u_7: 0.8724 - val_accuracy: 0.9948 - val_auc: 0.9406 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1516 - recall_7: 0.8732 - precision_7: 0.8379 - mean_io_u_7: 0.8692 - accuracy: 0.9947 - auc: 0.9398\n",
      "Epoch 22: val_loss improved from 0.14757 to 0.14628, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.1516 - recall_7: 0.8732 - precision_7: 0.8379 - mean_io_u_7: 0.8692 - accuracy: 0.9947 - auc: 0.9398 - val_loss: 0.1463 - val_recall_7: 0.8717 - val_precision_7: 0.8486 - val_mean_io_u_7: 0.8728 - val_accuracy: 0.9949 - val_auc: 0.9390 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1515 - recall_7: 0.8746 - precision_7: 0.8368 - mean_io_u_7: 0.8695 - accuracy: 0.9947 - auc: 0.9406\n",
      "Epoch 23: val_loss did not improve from 0.14628\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1515 - recall_7: 0.8747 - precision_7: 0.8368 - mean_io_u_7: 0.8695 - accuracy: 0.9947 - auc: 0.9406 - val_loss: 0.1465 - val_recall_7: 0.8714 - val_precision_7: 0.8489 - val_mean_io_u_7: 0.8728 - val_accuracy: 0.9949 - val_auc: 0.9387 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1503 - recall_7: 0.8752 - precision_7: 0.8386 - mean_io_u_7: 0.8704 - accuracy: 0.9947 - auc: 0.9408\n",
      "Epoch 24: val_loss did not improve from 0.14628\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1502 - recall_7: 0.8752 - precision_7: 0.8386 - mean_io_u_7: 0.8704 - accuracy: 0.9947 - auc: 0.9408 - val_loss: 0.1477 - val_recall_7: 0.8703 - val_precision_7: 0.8475 - val_mean_io_u_7: 0.8717 - val_accuracy: 0.9948 - val_auc: 0.9382 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1496 - recall_7: 0.8772 - precision_7: 0.8378 - mean_io_u_7: 0.8709 - accuracy: 0.9947 - auc: 0.9419\n",
      "Epoch 25: val_loss did not improve from 0.14628\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1497 - recall_7: 0.8772 - precision_7: 0.8378 - mean_io_u_7: 0.8709 - accuracy: 0.9947 - auc: 0.9419 - val_loss: 0.1472 - val_recall_7: 0.8761 - val_precision_7: 0.8428 - val_mean_io_u_7: 0.8727 - val_accuracy: 0.9948 - val_auc: 0.9408 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1488 - recall_7: 0.8762 - precision_7: 0.8402 - mean_io_u_7: 0.8715 - accuracy: 0.9948 - auc: 0.9412\n",
      "Epoch 26: val_loss improved from 0.14628 to 0.14558, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1488 - recall_7: 0.8762 - precision_7: 0.8402 - mean_io_u_7: 0.8715 - accuracy: 0.9948 - auc: 0.9412 - val_loss: 0.1456 - val_recall_7: 0.8738 - val_precision_7: 0.8477 - val_mean_io_u_7: 0.8735 - val_accuracy: 0.9949 - val_auc: 0.9396 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1473 - recall_7: 0.8769 - precision_7: 0.8424 - mean_io_u_7: 0.8724 - accuracy: 0.9948 - auc: 0.9417\n",
      "Epoch 27: val_loss improved from 0.14558 to 0.14249, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 309ms/step - loss: 0.1473 - recall_7: 0.8769 - precision_7: 0.8424 - mean_io_u_7: 0.8725 - accuracy: 0.9948 - auc: 0.9417 - val_loss: 0.1425 - val_recall_7: 0.8818 - val_precision_7: 0.8463 - val_mean_io_u_7: 0.8766 - val_accuracy: 0.9950 - val_auc: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1463 - recall_7: 0.8789 - precision_7: 0.8424 - mean_io_u_7: 0.8733 - accuracy: 0.9949 - auc: 0.9427\n",
      "Epoch 28: val_loss did not improve from 0.14249\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1463 - recall_7: 0.8789 - precision_7: 0.8424 - mean_io_u_7: 0.8733 - accuracy: 0.9949 - auc: 0.9427 - val_loss: 0.1427 - val_recall_7: 0.8833 - val_precision_7: 0.8444 - val_mean_io_u_7: 0.8762 - val_accuracy: 0.9950 - val_auc: 0.9443 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1455 - recall_7: 0.8803 - precision_7: 0.8424 - mean_io_u_7: 0.8739 - accuracy: 0.9949 - auc: 0.9435\n",
      "Epoch 29: val_loss improved from 0.14249 to 0.14062, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.1455 - recall_7: 0.8803 - precision_7: 0.8424 - mean_io_u_7: 0.8739 - accuracy: 0.9949 - auc: 0.9435 - val_loss: 0.1406 - val_recall_7: 0.8847 - val_precision_7: 0.8470 - val_mean_io_u_7: 0.8778 - val_accuracy: 0.9950 - val_auc: 0.9451 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1449 - recall_7: 0.8811 - precision_7: 0.8428 - mean_io_u_7: 0.8744 - accuracy: 0.9949 - auc: 0.9438\n",
      "Epoch 30: val_loss did not improve from 0.14062\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.1449 - recall_7: 0.8811 - precision_7: 0.8428 - mean_io_u_7: 0.8744 - accuracy: 0.9949 - auc: 0.9438 - val_loss: 0.1570 - val_recall_7: 0.8634 - val_precision_7: 0.8362 - val_mean_io_u_7: 0.8650 - val_accuracy: 0.9945 - val_auc: 0.9345 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1438 - recall_7: 0.8800 - precision_7: 0.8458 - mean_io_u_7: 0.8751 - accuracy: 0.9949 - auc: 0.9432\n",
      "Epoch 31: val_loss improved from 0.14062 to 0.13884, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.1438 - recall_7: 0.8800 - precision_7: 0.8458 - mean_io_u_7: 0.8751 - accuracy: 0.9949 - auc: 0.9432 - val_loss: 0.1388 - val_recall_7: 0.8805 - val_precision_7: 0.8539 - val_mean_io_u_7: 0.8784 - val_accuracy: 0.9951 - val_auc: 0.9432 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1439 - recall_7: 0.8798 - precision_7: 0.8458 - mean_io_u_7: 0.8749 - accuracy: 0.9949 - auc: 0.9432\n",
      "Epoch 32: val_loss did not improve from 0.13884\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1438 - recall_7: 0.8798 - precision_7: 0.8458 - mean_io_u_7: 0.8749 - accuracy: 0.9949 - auc: 0.9432 - val_loss: 0.1395 - val_recall_7: 0.8805 - val_precision_7: 0.8530 - val_mean_io_u_7: 0.8781 - val_accuracy: 0.9951 - val_auc: 0.9432 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1428 - recall_7: 0.8821 - precision_7: 0.8456 - mean_io_u_7: 0.8759 - accuracy: 0.9950 - auc: 0.9445\n",
      "Epoch 33: val_loss improved from 0.13884 to 0.13877, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.1428 - recall_7: 0.8821 - precision_7: 0.8456 - mean_io_u_7: 0.8759 - accuracy: 0.9950 - auc: 0.9445 - val_loss: 0.1388 - val_recall_7: 0.8818 - val_precision_7: 0.8529 - val_mean_io_u_7: 0.8785 - val_accuracy: 0.9951 - val_auc: 0.9440 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1418 - recall_7: 0.8817 - precision_7: 0.8479 - mean_io_u_7: 0.8763 - accuracy: 0.9950 - auc: 0.9444\n",
      "Epoch 34: val_loss did not improve from 0.13877\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1418 - recall_7: 0.8817 - precision_7: 0.8479 - mean_io_u_7: 0.8763 - accuracy: 0.9950 - auc: 0.9444 - val_loss: 0.1417 - val_recall_7: 0.8814 - val_precision_7: 0.8478 - val_mean_io_u_7: 0.8767 - val_accuracy: 0.9950 - val_auc: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1413 - recall_7: 0.8826 - precision_7: 0.8479 - mean_io_u_7: 0.8769 - accuracy: 0.9950 - auc: 0.9447\n",
      "Epoch 35: val_loss improved from 0.13877 to 0.13630, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.1414 - recall_7: 0.8825 - precision_7: 0.8478 - mean_io_u_7: 0.8769 - accuracy: 0.9950 - auc: 0.9446 - val_loss: 0.1363 - val_recall_7: 0.8849 - val_precision_7: 0.8545 - val_mean_io_u_7: 0.8808 - val_accuracy: 0.9952 - val_auc: 0.9453 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1409 - recall_7: 0.8822 - precision_7: 0.8490 - mean_io_u_7: 0.8771 - accuracy: 0.9950 - auc: 0.9443\n",
      "Epoch 36: val_loss did not improve from 0.13630\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1409 - recall_7: 0.8822 - precision_7: 0.8490 - mean_io_u_7: 0.8771 - accuracy: 0.9950 - auc: 0.9443 - val_loss: 0.1370 - val_recall_7: 0.8855 - val_precision_7: 0.8523 - val_mean_io_u_7: 0.8802 - val_accuracy: 0.9952 - val_auc: 0.9456 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1402 - recall_7: 0.8817 - precision_7: 0.8506 - mean_io_u_7: 0.8774 - accuracy: 0.9951 - auc: 0.9443\n",
      "Epoch 37: val_loss did not improve from 0.13630\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1402 - recall_7: 0.8817 - precision_7: 0.8506 - mean_io_u_7: 0.8774 - accuracy: 0.9951 - auc: 0.9443 - val_loss: 0.1368 - val_recall_7: 0.8881 - val_precision_7: 0.8505 - val_mean_io_u_7: 0.8808 - val_accuracy: 0.9952 - val_auc: 0.9470 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1395 - recall_7: 0.8839 - precision_7: 0.8499 - mean_io_u_7: 0.8782 - accuracy: 0.9951 - auc: 0.9455\n",
      "Epoch 38: val_loss improved from 0.13630 to 0.13563, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.1395 - recall_7: 0.8839 - precision_7: 0.8499 - mean_io_u_7: 0.8782 - accuracy: 0.9951 - auc: 0.9455 - val_loss: 0.1356 - val_recall_7: 0.8868 - val_precision_7: 0.8537 - val_mean_io_u_7: 0.8812 - val_accuracy: 0.9952 - val_auc: 0.9464 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1389 - recall_7: 0.8844 - precision_7: 0.8504 - mean_io_u_7: 0.8785 - accuracy: 0.9951 - auc: 0.9456\n",
      "Epoch 39: val_loss improved from 0.13563 to 0.13460, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.1389 - recall_7: 0.8844 - precision_7: 0.8504 - mean_io_u_7: 0.8785 - accuracy: 0.9951 - auc: 0.9456 - val_loss: 0.1346 - val_recall_7: 0.8857 - val_precision_7: 0.8571 - val_mean_io_u_7: 0.8820 - val_accuracy: 0.9953 - val_auc: 0.9457 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1383 - recall_7: 0.8851 - precision_7: 0.8508 - mean_io_u_7: 0.8791 - accuracy: 0.9951 - auc: 0.9460\n",
      "Epoch 40: val_loss improved from 0.13460 to 0.13374, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.1383 - recall_7: 0.8852 - precision_7: 0.8508 - mean_io_u_7: 0.8791 - accuracy: 0.9951 - auc: 0.9460 - val_loss: 0.1337 - val_recall_7: 0.8906 - val_precision_7: 0.8539 - val_mean_io_u_7: 0.8830 - val_accuracy: 0.9953 - val_auc: 0.9482 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1374 - recall_7: 0.8867 - precision_7: 0.8512 - mean_io_u_7: 0.8797 - accuracy: 0.9952 - auc: 0.9468\n",
      "Epoch 41: val_loss did not improve from 0.13374\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1375 - recall_7: 0.8866 - precision_7: 0.8511 - mean_io_u_7: 0.8797 - accuracy: 0.9952 - auc: 0.9468 - val_loss: 0.1351 - val_recall_7: 0.8871 - val_precision_7: 0.8576 - val_mean_io_u_7: 0.8829 - val_accuracy: 0.9953 - val_auc: 0.9465 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1366 - recall_7: 0.8864 - precision_7: 0.8528 - mean_io_u_7: 0.8803 - accuracy: 0.9952 - auc: 0.9466\n",
      "Epoch 42: val_loss did not improve from 0.13374\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1368 - recall_7: 0.8863 - precision_7: 0.8527 - mean_io_u_7: 0.8802 - accuracy: 0.9952 - auc: 0.9465 - val_loss: 0.1352 - val_recall_7: 0.8876 - val_precision_7: 0.8537 - val_mean_io_u_7: 0.8816 - val_accuracy: 0.9952 - val_auc: 0.9468 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1361 - recall_7: 0.8862 - precision_7: 0.8539 - mean_io_u_7: 0.8805 - accuracy: 0.9952 - auc: 0.9466\n",
      "Epoch 43: val_loss did not improve from 0.13374\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1361 - recall_7: 0.8862 - precision_7: 0.8540 - mean_io_u_7: 0.8806 - accuracy: 0.9952 - auc: 0.9466 - val_loss: 0.1341 - val_recall_7: 0.8881 - val_precision_7: 0.8554 - val_mean_io_u_7: 0.8825 - val_accuracy: 0.9953 - val_auc: 0.9471 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1357 - recall_7: 0.8878 - precision_7: 0.8531 - mean_io_u_7: 0.8810 - accuracy: 0.9952 - auc: 0.9474\n",
      "Epoch 44: val_loss did not improve from 0.13374\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1357 - recall_7: 0.8878 - precision_7: 0.8531 - mean_io_u_7: 0.8810 - accuracy: 0.9952 - auc: 0.9474 - val_loss: 0.1345 - val_recall_7: 0.8875 - val_precision_7: 0.8550 - val_mean_io_u_7: 0.8819 - val_accuracy: 0.9953 - val_auc: 0.9468 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1354 - recall_7: 0.8887 - precision_7: 0.8528 - mean_io_u_7: 0.8813 - accuracy: 0.9952 - auc: 0.9478\n",
      "Epoch 45: val_loss did not improve from 0.13374\n",
      "\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1355 - recall_7: 0.8886 - precision_7: 0.8527 - mean_io_u_7: 0.8812 - accuracy: 0.9952 - auc: 0.9478 - val_loss: 0.1361 - val_recall_7: 0.8848 - val_precision_7: 0.8546 - val_mean_io_u_7: 0.8806 - val_accuracy: 0.9952 - val_auc: 0.9455 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1344 - recall_7: 0.8893 - precision_7: 0.8541 - mean_io_u_7: 0.8821 - accuracy: 0.9953 - auc: 0.9480\n",
      "Epoch 46: val_loss improved from 0.13374 to 0.13244, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.1344 - recall_7: 0.8893 - precision_7: 0.8541 - mean_io_u_7: 0.8821 - accuracy: 0.9953 - auc: 0.9480 - val_loss: 0.1324 - val_recall_7: 0.8882 - val_precision_7: 0.8585 - val_mean_io_u_7: 0.8836 - val_accuracy: 0.9953 - val_auc: 0.9472 - lr: 1.0000e-05\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1338 - recall_7: 0.8891 - precision_7: 0.8554 - mean_io_u_7: 0.8824 - accuracy: 0.9953 - auc: 0.9480\n",
      "Epoch 47: val_loss improved from 0.13244 to 0.13157, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.1338 - recall_7: 0.8891 - precision_7: 0.8554 - mean_io_u_7: 0.8824 - accuracy: 0.9953 - auc: 0.9480 - val_loss: 0.1316 - val_recall_7: 0.8908 - val_precision_7: 0.8578 - val_mean_io_u_7: 0.8844 - val_accuracy: 0.9954 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 48/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1335 - recall_7: 0.8888 - precision_7: 0.8562 - mean_io_u_7: 0.8827 - accuracy: 0.9953 - auc: 0.9479\n",
      "Epoch 48: val_loss improved from 0.13157 to 0.13037, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.1335 - recall_7: 0.8888 - precision_7: 0.8562 - mean_io_u_7: 0.8827 - accuracy: 0.9953 - auc: 0.9479 - val_loss: 0.1304 - val_recall_7: 0.8903 - val_precision_7: 0.8605 - val_mean_io_u_7: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9483 - lr: 1.0000e-05\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1331 - recall_7: 0.8890 - precision_7: 0.8567 - mean_io_u_7: 0.8829 - accuracy: 0.9953 - auc: 0.9481\n",
      "Epoch 49: val_loss improved from 0.13037 to 0.12993, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.1331 - recall_7: 0.8890 - precision_7: 0.8567 - mean_io_u_7: 0.8829 - accuracy: 0.9953 - auc: 0.9481 - val_loss: 0.1299 - val_recall_7: 0.8917 - val_precision_7: 0.8600 - val_mean_io_u_7: 0.8857 - val_accuracy: 0.9954 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1331 - recall_7: 0.8889 - precision_7: 0.8568 - mean_io_u_7: 0.8828 - accuracy: 0.9953 - auc: 0.9481\n",
      "Epoch 50: val_loss did not improve from 0.12993\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1331 - recall_7: 0.8889 - precision_7: 0.8568 - mean_io_u_7: 0.8828 - accuracy: 0.9953 - auc: 0.9481 - val_loss: 0.1301 - val_recall_7: 0.8928 - val_precision_7: 0.8587 - val_mean_io_u_7: 0.8856 - val_accuracy: 0.9954 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1331 - recall_7: 0.8899 - precision_7: 0.8560 - mean_io_u_7: 0.8830 - accuracy: 0.9953 - auc: 0.9485\n",
      "Epoch 51: val_loss did not improve from 0.12993\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1331 - recall_7: 0.8899 - precision_7: 0.8560 - mean_io_u_7: 0.8830 - accuracy: 0.9953 - auc: 0.9485 - val_loss: 0.1312 - val_recall_7: 0.8920 - val_precision_7: 0.8574 - val_mean_io_u_7: 0.8848 - val_accuracy: 0.9954 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1329 - recall_7: 0.8895 - precision_7: 0.8568 - mean_io_u_7: 0.8831 - accuracy: 0.9953 - auc: 0.9483\n",
      "Epoch 52: val_loss did not improve from 0.12993\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1329 - recall_7: 0.8895 - precision_7: 0.8568 - mean_io_u_7: 0.8831 - accuracy: 0.9953 - auc: 0.9483 - val_loss: 0.1306 - val_recall_7: 0.8908 - val_precision_7: 0.8596 - val_mean_io_u_7: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1327 - recall_7: 0.8892 - precision_7: 0.8574 - mean_io_u_7: 0.8831 - accuracy: 0.9953 - auc: 0.9482\n",
      "Epoch 53: val_loss did not improve from 0.12993\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1327 - recall_7: 0.8892 - precision_7: 0.8574 - mean_io_u_7: 0.8831 - accuracy: 0.9953 - auc: 0.9482 - val_loss: 0.1301 - val_recall_7: 0.8906 - val_precision_7: 0.8606 - val_mean_io_u_7: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1326 - recall_7: 0.8899 - precision_7: 0.8570 - mean_io_u_7: 0.8832 - accuracy: 0.9953 - auc: 0.9486\n",
      "Epoch 54: val_loss improved from 0.12993 to 0.12977, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.1325 - recall_7: 0.8899 - precision_7: 0.8570 - mean_io_u_7: 0.8832 - accuracy: 0.9953 - auc: 0.9486 - val_loss: 0.1298 - val_recall_7: 0.8916 - val_precision_7: 0.8603 - val_mean_io_u_7: 0.8857 - val_accuracy: 0.9954 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1322 - recall_7: 0.8902 - precision_7: 0.8573 - mean_io_u_7: 0.8835 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 55: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1323 - recall_7: 0.8901 - precision_7: 0.8573 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9487 - val_loss: 0.1310 - val_recall_7: 0.8897 - val_precision_7: 0.8599 - val_mean_io_u_7: 0.8848 - val_accuracy: 0.9954 - val_auc: 0.9482 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1325 - recall_7: 0.8892 - precision_7: 0.8577 - mean_io_u_7: 0.8832 - accuracy: 0.9953 - auc: 0.9484\n",
      "Epoch 56: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1326 - recall_7: 0.8892 - precision_7: 0.8576 - mean_io_u_7: 0.8832 - accuracy: 0.9953 - auc: 0.9484 - val_loss: 0.1312 - val_recall_7: 0.8902 - val_precision_7: 0.8589 - val_mean_io_u_7: 0.8845 - val_accuracy: 0.9954 - val_auc: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1322 - recall_7: 0.8894 - precision_7: 0.8581 - mean_io_u_7: 0.8834 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 57: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1322 - recall_7: 0.8894 - precision_7: 0.8580 - mean_io_u_7: 0.8834 - accuracy: 0.9954 - auc: 0.9483 - val_loss: 0.1306 - val_recall_7: 0.8901 - val_precision_7: 0.8603 - val_mean_io_u_7: 0.8850 - val_accuracy: 0.9954 - val_auc: 0.9483 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1327 - recall_7: 0.8889 - precision_7: 0.8574 - mean_io_u_7: 0.8830 - accuracy: 0.9953 - auc: 0.9482\n",
      "Epoch 58: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1327 - recall_7: 0.8890 - precision_7: 0.8575 - mean_io_u_7: 0.8831 - accuracy: 0.9953 - auc: 0.9483 - val_loss: 0.1300 - val_recall_7: 0.8912 - val_precision_7: 0.8605 - val_mean_io_u_7: 0.8854 - val_accuracy: 0.9954 - val_auc: 0.9489 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1323 - recall_7: 0.8908 - precision_7: 0.8566 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9491\n",
      "Epoch 59: val_loss did not improve from 0.12977\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1323 - recall_7: 0.8908 - precision_7: 0.8566 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9491 - val_loss: 0.1306 - val_recall_7: 0.8915 - val_precision_7: 0.8589 - val_mean_io_u_7: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1323 - recall_7: 0.8905 - precision_7: 0.8568 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9489\n",
      "Epoch 60: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1323 - recall_7: 0.8905 - precision_7: 0.8568 - mean_io_u_7: 0.8836 - accuracy: 0.9953 - auc: 0.9489 - val_loss: 0.1309 - val_recall_7: 0.8920 - val_precision_7: 0.8580 - val_mean_io_u_7: 0.8850 - val_accuracy: 0.9954 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1321 - recall_7: 0.8906 - precision_7: 0.8572 - mean_io_u_7: 0.8836 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 61: val_loss did not improve from 0.12977\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1321 - recall_7: 0.8906 - precision_7: 0.8571 - mean_io_u_7: 0.8836 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.1316 - val_recall_7: 0.8894 - val_precision_7: 0.8590 - val_mean_io_u_7: 0.8842 - val_accuracy: 0.9954 - val_auc: 0.9480 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1322 - recall_7: 0.8901 - precision_7: 0.8573 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9487\n",
      "Epoch 62: val_loss improved from 0.12977 to 0.12957, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 317ms/step - loss: 0.1322 - recall_7: 0.8901 - precision_7: 0.8573 - mean_io_u_7: 0.8835 - accuracy: 0.9953 - auc: 0.9487 - val_loss: 0.1296 - val_recall_7: 0.8920 - val_precision_7: 0.8604 - val_mean_io_u_7: 0.8858 - val_accuracy: 0.9954 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1320 - recall_7: 0.8902 - precision_7: 0.8575 - mean_io_u_7: 0.8837 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 63: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1320 - recall_7: 0.8902 - precision_7: 0.8575 - mean_io_u_7: 0.8837 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1296 - val_recall_7: 0.8905 - val_precision_7: 0.8617 - val_mean_io_u_7: 0.8857 - val_accuracy: 0.9954 - val_auc: 0.9486 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1319 - recall_7: 0.8895 - precision_7: 0.8585 - mean_io_u_7: 0.8836 - accuracy: 0.9954 - auc: 0.9484\n",
      "Epoch 64: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1318 - recall_7: 0.8896 - precision_7: 0.8586 - mean_io_u_7: 0.8837 - accuracy: 0.9954 - auc: 0.9484 - val_loss: 0.1302 - val_recall_7: 0.8902 - val_precision_7: 0.8609 - val_mean_io_u_7: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1320 - recall_7: 0.8892 - precision_7: 0.8585 - mean_io_u_7: 0.8835 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 65: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1321 - recall_7: 0.8892 - precision_7: 0.8585 - mean_io_u_7: 0.8834 - accuracy: 0.9954 - auc: 0.9482 - val_loss: 0.1301 - val_recall_7: 0.8926 - val_precision_7: 0.8588 - val_mean_io_u_7: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1320 - recall_7: 0.8913 - precision_7: 0.8565 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9493\n",
      "Epoch 66: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1321 - recall_7: 0.8913 - precision_7: 0.8565 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9493 - val_loss: 0.1298 - val_recall_7: 0.8925 - val_precision_7: 0.8593 - val_mean_io_u_7: 0.8858 - val_accuracy: 0.9954 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1318 - recall_7: 0.8900 - precision_7: 0.8583 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 67: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1318 - recall_7: 0.8900 - precision_7: 0.8583 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.1303 - val_recall_7: 0.8902 - val_precision_7: 0.8606 - val_mean_io_u_7: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1316 - recall_7: 0.8900 - precision_7: 0.8585 - mean_io_u_7: 0.8839 - accuracy: 0.9954 - auc: 0.9487\n",
      "Epoch 68: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1316 - recall_7: 0.8900 - precision_7: 0.8585 - mean_io_u_7: 0.8839 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.1305 - val_recall_7: 0.8905 - val_precision_7: 0.8598 - val_mean_io_u_7: 0.8850 - val_accuracy: 0.9954 - val_auc: 0.9486 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1319 - recall_7: 0.8902 - precision_7: 0.8578 - mean_io_u_7: 0.8837 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 69: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1319 - recall_7: 0.8902 - precision_7: 0.8578 - mean_io_u_7: 0.8837 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1305 - val_recall_7: 0.8909 - val_precision_7: 0.8596 - val_mean_io_u_7: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1316 - recall_7: 0.8897 - precision_7: 0.8588 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 70: val_loss did not improve from 0.12957\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1316 - recall_7: 0.8897 - precision_7: 0.8588 - mean_io_u_7: 0.8838 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.1297 - val_recall_7: 0.8905 - val_precision_7: 0.8614 - val_mean_io_u_7: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1314 - recall_7: 0.8897 - precision_7: 0.8591 - mean_io_u_7: 0.8840 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 71: val_loss improved from 0.12957 to 0.12926, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 19s 302ms/step - loss: 0.1314 - recall_7: 0.8897 - precision_7: 0.8591 - mean_io_u_7: 0.8840 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.1293 - val_recall_7: 0.8905 - val_precision_7: 0.8622 - val_mean_io_u_7: 0.8858 - val_accuracy: 0.9955 - val_auc: 0.9486 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1313 - recall_7: 0.8900 - precision_7: 0.8591 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9487\n",
      "Epoch 72: val_loss did not improve from 0.12926\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1312 - recall_7: 0.8900 - precision_7: 0.8591 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.1295 - val_recall_7: 0.8905 - val_precision_7: 0.8619 - val_mean_io_u_7: 0.8857 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1313 - recall_7: 0.8909 - precision_7: 0.8583 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9492\n",
      "Epoch 73: val_loss did not improve from 0.12926\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1313 - recall_7: 0.8909 - precision_7: 0.8583 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9492 - val_loss: 0.1302 - val_recall_7: 0.8909 - val_precision_7: 0.8601 - val_mean_io_u_7: 0.8853 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1315 - recall_7: 0.8898 - precision_7: 0.8588 - mean_io_u_7: 0.8839 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 74: val_loss did not improve from 0.12926\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1316 - recall_7: 0.8897 - precision_7: 0.8588 - mean_io_u_7: 0.8839 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.1302 - val_recall_7: 0.8903 - val_precision_7: 0.8607 - val_mean_io_u_7: 0.8853 - val_accuracy: 0.9954 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1309 - recall_7: 0.8901 - precision_7: 0.8597 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 75: val_loss improved from 0.12926 to 0.12862, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.1310 - recall_7: 0.8900 - precision_7: 0.8596 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1286 - val_recall_7: 0.8924 - val_precision_7: 0.8616 - val_mean_io_u_7: 0.8865 - val_accuracy: 0.9955 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1309 - recall_7: 0.8901 - precision_7: 0.8596 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 76: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1309 - recall_7: 0.8901 - precision_7: 0.8596 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1295 - val_recall_7: 0.8910 - val_precision_7: 0.8612 - val_mean_io_u_7: 0.8856 - val_accuracy: 0.9954 - val_auc: 0.9489 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1313 - recall_7: 0.8900 - precision_7: 0.8590 - mean_io_u_7: 0.8840 - accuracy: 0.9954 - auc: 0.9487\n",
      "Epoch 77: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1314 - recall_7: 0.8899 - precision_7: 0.8588 - mean_io_u_7: 0.8839 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.1300 - val_recall_7: 0.8913 - val_precision_7: 0.8601 - val_mean_io_u_7: 0.8853 - val_accuracy: 0.9954 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1312 - recall_7: 0.8901 - precision_7: 0.8591 - mean_io_u_7: 0.8841 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 78: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1311 - recall_7: 0.8902 - precision_7: 0.8592 - mean_io_u_7: 0.8841 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.1303 - val_recall_7: 0.8908 - val_precision_7: 0.8600 - val_mean_io_u_7: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1313 - recall_7: 0.8905 - precision_7: 0.8585 - mean_io_u_7: 0.8841 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 79: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1313 - recall_7: 0.8905 - precision_7: 0.8585 - mean_io_u_7: 0.8841 - accuracy: 0.9954 - auc: 0.9490 - val_loss: 0.1303 - val_recall_7: 0.8906 - val_precision_7: 0.8602 - val_mean_io_u_7: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1309 - recall_7: 0.8904 - precision_7: 0.8593 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 80: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1309 - recall_7: 0.8904 - precision_7: 0.8593 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9490 - val_loss: 0.1296 - val_recall_7: 0.8910 - val_precision_7: 0.8609 - val_mean_io_u_7: 0.8856 - val_accuracy: 0.9954 - val_auc: 0.9489 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1309 - recall_7: 0.8913 - precision_7: 0.8585 - mean_io_u_7: 0.8845 - accuracy: 0.9954 - auc: 0.9494\n",
      "Epoch 81: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1309 - recall_7: 0.8913 - precision_7: 0.8585 - mean_io_u_7: 0.8844 - accuracy: 0.9954 - auc: 0.9494 - val_loss: 0.1298 - val_recall_7: 0.8920 - val_precision_7: 0.8597 - val_mean_io_u_7: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9493 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1311 - recall_7: 0.8908 - precision_7: 0.8586 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 82: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1311 - recall_7: 0.8909 - precision_7: 0.8586 - mean_io_u_7: 0.8843 - accuracy: 0.9954 - auc: 0.9491 - val_loss: 0.1293 - val_recall_7: 0.8929 - val_precision_7: 0.8598 - val_mean_io_u_7: 0.8860 - val_accuracy: 0.9954 - val_auc: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1313 - recall_7: 0.8904 - precision_7: 0.8586 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 83: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1313 - recall_7: 0.8904 - precision_7: 0.8586 - mean_io_u_7: 0.8842 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.1298 - val_recall_7: 0.8914 - val_precision_7: 0.8602 - val_mean_io_u_7: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1308 - recall_7: 0.8904 - precision_7: 0.8595 - mean_io_u_7: 0.8844 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 84: val_loss did not improve from 0.12862\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1308 - recall_7: 0.8904 - precision_7: 0.8595 - mean_io_u_7: 0.8844 - accuracy: 0.9954 - auc: 0.9490 - val_loss: 0.1286 - val_recall_7: 0.8917 - val_precision_7: 0.8620 - val_mean_io_u_7: 0.8864 - val_accuracy: 0.9955 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1304 - recall_7: 0.8904 - precision_7: 0.8602 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 85: val_loss improved from 0.12862 to 0.12859, saving model to ./iter_wDice-3.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-3.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.1304 - recall_7: 0.8904 - precision_7: 0.8602 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.1286 - val_recall_7: 0.8921 - val_precision_7: 0.8619 - val_mean_io_u_7: 0.8864 - val_accuracy: 0.9955 - val_auc: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1304 - recall_7: 0.8914 - precision_7: 0.8593 - mean_io_u_7: 0.8848 - accuracy: 0.9954 - auc: 0.9495\n",
      "Epoch 86: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1303 - recall_7: 0.8915 - precision_7: 0.8594 - mean_io_u_7: 0.8849 - accuracy: 0.9954 - auc: 0.9495 - val_loss: 0.1288 - val_recall_7: 0.8919 - val_precision_7: 0.8617 - val_mean_io_u_7: 0.8864 - val_accuracy: 0.9955 - val_auc: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1304 - recall_7: 0.8913 - precision_7: 0.8594 - mean_io_u_7: 0.8848 - accuracy: 0.9954 - auc: 0.9493\n",
      "Epoch 87: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1304 - recall_7: 0.8913 - precision_7: 0.8594 - mean_io_u_7: 0.8848 - accuracy: 0.9954 - auc: 0.9494 - val_loss: 0.1287 - val_recall_7: 0.8919 - val_precision_7: 0.8617 - val_mean_io_u_7: 0.8863 - val_accuracy: 0.9955 - val_auc: 0.9493 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1303 - recall_7: 0.8905 - precision_7: 0.8602 - mean_io_u_7: 0.8847 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 88: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1303 - recall_7: 0.8905 - precision_7: 0.8602 - mean_io_u_7: 0.8847 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.1286 - val_recall_7: 0.8908 - val_precision_7: 0.8629 - val_mean_io_u_7: 0.8862 - val_accuracy: 0.9955 - val_auc: 0.9488 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1306 - recall_7: 0.8907 - precision_7: 0.8595 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9492\n",
      "Epoch 89: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1306 - recall_7: 0.8907 - precision_7: 0.8595 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9492 - val_loss: 0.1300 - val_recall_7: 0.8902 - val_precision_7: 0.8609 - val_mean_io_u_7: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1303 - recall_7: 0.8905 - precision_7: 0.8603 - mean_io_u_7: 0.8847 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 90: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1303 - recall_7: 0.8905 - precision_7: 0.8603 - mean_io_u_7: 0.8847 - accuracy: 0.9954 - auc: 0.9490 - val_loss: 0.1306 - val_recall_7: 0.8893 - val_precision_7: 0.8608 - val_mean_io_u_7: 0.8848 - val_accuracy: 0.9954 - val_auc: 0.9480 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1302 - recall_7: 0.8909 - precision_7: 0.8601 - mean_io_u_7: 0.8849 - accuracy: 0.9954 - auc: 0.9492\n",
      "Epoch 91: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1303 - recall_7: 0.8908 - precision_7: 0.8600 - mean_io_u_7: 0.8848 - accuracy: 0.9954 - auc: 0.9492 - val_loss: 0.1303 - val_recall_7: 0.8905 - val_precision_7: 0.8601 - val_mean_io_u_7: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1304 - recall_7: 0.8898 - precision_7: 0.8607 - mean_io_u_7: 0.8845 - accuracy: 0.9954 - auc: 0.9487\n",
      "Epoch 92: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1304 - recall_7: 0.8898 - precision_7: 0.8607 - mean_io_u_7: 0.8845 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.1291 - val_recall_7: 0.8901 - val_precision_7: 0.8628 - val_mean_io_u_7: 0.8859 - val_accuracy: 0.9955 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1302 - recall_7: 0.8903 - precision_7: 0.8607 - mean_io_u_7: 0.8848 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 93: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1302 - recall_7: 0.8903 - precision_7: 0.8607 - mean_io_u_7: 0.8847 - accuracy: 0.9954 - auc: 0.9490 - val_loss: 0.1291 - val_recall_7: 0.8912 - val_precision_7: 0.8617 - val_mean_io_u_7: 0.8858 - val_accuracy: 0.9955 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 94/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1304 - recall_7: 0.8909 - precision_7: 0.8596 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9493\n",
      "Epoch 94: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1305 - recall_7: 0.8909 - precision_7: 0.8596 - mean_io_u_7: 0.8846 - accuracy: 0.9954 - auc: 0.9493 - val_loss: 0.1286 - val_recall_7: 0.8916 - val_precision_7: 0.8622 - val_mean_io_u_7: 0.8864 - val_accuracy: 0.9955 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 95/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1299 - recall_7: 0.8910 - precision_7: 0.8606 - mean_io_u_7: 0.8851 - accuracy: 0.9954 - auc: 0.9493\n",
      "Epoch 95: val_loss did not improve from 0.12859\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1299 - recall_7: 0.8910 - precision_7: 0.8606 - mean_io_u_7: 0.8851 - accuracy: 0.9954 - auc: 0.9493 - val_loss: 0.1292 - val_recall_7: 0.8922 - val_precision_7: 0.8606 - val_mean_io_u_7: 0.8859 - val_accuracy: 0.9954 - val_auc: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 95: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f05a04c0f70>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.0697 - recall_8: 0.9865 - precision_8: 0.1117 - mean_io_u_8: 0.5451 - accuracy: 0.8585 - auc: 0.9448\n",
      "Epoch 1: val_loss improved from inf to 1.32384, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 26s 351ms/step - loss: 2.0697 - recall_8: 0.9865 - precision_8: 0.1117 - mean_io_u_8: 0.5451 - accuracy: 0.8585 - auc: 0.9448 - val_loss: 1.3238 - val_recall_8: 0.8083 - val_precision_8: 0.1941 - val_mean_io_u_8: 0.4986 - val_accuracy: 0.9361 - val_auc: 0.9371 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.3191 - recall_8: 0.9870 - precision_8: 0.2031 - mean_io_u_8: 0.5876 - accuracy: 0.9300 - auc: 0.9622\n",
      "Epoch 2: val_loss improved from 1.32384 to 0.97398, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 1.3191 - recall_8: 0.9870 - precision_8: 0.2031 - mean_io_u_8: 0.5876 - accuracy: 0.9300 - auc: 0.9622 - val_loss: 0.9740 - val_recall_8: 0.3739 - val_precision_8: 0.2435 - val_mean_io_u_8: 0.5607 - val_accuracy: 0.9678 - val_auc: 0.6777 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.8149 - recall_8: 0.9750 - precision_8: 0.3676 - mean_io_u_8: 0.6870 - accuracy: 0.9693 - auc: 0.9705\n",
      "Epoch 3: val_loss improved from 0.97398 to 0.62401, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 0.8149 - recall_8: 0.9750 - precision_8: 0.3676 - mean_io_u_8: 0.6870 - accuracy: 0.9693 - auc: 0.9705 - val_loss: 0.6240 - val_recall_8: 0.4051 - val_precision_8: 0.5879 - val_mean_io_u_8: 0.5612 - val_accuracy: 0.9842 - val_auc: 0.6704 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4708 - recall_8: 0.9253 - precision_8: 0.5749 - mean_io_u_8: 0.7740 - accuracy: 0.9863 - auc: 0.9518\n",
      "Epoch 4: val_loss did not improve from 0.62401\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.4708 - recall_8: 0.9253 - precision_8: 0.5749 - mean_io_u_8: 0.7740 - accuracy: 0.9863 - auc: 0.9518 - val_loss: 1.0995 - val_recall_8: 0.8958 - val_precision_8: 0.2139 - val_mean_io_u_8: 0.5851 - val_accuracy: 0.9388 - val_auc: 0.9235 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3178 - recall_8: 0.8841 - precision_8: 0.6989 - mean_io_u_8: 0.8175 - accuracy: 0.9910 - auc: 0.9487\n",
      "Epoch 5: val_loss improved from 0.62401 to 0.30651, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.3178 - recall_8: 0.8840 - precision_8: 0.6989 - mean_io_u_8: 0.8174 - accuracy: 0.9910 - auc: 0.9487 - val_loss: 0.3065 - val_recall_8: 0.7221 - val_precision_8: 0.7488 - val_mean_io_u_8: 0.7475 - val_accuracy: 0.9906 - val_auc: 0.8785 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2626 - recall_8: 0.8641 - precision_8: 0.7489 - mean_io_u_8: 0.8311 - accuracy: 0.9923 - auc: 0.9386\n",
      "Epoch 6: val_loss improved from 0.30651 to 0.24831, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 0.2626 - recall_8: 0.8642 - precision_8: 0.7489 - mean_io_u_8: 0.8311 - accuracy: 0.9923 - auc: 0.9387 - val_loss: 0.2483 - val_recall_8: 0.8802 - val_precision_8: 0.7213 - val_mean_io_u_8: 0.8244 - val_accuracy: 0.9917 - val_auc: 0.9427 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2447 - recall_8: 0.8581 - precision_8: 0.7628 - mean_io_u_8: 0.8342 - accuracy: 0.9926 - auc: 0.9347\n",
      "Epoch 7: val_loss improved from 0.24831 to 0.21364, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.2447 - recall_8: 0.8579 - precision_8: 0.7629 - mean_io_u_8: 0.8342 - accuracy: 0.9926 - auc: 0.9346 - val_loss: 0.2136 - val_recall_8: 0.8371 - val_precision_8: 0.7988 - val_mean_io_u_8: 0.8369 - val_accuracy: 0.9933 - val_auc: 0.9227 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2291 - recall_8: 0.8571 - precision_8: 0.7781 - mean_io_u_8: 0.8399 - accuracy: 0.9930 - auc: 0.9339\n",
      "Epoch 8: val_loss did not improve from 0.21364\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2289 - recall_8: 0.8572 - precision_8: 0.7782 - mean_io_u_8: 0.8400 - accuracy: 0.9930 - auc: 0.9340 - val_loss: 0.2142 - val_recall_8: 0.8622 - val_precision_8: 0.7790 - val_mean_io_u_8: 0.8424 - val_accuracy: 0.9931 - val_auc: 0.9329 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2243 - recall_8: 0.8553 - precision_8: 0.7815 - mean_io_u_8: 0.8407 - accuracy: 0.9931 - auc: 0.9321\n",
      "Epoch 9: val_loss improved from 0.21364 to 0.21106, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.2242 - recall_8: 0.8553 - precision_8: 0.7816 - mean_io_u_8: 0.8407 - accuracy: 0.9931 - auc: 0.9321 - val_loss: 0.2111 - val_recall_8: 0.8152 - val_precision_8: 0.8215 - val_mean_io_u_8: 0.8355 - val_accuracy: 0.9935 - val_auc: 0.9121 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2185 - recall_8: 0.8533 - precision_8: 0.7890 - mean_io_u_8: 0.8427 - accuracy: 0.9932 - auc: 0.9307\n",
      "Epoch 10: val_loss improved from 0.21106 to 0.20168, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.2185 - recall_8: 0.8532 - precision_8: 0.7891 - mean_io_u_8: 0.8427 - accuracy: 0.9932 - auc: 0.9306 - val_loss: 0.2017 - val_recall_8: 0.8414 - val_precision_8: 0.8139 - val_mean_io_u_8: 0.8460 - val_accuracy: 0.9937 - val_auc: 0.9237 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2141 - recall_8: 0.8535 - precision_8: 0.7931 - mean_io_u_8: 0.8444 - accuracy: 0.9933 - auc: 0.9303\n",
      "Epoch 11: val_loss improved from 0.20168 to 0.19874, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.2141 - recall_8: 0.8535 - precision_8: 0.7931 - mean_io_u_8: 0.8444 - accuracy: 0.9933 - auc: 0.9303 - val_loss: 0.1987 - val_recall_8: 0.8410 - val_precision_8: 0.8194 - val_mean_io_u_8: 0.8485 - val_accuracy: 0.9938 - val_auc: 0.9239 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2094 - recall_8: 0.8543 - precision_8: 0.7982 - mean_io_u_8: 0.8467 - accuracy: 0.9935 - auc: 0.9307\n",
      "Epoch 12: val_loss did not improve from 0.19874\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2094 - recall_8: 0.8542 - precision_8: 0.7983 - mean_io_u_8: 0.8467 - accuracy: 0.9935 - auc: 0.9307 - val_loss: 0.2011 - val_recall_8: 0.8460 - val_precision_8: 0.8118 - val_mean_io_u_8: 0.8488 - val_accuracy: 0.9937 - val_auc: 0.9256 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2062 - recall_8: 0.8541 - precision_8: 0.8021 - mean_io_u_8: 0.8481 - accuracy: 0.9936 - auc: 0.9304\n",
      "Epoch 13: val_loss did not improve from 0.19874\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2062 - recall_8: 0.8541 - precision_8: 0.8021 - mean_io_u_8: 0.8481 - accuracy: 0.9936 - auc: 0.9304 - val_loss: 0.2176 - val_recall_8: 0.8117 - val_precision_8: 0.8154 - val_mean_io_u_8: 0.8371 - val_accuracy: 0.9933 - val_auc: 0.9086 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2039 - recall_8: 0.8536 - precision_8: 0.8052 - mean_io_u_8: 0.8492 - accuracy: 0.9936 - auc: 0.9297\n",
      "Epoch 14: val_loss improved from 0.19874 to 0.19507, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 19s 301ms/step - loss: 0.2039 - recall_8: 0.8536 - precision_8: 0.8052 - mean_io_u_8: 0.8492 - accuracy: 0.9936 - auc: 0.9297 - val_loss: 0.1951 - val_recall_8: 0.8445 - val_precision_8: 0.8220 - val_mean_io_u_8: 0.8510 - val_accuracy: 0.9939 - val_auc: 0.9250 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2013 - recall_8: 0.8526 - precision_8: 0.8094 - mean_io_u_8: 0.8502 - accuracy: 0.9937 - auc: 0.9293\n",
      "Epoch 15: val_loss did not improve from 0.19507\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2013 - recall_8: 0.8526 - precision_8: 0.8095 - mean_io_u_8: 0.8502 - accuracy: 0.9937 - auc: 0.9293 - val_loss: 0.1957 - val_recall_8: 0.8620 - val_precision_8: 0.8072 - val_mean_io_u_8: 0.8542 - val_accuracy: 0.9938 - val_auc: 0.9326 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1990 - recall_8: 0.8544 - precision_8: 0.8111 - mean_io_u_8: 0.8516 - accuracy: 0.9938 - auc: 0.9303\n",
      "Epoch 16: val_loss did not improve from 0.19507\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1990 - recall_8: 0.8544 - precision_8: 0.8111 - mean_io_u_8: 0.8516 - accuracy: 0.9938 - auc: 0.9303 - val_loss: 0.2011 - val_recall_8: 0.8412 - val_precision_8: 0.8161 - val_mean_io_u_8: 0.8481 - val_accuracy: 0.9937 - val_auc: 0.9232 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1969 - recall_8: 0.8574 - precision_8: 0.8113 - mean_io_u_8: 0.8528 - accuracy: 0.9938 - auc: 0.9313\n",
      "Epoch 17: val_loss did not improve from 0.19507\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1969 - recall_8: 0.8575 - precision_8: 0.8114 - mean_io_u_8: 0.8529 - accuracy: 0.9938 - auc: 0.9314 - val_loss: 0.2124 - val_recall_8: 0.8342 - val_precision_8: 0.8036 - val_mean_io_u_8: 0.8414 - val_accuracy: 0.9933 - val_auc: 0.9193 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1954 - recall_8: 0.8569 - precision_8: 0.8136 - mean_io_u_8: 0.8537 - accuracy: 0.9939 - auc: 0.9310\n",
      "Epoch 18: val_loss improved from 0.19507 to 0.18585, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1954 - recall_8: 0.8570 - precision_8: 0.8136 - mean_io_u_8: 0.8538 - accuracy: 0.9939 - auc: 0.9311 - val_loss: 0.1859 - val_recall_8: 0.8612 - val_precision_8: 0.8225 - val_mean_io_u_8: 0.8589 - val_accuracy: 0.9941 - val_auc: 0.9325 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1913 - recall_8: 0.8584 - precision_8: 0.8183 - mean_io_u_8: 0.8561 - accuracy: 0.9940 - auc: 0.9317\n",
      "Epoch 19: val_loss did not improve from 0.18585\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1913 - recall_8: 0.8584 - precision_8: 0.8183 - mean_io_u_8: 0.8561 - accuracy: 0.9940 - auc: 0.9317 - val_loss: 0.1891 - val_recall_8: 0.8513 - val_precision_8: 0.8259 - val_mean_io_u_8: 0.8554 - val_accuracy: 0.9941 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1901 - recall_8: 0.8587 - precision_8: 0.8198 - mean_io_u_8: 0.8566 - accuracy: 0.9941 - auc: 0.9320\n",
      "Epoch 20: val_loss did not improve from 0.18585\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1901 - recall_8: 0.8587 - precision_8: 0.8198 - mean_io_u_8: 0.8566 - accuracy: 0.9941 - auc: 0.9320 - val_loss: 0.1989 - val_recall_8: 0.8579 - val_precision_8: 0.8053 - val_mean_io_u_8: 0.8521 - val_accuracy: 0.9937 - val_auc: 0.9303 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1889 - recall_8: 0.8603 - precision_8: 0.8200 - mean_io_u_8: 0.8576 - accuracy: 0.9941 - auc: 0.9325\n",
      "Epoch 21: val_loss did not improve from 0.18585\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1889 - recall_8: 0.8605 - precision_8: 0.8200 - mean_io_u_8: 0.8576 - accuracy: 0.9941 - auc: 0.9325 - val_loss: 0.1909 - val_recall_8: 0.8687 - val_precision_8: 0.8090 - val_mean_io_u_8: 0.8573 - val_accuracy: 0.9939 - val_auc: 0.9361 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1859 - recall_8: 0.8632 - precision_8: 0.8223 - mean_io_u_8: 0.8593 - accuracy: 0.9942 - auc: 0.9339\n",
      "Epoch 22: val_loss did not improve from 0.18585\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1858 - recall_8: 0.8632 - precision_8: 0.8224 - mean_io_u_8: 0.8594 - accuracy: 0.9942 - auc: 0.9339 - val_loss: 0.1890 - val_recall_8: 0.8382 - val_precision_8: 0.8376 - val_mean_io_u_8: 0.8541 - val_accuracy: 0.9942 - val_auc: 0.9221 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1827 - recall_8: 0.8626 - precision_8: 0.8277 - mean_io_u_8: 0.8611 - accuracy: 0.9943 - auc: 0.9337\n",
      "Epoch 23: val_loss improved from 0.18585 to 0.17887, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1826 - recall_8: 0.8626 - precision_8: 0.8278 - mean_io_u_8: 0.8612 - accuracy: 0.9943 - auc: 0.9337 - val_loss: 0.1789 - val_recall_8: 0.8628 - val_precision_8: 0.8324 - val_mean_io_u_8: 0.8633 - val_accuracy: 0.9944 - val_auc: 0.9333 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1806 - recall_8: 0.8663 - precision_8: 0.8276 - mean_io_u_8: 0.8626 - accuracy: 0.9943 - auc: 0.9355\n",
      "Epoch 24: val_loss did not improve from 0.17887\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1805 - recall_8: 0.8663 - precision_8: 0.8277 - mean_io_u_8: 0.8626 - accuracy: 0.9943 - auc: 0.9355 - val_loss: 0.1839 - val_recall_8: 0.8457 - val_precision_8: 0.8390 - val_mean_io_u_8: 0.8585 - val_accuracy: 0.9943 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1792 - recall_8: 0.8656 - precision_8: 0.8302 - mean_io_u_8: 0.8633 - accuracy: 0.9944 - auc: 0.9351\n",
      "Epoch 25: val_loss improved from 0.17887 to 0.17236, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 317ms/step - loss: 0.1792 - recall_8: 0.8656 - precision_8: 0.8302 - mean_io_u_8: 0.8633 - accuracy: 0.9944 - auc: 0.9351 - val_loss: 0.1724 - val_recall_8: 0.8829 - val_precision_8: 0.8260 - val_mean_io_u_8: 0.8693 - val_accuracy: 0.9945 - val_auc: 0.9427 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1786 - recall_8: 0.8687 - precision_8: 0.8285 - mean_io_u_8: 0.8638 - accuracy: 0.9944 - auc: 0.9367\n",
      "Epoch 26: val_loss improved from 0.17236 to 0.17123, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.1786 - recall_8: 0.8687 - precision_8: 0.8285 - mean_io_u_8: 0.8638 - accuracy: 0.9944 - auc: 0.9367 - val_loss: 0.1712 - val_recall_8: 0.8693 - val_precision_8: 0.8385 - val_mean_io_u_8: 0.8678 - val_accuracy: 0.9946 - val_auc: 0.9366 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1736 - recall_8: 0.8696 - precision_8: 0.8356 - mean_io_u_8: 0.8671 - accuracy: 0.9946 - auc: 0.9372\n",
      "Epoch 27: val_loss did not improve from 0.17123\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1735 - recall_8: 0.8696 - precision_8: 0.8356 - mean_io_u_8: 0.8671 - accuracy: 0.9946 - auc: 0.9372 - val_loss: 0.1847 - val_recall_8: 0.8496 - val_precision_8: 0.8342 - val_mean_io_u_8: 0.8579 - val_accuracy: 0.9942 - val_auc: 0.9274 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1720 - recall_8: 0.8704 - precision_8: 0.8372 - mean_io_u_8: 0.8677 - accuracy: 0.9946 - auc: 0.9378\n",
      "Epoch 28: val_loss improved from 0.17123 to 0.17104, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.1720 - recall_8: 0.8704 - precision_8: 0.8372 - mean_io_u_8: 0.8677 - accuracy: 0.9946 - auc: 0.9378 - val_loss: 0.1710 - val_recall_8: 0.8845 - val_precision_8: 0.8269 - val_mean_io_u_8: 0.8702 - val_accuracy: 0.9946 - val_auc: 0.9438 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1697 - recall_8: 0.8767 - precision_8: 0.8355 - mean_io_u_8: 0.8697 - accuracy: 0.9947 - auc: 0.9408\n",
      "Epoch 29: val_loss did not improve from 0.17104\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1697 - recall_8: 0.8767 - precision_8: 0.8355 - mean_io_u_8: 0.8697 - accuracy: 0.9947 - auc: 0.9408 - val_loss: 0.1729 - val_recall_8: 0.8680 - val_precision_8: 0.8373 - val_mean_io_u_8: 0.8668 - val_accuracy: 0.9946 - val_auc: 0.9367 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1665 - recall_8: 0.8774 - precision_8: 0.8401 - mean_io_u_8: 0.8715 - accuracy: 0.9948 - auc: 0.9412\n",
      "Epoch 30: val_loss improved from 0.17104 to 0.16311, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.1664 - recall_8: 0.8774 - precision_8: 0.8401 - mean_io_u_8: 0.8715 - accuracy: 0.9948 - auc: 0.9412 - val_loss: 0.1631 - val_recall_8: 0.8728 - val_precision_8: 0.8487 - val_mean_io_u_8: 0.8722 - val_accuracy: 0.9949 - val_auc: 0.9391 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1660 - recall_8: 0.8781 - precision_8: 0.8400 - mean_io_u_8: 0.8718 - accuracy: 0.9948 - auc: 0.9415\n",
      "Epoch 31: val_loss did not improve from 0.16311\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1660 - recall_8: 0.8781 - precision_8: 0.8400 - mean_io_u_8: 0.8718 - accuracy: 0.9948 - auc: 0.9415 - val_loss: 0.1642 - val_recall_8: 0.8573 - val_precision_8: 0.8608 - val_mean_io_u_8: 0.8700 - val_accuracy: 0.9949 - val_auc: 0.9318 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1656 - recall_8: 0.8783 - precision_8: 0.8404 - mean_io_u_8: 0.8720 - accuracy: 0.9948 - auc: 0.9417\n",
      "Epoch 32: val_loss did not improve from 0.16311\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1656 - recall_8: 0.8783 - precision_8: 0.8404 - mean_io_u_8: 0.8721 - accuracy: 0.9948 - auc: 0.9417 - val_loss: 0.1641 - val_recall_8: 0.8734 - val_precision_8: 0.8464 - val_mean_io_u_8: 0.8719 - val_accuracy: 0.9949 - val_auc: 0.9391 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1608 - recall_8: 0.8810 - precision_8: 0.8456 - mean_io_u_8: 0.8749 - accuracy: 0.9950 - auc: 0.9432\n",
      "Epoch 33: val_loss did not improve from 0.16311\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1609 - recall_8: 0.8809 - precision_8: 0.8456 - mean_io_u_8: 0.8749 - accuracy: 0.9950 - auc: 0.9432 - val_loss: 0.1633 - val_recall_8: 0.8738 - val_precision_8: 0.8473 - val_mean_io_u_8: 0.8728 - val_accuracy: 0.9949 - val_auc: 0.9394 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1584 - recall_8: 0.8832 - precision_8: 0.8476 - mean_io_u_8: 0.8768 - accuracy: 0.9950 - auc: 0.9442\n",
      "Epoch 34: val_loss improved from 0.16311 to 0.15335, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1585 - recall_8: 0.8832 - precision_8: 0.8474 - mean_io_u_8: 0.8767 - accuracy: 0.9950 - auc: 0.9442 - val_loss: 0.1533 - val_recall_8: 0.8979 - val_precision_8: 0.8425 - val_mean_io_u_8: 0.8818 - val_accuracy: 0.9951 - val_auc: 0.9504 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1566 - recall_8: 0.8850 - precision_8: 0.8488 - mean_io_u_8: 0.8779 - accuracy: 0.9951 - auc: 0.9451\n",
      "Epoch 35: val_loss did not improve from 0.15335\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1567 - recall_8: 0.8850 - precision_8: 0.8487 - mean_io_u_8: 0.8779 - accuracy: 0.9951 - auc: 0.9451 - val_loss: 0.1656 - val_recall_8: 0.8793 - val_precision_8: 0.8391 - val_mean_io_u_8: 0.8721 - val_accuracy: 0.9948 - val_auc: 0.9419 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1564 - recall_8: 0.8849 - precision_8: 0.8491 - mean_io_u_8: 0.8778 - accuracy: 0.9951 - auc: 0.9452\n",
      "Epoch 36: val_loss did not improve from 0.15335\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1564 - recall_8: 0.8850 - precision_8: 0.8491 - mean_io_u_8: 0.8778 - accuracy: 0.9951 - auc: 0.9452 - val_loss: 0.1638 - val_recall_8: 0.8818 - val_precision_8: 0.8397 - val_mean_io_u_8: 0.8733 - val_accuracy: 0.9948 - val_auc: 0.9430 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1527 - recall_8: 0.8883 - precision_8: 0.8521 - mean_io_u_8: 0.8803 - accuracy: 0.9952 - auc: 0.9470\n",
      "Epoch 37: val_loss did not improve from 0.15335\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1528 - recall_8: 0.8883 - precision_8: 0.8520 - mean_io_u_8: 0.8802 - accuracy: 0.9952 - auc: 0.9470 - val_loss: 0.1694 - val_recall_8: 0.8592 - val_precision_8: 0.8506 - val_mean_io_u_8: 0.8668 - val_accuracy: 0.9947 - val_auc: 0.9325 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1529 - recall_8: 0.8873 - precision_8: 0.8526 - mean_io_u_8: 0.8802 - accuracy: 0.9952 - auc: 0.9463\n",
      "Epoch 38: val_loss did not improve from 0.15335\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1528 - recall_8: 0.8873 - precision_8: 0.8527 - mean_io_u_8: 0.8802 - accuracy: 0.9952 - auc: 0.9463 - val_loss: 0.1575 - val_recall_8: 0.8711 - val_precision_8: 0.8604 - val_mean_io_u_8: 0.8762 - val_accuracy: 0.9951 - val_auc: 0.9386 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1502 - recall_8: 0.8890 - precision_8: 0.8553 - mean_io_u_8: 0.8819 - accuracy: 0.9953 - auc: 0.9474\n",
      "Epoch 39: val_loss improved from 0.15335 to 0.15263, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.1502 - recall_8: 0.8890 - precision_8: 0.8553 - mean_io_u_8: 0.8819 - accuracy: 0.9953 - auc: 0.9474 - val_loss: 0.1526 - val_recall_8: 0.8847 - val_precision_8: 0.8552 - val_mean_io_u_8: 0.8801 - val_accuracy: 0.9952 - val_auc: 0.9451 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1544 - recall_8: 0.8831 - precision_8: 0.8537 - mean_io_u_8: 0.8786 - accuracy: 0.9952 - auc: 0.9444\n",
      "Epoch 40: val_loss improved from 0.15263 to 0.14906, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 317ms/step - loss: 0.1544 - recall_8: 0.8831 - precision_8: 0.8537 - mean_io_u_8: 0.8786 - accuracy: 0.9952 - auc: 0.9444 - val_loss: 0.1491 - val_recall_8: 0.8912 - val_precision_8: 0.8550 - val_mean_io_u_8: 0.8837 - val_accuracy: 0.9953 - val_auc: 0.9478 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1477 - recall_8: 0.8905 - precision_8: 0.8579 - mean_io_u_8: 0.8836 - accuracy: 0.9954 - auc: 0.9479\n",
      "Epoch 41: val_loss did not improve from 0.14906\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.1477 - recall_8: 0.8905 - precision_8: 0.8579 - mean_io_u_8: 0.8836 - accuracy: 0.9954 - auc: 0.9479 - val_loss: 0.1618 - val_recall_8: 0.8593 - val_precision_8: 0.8624 - val_mean_io_u_8: 0.8707 - val_accuracy: 0.9950 - val_auc: 0.9333 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1478 - recall_8: 0.8911 - precision_8: 0.8574 - mean_io_u_8: 0.8837 - accuracy: 0.9954 - auc: 0.9482\n",
      "Epoch 42: val_loss did not improve from 0.14906\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1478 - recall_8: 0.8910 - precision_8: 0.8573 - mean_io_u_8: 0.8836 - accuracy: 0.9954 - auc: 0.9482 - val_loss: 0.1510 - val_recall_8: 0.8918 - val_precision_8: 0.8522 - val_mean_io_u_8: 0.8828 - val_accuracy: 0.9953 - val_auc: 0.9480 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1447 - recall_8: 0.8912 - precision_8: 0.8622 - mean_io_u_8: 0.8854 - accuracy: 0.9955 - auc: 0.9485\n",
      "Epoch 43: val_loss improved from 0.14906 to 0.14526, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.1447 - recall_8: 0.8912 - precision_8: 0.8622 - mean_io_u_8: 0.8854 - accuracy: 0.9955 - auc: 0.9485 - val_loss: 0.1453 - val_recall_8: 0.8851 - val_precision_8: 0.8663 - val_mean_io_u_8: 0.8835 - val_accuracy: 0.9955 - val_auc: 0.9455 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1428 - recall_8: 0.8941 - precision_8: 0.8626 - mean_io_u_8: 0.8867 - accuracy: 0.9955 - auc: 0.9499\n",
      "Epoch 44: val_loss improved from 0.14526 to 0.13910, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.1428 - recall_8: 0.8941 - precision_8: 0.8626 - mean_io_u_8: 0.8867 - accuracy: 0.9955 - auc: 0.9499 - val_loss: 0.1391 - val_recall_8: 0.8850 - val_precision_8: 0.8765 - val_mean_io_u_8: 0.8872 - val_accuracy: 0.9957 - val_auc: 0.9458 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1432 - recall_8: 0.8921 - precision_8: 0.8635 - mean_io_u_8: 0.8864 - accuracy: 0.9955 - auc: 0.9490\n",
      "Epoch 45: val_loss did not improve from 0.13910\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1433 - recall_8: 0.8921 - precision_8: 0.8635 - mean_io_u_8: 0.8864 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.1579 - val_recall_8: 0.8770 - val_precision_8: 0.8553 - val_mean_io_u_8: 0.8775 - val_accuracy: 0.9951 - val_auc: 0.9412 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1417 - recall_8: 0.8937 - precision_8: 0.8646 - mean_io_u_8: 0.8875 - accuracy: 0.9956 - auc: 0.9497\n",
      "Epoch 46: val_loss did not improve from 0.13910\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1417 - recall_8: 0.8937 - precision_8: 0.8645 - mean_io_u_8: 0.8875 - accuracy: 0.9956 - auc: 0.9497 - val_loss: 0.1411 - val_recall_8: 0.8942 - val_precision_8: 0.8649 - val_mean_io_u_8: 0.8875 - val_accuracy: 0.9956 - val_auc: 0.9498 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1411 - recall_8: 0.8940 - precision_8: 0.8653 - mean_io_u_8: 0.8879 - accuracy: 0.9956 - auc: 0.9498\n",
      "Epoch 47: val_loss did not improve from 0.13910\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1412 - recall_8: 0.8940 - precision_8: 0.8652 - mean_io_u_8: 0.8878 - accuracy: 0.9956 - auc: 0.9498 - val_loss: 0.1422 - val_recall_8: 0.8979 - val_precision_8: 0.8603 - val_mean_io_u_8: 0.8882 - val_accuracy: 0.9955 - val_auc: 0.9513 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1405 - recall_8: 0.8949 - precision_8: 0.8655 - mean_io_u_8: 0.8883 - accuracy: 0.9956 - auc: 0.9503\n",
      "Epoch 48: val_loss did not improve from 0.13910\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1405 - recall_8: 0.8949 - precision_8: 0.8655 - mean_io_u_8: 0.8883 - accuracy: 0.9956 - auc: 0.9503 - val_loss: 0.1402 - val_recall_8: 0.8908 - val_precision_8: 0.8703 - val_mean_io_u_8: 0.8882 - val_accuracy: 0.9956 - val_auc: 0.9486 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1376 - recall_8: 0.8951 - precision_8: 0.8699 - mean_io_u_8: 0.8901 - accuracy: 0.9957 - auc: 0.9505\n",
      "Epoch 49: val_loss did not improve from 0.13910\n",
      "\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1377 - recall_8: 0.8950 - precision_8: 0.8699 - mean_io_u_8: 0.8900 - accuracy: 0.9957 - auc: 0.9505 - val_loss: 0.1407 - val_recall_8: 0.8756 - val_precision_8: 0.8824 - val_mean_io_u_8: 0.8846 - val_accuracy: 0.9957 - val_auc: 0.9416 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1319 - recall_8: 0.8995 - precision_8: 0.8752 - mean_io_u_8: 0.8938 - accuracy: 0.9959 - auc: 0.9528\n",
      "Epoch 50: val_loss improved from 0.13910 to 0.12967, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1319 - recall_8: 0.8995 - precision_8: 0.8752 - mean_io_u_8: 0.8938 - accuracy: 0.9959 - auc: 0.9528 - val_loss: 0.1297 - val_recall_8: 0.9004 - val_precision_8: 0.8781 - val_mean_io_u_8: 0.8957 - val_accuracy: 0.9959 - val_auc: 0.9530 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1294 - recall_8: 0.9029 - precision_8: 0.8763 - mean_io_u_8: 0.8959 - accuracy: 0.9960 - auc: 0.9544\n",
      "Epoch 51: val_loss improved from 0.12967 to 0.12827, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 18s 283ms/step - loss: 0.1294 - recall_8: 0.9029 - precision_8: 0.8762 - mean_io_u_8: 0.8959 - accuracy: 0.9960 - auc: 0.9544 - val_loss: 0.1283 - val_recall_8: 0.8984 - val_precision_8: 0.8823 - val_mean_io_u_8: 0.8959 - val_accuracy: 0.9960 - val_auc: 0.9522 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1283 - recall_8: 0.9017 - precision_8: 0.8791 - mean_io_u_8: 0.8964 - accuracy: 0.9960 - auc: 0.9539\n",
      "Epoch 52: val_loss did not improve from 0.12827\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1283 - recall_8: 0.9018 - precision_8: 0.8791 - mean_io_u_8: 0.8964 - accuracy: 0.9960 - auc: 0.9539 - val_loss: 0.1307 - val_recall_8: 0.8971 - val_precision_8: 0.8794 - val_mean_io_u_8: 0.8943 - val_accuracy: 0.9959 - val_auc: 0.9515 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1280 - recall_8: 0.9040 - precision_8: 0.8776 - mean_io_u_8: 0.8970 - accuracy: 0.9960 - auc: 0.9549\n",
      "Epoch 53: val_loss did not improve from 0.12827\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1280 - recall_8: 0.9040 - precision_8: 0.8776 - mean_io_u_8: 0.8970 - accuracy: 0.9960 - auc: 0.9549 - val_loss: 0.1359 - val_recall_8: 0.8875 - val_precision_8: 0.8796 - val_mean_io_u_8: 0.8896 - val_accuracy: 0.9958 - val_auc: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1273 - recall_8: 0.9050 - precision_8: 0.8778 - mean_io_u_8: 0.8975 - accuracy: 0.9960 - auc: 0.9554\n",
      "Epoch 54: val_loss improved from 0.12827 to 0.12537, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.1272 - recall_8: 0.9051 - precision_8: 0.8779 - mean_io_u_8: 0.8976 - accuracy: 0.9960 - auc: 0.9554 - val_loss: 0.1254 - val_recall_8: 0.9046 - val_precision_8: 0.8813 - val_mean_io_u_8: 0.8989 - val_accuracy: 0.9961 - val_auc: 0.9550 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1270 - recall_8: 0.9036 - precision_8: 0.8795 - mean_io_u_8: 0.8974 - accuracy: 0.9960 - auc: 0.9547\n",
      "Epoch 55: val_loss did not improve from 0.12537\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.1271 - recall_8: 0.9036 - precision_8: 0.8794 - mean_io_u_8: 0.8974 - accuracy: 0.9960 - auc: 0.9547 - val_loss: 0.1257 - val_recall_8: 0.9052 - val_precision_8: 0.8802 - val_mean_io_u_8: 0.8988 - val_accuracy: 0.9961 - val_auc: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1265 - recall_8: 0.9041 - precision_8: 0.8799 - mean_io_u_8: 0.8978 - accuracy: 0.9960 - auc: 0.9550\n",
      "Epoch 56: val_loss improved from 0.12537 to 0.12510, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.1265 - recall_8: 0.9041 - precision_8: 0.8798 - mean_io_u_8: 0.8978 - accuracy: 0.9960 - auc: 0.9550 - val_loss: 0.1251 - val_recall_8: 0.8998 - val_precision_8: 0.8861 - val_mean_io_u_8: 0.8981 - val_accuracy: 0.9961 - val_auc: 0.9530 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1261 - recall_8: 0.9032 - precision_8: 0.8813 - mean_io_u_8: 0.8980 - accuracy: 0.9961 - auc: 0.9545\n",
      "Epoch 57: val_loss did not improve from 0.12510\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1261 - recall_8: 0.9032 - precision_8: 0.8813 - mean_io_u_8: 0.8980 - accuracy: 0.9961 - auc: 0.9546 - val_loss: 0.1285 - val_recall_8: 0.8978 - val_precision_8: 0.8822 - val_mean_io_u_8: 0.8960 - val_accuracy: 0.9960 - val_auc: 0.9520 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1260 - recall_8: 0.9051 - precision_8: 0.8798 - mean_io_u_8: 0.8985 - accuracy: 0.9961 - auc: 0.9555\n",
      "Epoch 58: val_loss did not improve from 0.12510\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1260 - recall_8: 0.9051 - precision_8: 0.8798 - mean_io_u_8: 0.8985 - accuracy: 0.9961 - auc: 0.9554 - val_loss: 0.1271 - val_recall_8: 0.8996 - val_precision_8: 0.8829 - val_mean_io_u_8: 0.8968 - val_accuracy: 0.9960 - val_auc: 0.9527 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1254 - recall_8: 0.9054 - precision_8: 0.8805 - mean_io_u_8: 0.8987 - accuracy: 0.9961 - auc: 0.9557\n",
      "Epoch 59: val_loss improved from 0.12510 to 0.12445, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 19s 289ms/step - loss: 0.1254 - recall_8: 0.9054 - precision_8: 0.8806 - mean_io_u_8: 0.8988 - accuracy: 0.9961 - auc: 0.9557 - val_loss: 0.1244 - val_recall_8: 0.9087 - val_precision_8: 0.8791 - val_mean_io_u_8: 0.9005 - val_accuracy: 0.9961 - val_auc: 0.9570 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1254 - recall_8: 0.9056 - precision_8: 0.8804 - mean_io_u_8: 0.8989 - accuracy: 0.9961 - auc: 0.9557\n",
      "Epoch 60: val_loss did not improve from 0.12445\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.1254 - recall_8: 0.9056 - precision_8: 0.8804 - mean_io_u_8: 0.8989 - accuracy: 0.9961 - auc: 0.9557 - val_loss: 0.1247 - val_recall_8: 0.9039 - val_precision_8: 0.8830 - val_mean_io_u_8: 0.8992 - val_accuracy: 0.9961 - val_auc: 0.9548 - lr: 1.0000e-04\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1251 - recall_8: 0.9047 - precision_8: 0.8817 - mean_io_u_8: 0.8989 - accuracy: 0.9961 - auc: 0.9553\n",
      "Epoch 61: val_loss did not improve from 0.12445\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1250 - recall_8: 0.9048 - precision_8: 0.8816 - mean_io_u_8: 0.8990 - accuracy: 0.9961 - auc: 0.9553 - val_loss: 0.1245 - val_recall_8: 0.9019 - val_precision_8: 0.8851 - val_mean_io_u_8: 0.8988 - val_accuracy: 0.9961 - val_auc: 0.9540 - lr: 1.0000e-04\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1246 - recall_8: 0.9043 - precision_8: 0.8828 - mean_io_u_8: 0.8990 - accuracy: 0.9961 - auc: 0.9551\n",
      "Epoch 62: val_loss did not improve from 0.12445\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1246 - recall_8: 0.9043 - precision_8: 0.8827 - mean_io_u_8: 0.8990 - accuracy: 0.9961 - auc: 0.9551 - val_loss: 0.1253 - val_recall_8: 0.8997 - val_precision_8: 0.8858 - val_mean_io_u_8: 0.8978 - val_accuracy: 0.9961 - val_auc: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 63/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1243 - recall_8: 0.9047 - precision_8: 0.8828 - mean_io_u_8: 0.8992 - accuracy: 0.9961 - auc: 0.9554\n",
      "Epoch 63: val_loss improved from 0.12445 to 0.12347, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 18s 274ms/step - loss: 0.1243 - recall_8: 0.9047 - precision_8: 0.8828 - mean_io_u_8: 0.8992 - accuracy: 0.9961 - auc: 0.9554 - val_loss: 0.1235 - val_recall_8: 0.9049 - val_precision_8: 0.8841 - val_mean_io_u_8: 0.9002 - val_accuracy: 0.9961 - val_auc: 0.9554 - lr: 1.0000e-04\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1244 - recall_8: 0.9055 - precision_8: 0.8820 - mean_io_u_8: 0.8994 - accuracy: 0.9961 - auc: 0.9558\n",
      "Epoch 64: val_loss did not improve from 0.12347\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1243 - recall_8: 0.9056 - precision_8: 0.8821 - mean_io_u_8: 0.8994 - accuracy: 0.9961 - auc: 0.9558 - val_loss: 0.1258 - val_recall_8: 0.9009 - val_precision_8: 0.8839 - val_mean_io_u_8: 0.8980 - val_accuracy: 0.9961 - val_auc: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1242 - recall_8: 0.9056 - precision_8: 0.8822 - mean_io_u_8: 0.8995 - accuracy: 0.9961 - auc: 0.9557\n",
      "Epoch 65: val_loss did not improve from 0.12347\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1243 - recall_8: 0.9055 - precision_8: 0.8822 - mean_io_u_8: 0.8995 - accuracy: 0.9961 - auc: 0.9557 - val_loss: 0.1241 - val_recall_8: 0.9035 - val_precision_8: 0.8842 - val_mean_io_u_8: 0.8995 - val_accuracy: 0.9961 - val_auc: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1240 - recall_8: 0.9068 - precision_8: 0.8815 - mean_io_u_8: 0.8997 - accuracy: 0.9961 - auc: 0.9564\n",
      "Epoch 66: val_loss improved from 0.12347 to 0.12261, saving model to ./iter_wDice-10.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-10.model/assets\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.1240 - recall_8: 0.9068 - precision_8: 0.8815 - mean_io_u_8: 0.8996 - accuracy: 0.9961 - auc: 0.9563 - val_loss: 0.1226 - val_recall_8: 0.9074 - val_precision_8: 0.8833 - val_mean_io_u_8: 0.9012 - val_accuracy: 0.9962 - val_auc: 0.9565 - lr: 1.0000e-04\n",
      "Epoch 67/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1241 - recall_8: 0.9061 - precision_8: 0.8820 - mean_io_u_8: 0.8996 - accuracy: 0.9961 - auc: 0.9560\n",
      "Epoch 67: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.1241 - recall_8: 0.9061 - precision_8: 0.8820 - mean_io_u_8: 0.8996 - accuracy: 0.9961 - auc: 0.9560 - val_loss: 0.1236 - val_recall_8: 0.9056 - val_precision_8: 0.8832 - val_mean_io_u_8: 0.9002 - val_accuracy: 0.9961 - val_auc: 0.9556 - lr: 1.0000e-04\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1234 - recall_8: 0.9062 - precision_8: 0.8831 - mean_io_u_8: 0.9002 - accuracy: 0.9961 - auc: 0.9560\n",
      "Epoch 68: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.1234 - recall_8: 0.9061 - precision_8: 0.8831 - mean_io_u_8: 0.9002 - accuracy: 0.9961 - auc: 0.9560 - val_loss: 0.1227 - val_recall_8: 0.9063 - val_precision_8: 0.8842 - val_mean_io_u_8: 0.9010 - val_accuracy: 0.9962 - val_auc: 0.9559 - lr: 1.0000e-04\n",
      "Epoch 69/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1231 - recall_8: 0.9055 - precision_8: 0.8842 - mean_io_u_8: 0.9002 - accuracy: 0.9962 - auc: 0.9556\n",
      "Epoch 69: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1231 - recall_8: 0.9055 - precision_8: 0.8841 - mean_io_u_8: 0.9002 - accuracy: 0.9962 - auc: 0.9556 - val_loss: 0.1245 - val_recall_8: 0.9023 - val_precision_8: 0.8847 - val_mean_io_u_8: 0.8989 - val_accuracy: 0.9961 - val_auc: 0.9541 - lr: 1.0000e-04\n",
      "Epoch 70/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1230 - recall_8: 0.9055 - precision_8: 0.8843 - mean_io_u_8: 0.9002 - accuracy: 0.9962 - auc: 0.9557\n",
      "Epoch 70: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1230 - recall_8: 0.9055 - precision_8: 0.8843 - mean_io_u_8: 0.9002 - accuracy: 0.9962 - auc: 0.9557 - val_loss: 0.1245 - val_recall_8: 0.9010 - val_precision_8: 0.8858 - val_mean_io_u_8: 0.8988 - val_accuracy: 0.9961 - val_auc: 0.9534 - lr: 1.0000e-04\n",
      "Epoch 71/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1225 - recall_8: 0.9065 - precision_8: 0.8841 - mean_io_u_8: 0.9007 - accuracy: 0.9962 - auc: 0.9562\n",
      "Epoch 71: val_loss did not improve from 0.12261\n",
      "\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1226 - recall_8: 0.9065 - precision_8: 0.8841 - mean_io_u_8: 0.9006 - accuracy: 0.9962 - auc: 0.9562 - val_loss: 0.1287 - val_recall_8: 0.8996 - val_precision_8: 0.8802 - val_mean_io_u_8: 0.8962 - val_accuracy: 0.9960 - val_auc: 0.9528 - lr: 1.0000e-04\n",
      "Epoch 72/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1226 - recall_8: 0.9071 - precision_8: 0.8835 - mean_io_u_8: 0.9007 - accuracy: 0.9962 - auc: 0.9565\n",
      "Epoch 72: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 11s 177ms/step - loss: 0.1226 - recall_8: 0.9071 - precision_8: 0.8835 - mean_io_u_8: 0.9007 - accuracy: 0.9962 - auc: 0.9565 - val_loss: 0.1282 - val_recall_8: 0.8975 - val_precision_8: 0.8830 - val_mean_io_u_8: 0.8961 - val_accuracy: 0.9960 - val_auc: 0.9519 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1219 - recall_8: 0.9070 - precision_8: 0.8848 - mean_io_u_8: 0.9011 - accuracy: 0.9962 - auc: 0.9564\n",
      "Epoch 73: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1219 - recall_8: 0.9070 - precision_8: 0.8848 - mean_io_u_8: 0.9011 - accuracy: 0.9962 - auc: 0.9564 - val_loss: 0.1273 - val_recall_8: 0.8977 - val_precision_8: 0.8842 - val_mean_io_u_8: 0.8966 - val_accuracy: 0.9960 - val_auc: 0.9519 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1220 - recall_8: 0.9073 - precision_8: 0.8842 - mean_io_u_8: 0.9011 - accuracy: 0.9962 - auc: 0.9566\n",
      "Epoch 74: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1221 - recall_8: 0.9072 - precision_8: 0.8842 - mean_io_u_8: 0.9010 - accuracy: 0.9962 - auc: 0.9565 - val_loss: 0.1231 - val_recall_8: 0.9039 - val_precision_8: 0.8854 - val_mean_io_u_8: 0.9001 - val_accuracy: 0.9962 - val_auc: 0.9549 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1218 - recall_8: 0.9077 - precision_8: 0.8841 - mean_io_u_8: 0.9012 - accuracy: 0.9962 - auc: 0.9568\n",
      "Epoch 75: val_loss did not improve from 0.12261\n",
      "65/65 [==============================] - 12s 178ms/step - loss: 0.1219 - recall_8: 0.9077 - precision_8: 0.8841 - mean_io_u_8: 0.9012 - accuracy: 0.9962 - auc: 0.9567 - val_loss: 0.1228 - val_recall_8: 0.9047 - val_precision_8: 0.8853 - val_mean_io_u_8: 0.9004 - val_accuracy: 0.9962 - val_auc: 0.9553 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1218 - recall_8: 0.9070 - precision_8: 0.8848 - mean_io_u_8: 0.9012 - accuracy: 0.9962 - auc: 0.9564\n",
      "Epoch 76: val_loss did not improve from 0.12261\n",
      "\n",
      "Epoch 76: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 12s 177ms/step - loss: 0.1218 - recall_8: 0.9070 - precision_8: 0.8849 - mean_io_u_8: 0.9012 - accuracy: 0.9962 - auc: 0.9564 - val_loss: 0.1236 - val_recall_8: 0.9027 - val_precision_8: 0.8858 - val_mean_io_u_8: 0.8997 - val_accuracy: 0.9961 - val_auc: 0.9543 - lr: 1.0000e-05\n",
      "Epoch 76: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f041c5638b0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 3.6969 - recall_9: 0.9853 - precision_9: 0.0898 - mean_io_u_9: 0.4911 - accuracy: 0.8199 - auc: 0.9329\n",
      "Epoch 1: val_loss improved from inf to 1.65671, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 25s 342ms/step - loss: 3.6932 - recall_9: 0.9854 - precision_9: 0.0900 - mean_io_u_9: 0.4911 - accuracy: 0.8201 - auc: 0.9329 - val_loss: 1.6567 - val_recall_9: 0.5006 - val_precision_9: 0.1652 - val_mean_io_u_9: 0.4922 - val_accuracy: 0.9454 - val_auc: 0.6573 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.0958 - recall_9: 0.9936 - precision_9: 0.1770 - mean_io_u_9: 0.5595 - accuracy: 0.9166 - auc: 0.9571\n",
      "Epoch 2: val_loss improved from 1.65671 to 1.38733, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 2.0958 - recall_9: 0.9936 - precision_9: 0.1770 - mean_io_u_9: 0.5595 - accuracy: 0.9166 - auc: 0.9571 - val_loss: 1.3873 - val_recall_9: 0.5497 - val_precision_9: 0.1944 - val_mean_io_u_9: 0.4910 - val_accuracy: 0.9508 - val_auc: 0.6616 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.3402 - recall_9: 0.9843 - precision_9: 0.2860 - mean_io_u_9: 0.6308 - accuracy: 0.9554 - auc: 0.9695\n",
      "Epoch 3: val_loss improved from 1.38733 to 0.78014, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 1.3402 - recall_9: 0.9843 - precision_9: 0.2860 - mean_io_u_9: 0.6308 - accuracy: 0.9554 - auc: 0.9695 - val_loss: 0.7801 - val_recall_9: 0.3874 - val_precision_9: 0.3991 - val_mean_io_u_9: 0.4968 - val_accuracy: 0.9784 - val_auc: 0.7208 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.7333 - recall_9: 0.9569 - precision_9: 0.4931 - mean_io_u_9: 0.7433 - accuracy: 0.9815 - auc: 0.9617\n",
      "Epoch 4: val_loss improved from 0.78014 to 0.65460, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.7333 - recall_9: 0.9569 - precision_9: 0.4931 - mean_io_u_9: 0.7433 - accuracy: 0.9815 - auc: 0.9617 - val_loss: 0.6546 - val_recall_9: 0.2667 - val_precision_9: 0.8125 - val_mean_io_u_9: 0.5329 - val_accuracy: 0.9857 - val_auc: 0.6748 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4193 - recall_9: 0.9086 - precision_9: 0.6701 - mean_io_u_9: 0.8155 - accuracy: 0.9903 - auc: 0.9484\n",
      "Epoch 5: val_loss improved from 0.65460 to 0.56081, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.4193 - recall_9: 0.9086 - precision_9: 0.6701 - mean_io_u_9: 0.8155 - accuracy: 0.9903 - auc: 0.9484 - val_loss: 0.5608 - val_recall_9: 0.3701 - val_precision_9: 0.7986 - val_mean_io_u_9: 0.6059 - val_accuracy: 0.9870 - val_auc: 0.7057 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3151 - recall_9: 0.8808 - precision_9: 0.7371 - mean_io_u_9: 0.8335 - accuracy: 0.9922 - auc: 0.9471\n",
      "Epoch 6: val_loss improved from 0.56081 to 0.34130, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.3151 - recall_9: 0.8808 - precision_9: 0.7371 - mean_io_u_9: 0.8335 - accuracy: 0.9922 - auc: 0.9471 - val_loss: 0.3413 - val_recall_9: 0.7243 - val_precision_9: 0.7434 - val_mean_io_u_9: 0.7730 - val_accuracy: 0.9905 - val_auc: 0.8699 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2771 - recall_9: 0.8680 - precision_9: 0.7649 - mean_io_u_9: 0.8392 - accuracy: 0.9928 - auc: 0.9407\n",
      "Epoch 7: val_loss improved from 0.34130 to 0.27106, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 305ms/step - loss: 0.2771 - recall_9: 0.8679 - precision_9: 0.7649 - mean_io_u_9: 0.8392 - accuracy: 0.9928 - auc: 0.9407 - val_loss: 0.2711 - val_recall_9: 0.8121 - val_precision_9: 0.7730 - val_mean_io_u_9: 0.8189 - val_accuracy: 0.9923 - val_auc: 0.9116 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2599 - recall_9: 0.8616 - precision_9: 0.7776 - mean_io_u_9: 0.8414 - accuracy: 0.9931 - auc: 0.9372\n",
      "Epoch 8: val_loss improved from 0.27106 to 0.24549, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 324ms/step - loss: 0.2597 - recall_9: 0.8618 - precision_9: 0.7778 - mean_io_u_9: 0.8415 - accuracy: 0.9931 - auc: 0.9372 - val_loss: 0.2455 - val_recall_9: 0.8565 - val_precision_9: 0.7754 - val_mean_io_u_9: 0.8385 - val_accuracy: 0.9929 - val_auc: 0.9316 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2512 - recall_9: 0.8593 - precision_9: 0.7832 - mean_io_u_9: 0.8428 - accuracy: 0.9932 - auc: 0.9350\n",
      "Epoch 9: val_loss improved from 0.24549 to 0.24491, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 304ms/step - loss: 0.2512 - recall_9: 0.8593 - precision_9: 0.7832 - mean_io_u_9: 0.8428 - accuracy: 0.9932 - auc: 0.9350 - val_loss: 0.2449 - val_recall_9: 0.8429 - val_precision_9: 0.7854 - val_mean_io_u_9: 0.8355 - val_accuracy: 0.9930 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2400 - recall_9: 0.8598 - precision_9: 0.7931 - mean_io_u_9: 0.8463 - accuracy: 0.9934 - auc: 0.9357\n",
      "Epoch 10: val_loss did not improve from 0.24491\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2400 - recall_9: 0.8599 - precision_9: 0.7930 - mean_io_u_9: 0.8464 - accuracy: 0.9934 - auc: 0.9358 - val_loss: 0.2487 - val_recall_9: 0.8323 - val_precision_9: 0.7882 - val_mean_io_u_9: 0.8320 - val_accuracy: 0.9929 - val_auc: 0.9214 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2334 - recall_9: 0.8592 - precision_9: 0.7991 - mean_io_u_9: 0.8483 - accuracy: 0.9936 - auc: 0.9351\n",
      "Epoch 11: val_loss improved from 0.24491 to 0.23940, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.2334 - recall_9: 0.8592 - precision_9: 0.7991 - mean_io_u_9: 0.8483 - accuracy: 0.9936 - auc: 0.9351 - val_loss: 0.2394 - val_recall_9: 0.8431 - val_precision_9: 0.7929 - val_mean_io_u_9: 0.8398 - val_accuracy: 0.9932 - val_auc: 0.9254 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2283 - recall_9: 0.8610 - precision_9: 0.8024 - mean_io_u_9: 0.8503 - accuracy: 0.9937 - auc: 0.9360\n",
      "Epoch 12: val_loss improved from 0.23940 to 0.22848, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.2283 - recall_9: 0.8610 - precision_9: 0.8024 - mean_io_u_9: 0.8503 - accuracy: 0.9937 - auc: 0.9360 - val_loss: 0.2285 - val_recall_9: 0.8419 - val_precision_9: 0.8085 - val_mean_io_u_9: 0.8442 - val_accuracy: 0.9936 - val_auc: 0.9253 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2238 - recall_9: 0.8600 - precision_9: 0.8078 - mean_io_u_9: 0.8517 - accuracy: 0.9938 - auc: 0.9355\n",
      "Epoch 13: val_loss improved from 0.22848 to 0.21842, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.2238 - recall_9: 0.8600 - precision_9: 0.8079 - mean_io_u_9: 0.8518 - accuracy: 0.9938 - auc: 0.9355 - val_loss: 0.2184 - val_recall_9: 0.8578 - val_precision_9: 0.8099 - val_mean_io_u_9: 0.8512 - val_accuracy: 0.9938 - val_auc: 0.9339 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2189 - recall_9: 0.8617 - precision_9: 0.8118 - mean_io_u_9: 0.8536 - accuracy: 0.9939 - auc: 0.9367\n",
      "Epoch 14: val_loss did not improve from 0.21842\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2189 - recall_9: 0.8617 - precision_9: 0.8118 - mean_io_u_9: 0.8536 - accuracy: 0.9939 - auc: 0.9367 - val_loss: 0.2499 - val_recall_9: 0.8573 - val_precision_9: 0.7707 - val_mean_io_u_9: 0.8365 - val_accuracy: 0.9928 - val_auc: 0.9324 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2339 - recall_9: 0.8558 - precision_9: 0.7959 - mean_io_u_9: 0.8458 - accuracy: 0.9934 - auc: 0.9333\n",
      "Epoch 15: val_loss did not improve from 0.21842\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2339 - recall_9: 0.8558 - precision_9: 0.7959 - mean_io_u_9: 0.8458 - accuracy: 0.9934 - auc: 0.9333 - val_loss: 0.4427 - val_recall_9: 0.5449 - val_precision_9: 0.7712 - val_mean_io_u_9: 0.7139 - val_accuracy: 0.9889 - val_auc: 0.7873 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2202 - recall_9: 0.8580 - precision_9: 0.8116 - mean_io_u_9: 0.8518 - accuracy: 0.9939 - auc: 0.9352\n",
      "Epoch 16: val_loss improved from 0.21842 to 0.21437, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 19s 297ms/step - loss: 0.2202 - recall_9: 0.8580 - precision_9: 0.8116 - mean_io_u_9: 0.8518 - accuracy: 0.9939 - auc: 0.9352 - val_loss: 0.2144 - val_recall_9: 0.8478 - val_precision_9: 0.8232 - val_mean_io_u_9: 0.8513 - val_accuracy: 0.9940 - val_auc: 0.9292 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2125 - recall_9: 0.8626 - precision_9: 0.8177 - mean_io_u_9: 0.8562 - accuracy: 0.9941 - auc: 0.9370\n",
      "Epoch 17: val_loss did not improve from 0.21437\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2125 - recall_9: 0.8626 - precision_9: 0.8177 - mean_io_u_9: 0.8562 - accuracy: 0.9941 - auc: 0.9370 - val_loss: 0.2455 - val_recall_9: 0.8429 - val_precision_9: 0.7851 - val_mean_io_u_9: 0.8369 - val_accuracy: 0.9930 - val_auc: 0.9252 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2050 - recall_9: 0.8657 - precision_9: 0.8250 - mean_io_u_9: 0.8597 - accuracy: 0.9943 - auc: 0.9385\n",
      "Epoch 18: val_loss improved from 0.21437 to 0.19556, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.2049 - recall_9: 0.8658 - precision_9: 0.8250 - mean_io_u_9: 0.8598 - accuracy: 0.9943 - auc: 0.9386 - val_loss: 0.1956 - val_recall_9: 0.8654 - val_precision_9: 0.8347 - val_mean_io_u_9: 0.8636 - val_accuracy: 0.9945 - val_auc: 0.9374 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2014 - recall_9: 0.8696 - precision_9: 0.8262 - mean_io_u_9: 0.8621 - accuracy: 0.9944 - auc: 0.9402\n",
      "Epoch 19: val_loss did not improve from 0.19556\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2013 - recall_9: 0.8697 - precision_9: 0.8263 - mean_io_u_9: 0.8622 - accuracy: 0.9944 - auc: 0.9403 - val_loss: 0.2342 - val_recall_9: 0.8250 - val_precision_9: 0.8135 - val_mean_io_u_9: 0.8378 - val_accuracy: 0.9934 - val_auc: 0.9185 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1973 - recall_9: 0.8711 - precision_9: 0.8305 - mean_io_u_9: 0.8644 - accuracy: 0.9945 - auc: 0.9407\n",
      "Epoch 20: val_loss did not improve from 0.19556\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1972 - recall_9: 0.8711 - precision_9: 0.8305 - mean_io_u_9: 0.8644 - accuracy: 0.9945 - auc: 0.9407 - val_loss: 0.2448 - val_recall_9: 0.8144 - val_precision_9: 0.8077 - val_mean_io_u_9: 0.8329 - val_accuracy: 0.9932 - val_auc: 0.9127 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1967 - recall_9: 0.8737 - precision_9: 0.8289 - mean_io_u_9: 0.8650 - accuracy: 0.9945 - auc: 0.9415\n",
      "Epoch 21: val_loss improved from 0.19556 to 0.19482, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.1967 - recall_9: 0.8737 - precision_9: 0.8289 - mean_io_u_9: 0.8650 - accuracy: 0.9945 - auc: 0.9415 - val_loss: 0.1948 - val_recall_9: 0.8707 - val_precision_9: 0.8316 - val_mean_io_u_9: 0.8652 - val_accuracy: 0.9945 - val_auc: 0.9396 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1901 - recall_9: 0.8763 - precision_9: 0.8356 - mean_io_u_9: 0.8683 - accuracy: 0.9947 - auc: 0.9432\n",
      "Epoch 22: val_loss did not improve from 0.19482\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1901 - recall_9: 0.8763 - precision_9: 0.8356 - mean_io_u_9: 0.8683 - accuracy: 0.9947 - auc: 0.9432 - val_loss: 0.2016 - val_recall_9: 0.8788 - val_precision_9: 0.8164 - val_mean_io_u_9: 0.8637 - val_accuracy: 0.9943 - val_auc: 0.9426 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1887 - recall_9: 0.8778 - precision_9: 0.8362 - mean_io_u_9: 0.8694 - accuracy: 0.9947 - auc: 0.9435\n",
      "Epoch 23: val_loss did not improve from 0.19482\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1887 - recall_9: 0.8778 - precision_9: 0.8362 - mean_io_u_9: 0.8694 - accuracy: 0.9947 - auc: 0.9435 - val_loss: 0.2046 - val_recall_9: 0.8555 - val_precision_9: 0.8302 - val_mean_io_u_9: 0.8580 - val_accuracy: 0.9942 - val_auc: 0.9322 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1842 - recall_9: 0.8787 - precision_9: 0.8415 - mean_io_u_9: 0.8716 - accuracy: 0.9948 - auc: 0.9441\n",
      "Epoch 24: val_loss did not improve from 0.19482\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1841 - recall_9: 0.8787 - precision_9: 0.8415 - mean_io_u_9: 0.8717 - accuracy: 0.9948 - auc: 0.9441 - val_loss: 0.2348 - val_recall_9: 0.8299 - val_precision_9: 0.8088 - val_mean_io_u_9: 0.8403 - val_accuracy: 0.9934 - val_auc: 0.9196 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1819 - recall_9: 0.8811 - precision_9: 0.8425 - mean_io_u_9: 0.8731 - accuracy: 0.9949 - auc: 0.9451\n",
      "Epoch 25: val_loss improved from 0.19482 to 0.19079, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.1820 - recall_9: 0.8810 - precision_9: 0.8425 - mean_io_u_9: 0.8731 - accuracy: 0.9949 - auc: 0.9450 - val_loss: 0.1908 - val_recall_9: 0.8679 - val_precision_9: 0.8393 - val_mean_io_u_9: 0.8668 - val_accuracy: 0.9946 - val_auc: 0.9384 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1768 - recall_9: 0.8828 - precision_9: 0.8481 - mean_io_u_9: 0.8758 - accuracy: 0.9950 - auc: 0.9460\n",
      "Epoch 26: val_loss did not improve from 0.19079\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1768 - recall_9: 0.8828 - precision_9: 0.8481 - mean_io_u_9: 0.8758 - accuracy: 0.9950 - auc: 0.9460 - val_loss: 0.2369 - val_recall_9: 0.8275 - val_precision_9: 0.8073 - val_mean_io_u_9: 0.8391 - val_accuracy: 0.9933 - val_auc: 0.9186 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1769 - recall_9: 0.8854 - precision_9: 0.8456 - mean_io_u_9: 0.8763 - accuracy: 0.9950 - auc: 0.9469\n",
      "Epoch 27: val_loss improved from 0.19079 to 0.18296, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.1769 - recall_9: 0.8855 - precision_9: 0.8457 - mean_io_u_9: 0.8764 - accuracy: 0.9950 - auc: 0.9469 - val_loss: 0.1830 - val_recall_9: 0.8633 - val_precision_9: 0.8541 - val_mean_io_u_9: 0.8691 - val_accuracy: 0.9949 - val_auc: 0.9363 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1750 - recall_9: 0.8838 - precision_9: 0.8495 - mean_io_u_9: 0.8771 - accuracy: 0.9951 - auc: 0.9462\n",
      "Epoch 28: val_loss improved from 0.18296 to 0.18137, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.1750 - recall_9: 0.8838 - precision_9: 0.8495 - mean_io_u_9: 0.8771 - accuracy: 0.9951 - auc: 0.9461 - val_loss: 0.1814 - val_recall_9: 0.8802 - val_precision_9: 0.8427 - val_mean_io_u_9: 0.8730 - val_accuracy: 0.9949 - val_auc: 0.9441 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1717 - recall_9: 0.8877 - precision_9: 0.8508 - mean_io_u_9: 0.8792 - accuracy: 0.9952 - auc: 0.9483\n",
      "Epoch 29: val_loss did not improve from 0.18137\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1717 - recall_9: 0.8877 - precision_9: 0.8508 - mean_io_u_9: 0.8792 - accuracy: 0.9952 - auc: 0.9483 - val_loss: 0.2020 - val_recall_9: 0.8511 - val_precision_9: 0.8372 - val_mean_io_u_9: 0.8591 - val_accuracy: 0.9943 - val_auc: 0.9297 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1682 - recall_9: 0.8878 - precision_9: 0.8555 - mean_io_u_9: 0.8810 - accuracy: 0.9953 - auc: 0.9482\n",
      "Epoch 30: val_loss did not improve from 0.18137\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1682 - recall_9: 0.8878 - precision_9: 0.8555 - mean_io_u_9: 0.8810 - accuracy: 0.9953 - auc: 0.9482 - val_loss: 0.1885 - val_recall_9: 0.8751 - val_precision_9: 0.8368 - val_mean_io_u_9: 0.8696 - val_accuracy: 0.9947 - val_auc: 0.9412 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1681 - recall_9: 0.8887 - precision_9: 0.8547 - mean_io_u_9: 0.8812 - accuracy: 0.9953 - auc: 0.9486\n",
      "Epoch 31: val_loss did not improve from 0.18137\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.1681 - recall_9: 0.8887 - precision_9: 0.8548 - mean_io_u_9: 0.8812 - accuracy: 0.9953 - auc: 0.9486 - val_loss: 0.1843 - val_recall_9: 0.8675 - val_precision_9: 0.8487 - val_mean_io_u_9: 0.8701 - val_accuracy: 0.9948 - val_auc: 0.9372 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1662 - recall_9: 0.8894 - precision_9: 0.8569 - mean_io_u_9: 0.8825 - accuracy: 0.9953 - auc: 0.9487\n",
      "Epoch 32: val_loss improved from 0.18137 to 0.17789, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 316ms/step - loss: 0.1662 - recall_9: 0.8894 - precision_9: 0.8569 - mean_io_u_9: 0.8825 - accuracy: 0.9953 - auc: 0.9487 - val_loss: 0.1779 - val_recall_9: 0.8646 - val_precision_9: 0.8598 - val_mean_io_u_9: 0.8724 - val_accuracy: 0.9950 - val_auc: 0.9363 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1650 - recall_9: 0.8894 - precision_9: 0.8584 - mean_io_u_9: 0.8828 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 33: val_loss did not improve from 0.17789\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1650 - recall_9: 0.8894 - precision_9: 0.8584 - mean_io_u_9: 0.8828 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1801 - val_recall_9: 0.8840 - val_precision_9: 0.8410 - val_mean_io_u_9: 0.8747 - val_accuracy: 0.9949 - val_auc: 0.9449 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1599 - recall_9: 0.8928 - precision_9: 0.8627 - mean_io_u_9: 0.8858 - accuracy: 0.9955 - auc: 0.9508\n",
      "Epoch 34: val_loss improved from 0.17789 to 0.16569, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.1600 - recall_9: 0.8927 - precision_9: 0.8626 - mean_io_u_9: 0.8858 - accuracy: 0.9955 - auc: 0.9508 - val_loss: 0.1657 - val_recall_9: 0.8870 - val_precision_9: 0.8586 - val_mean_io_u_9: 0.8827 - val_accuracy: 0.9953 - val_auc: 0.9473 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1586 - recall_9: 0.8952 - precision_9: 0.8624 - mean_io_u_9: 0.8869 - accuracy: 0.9955 - auc: 0.9518\n",
      "Epoch 35: val_loss did not improve from 0.16569\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1586 - recall_9: 0.8952 - precision_9: 0.8624 - mean_io_u_9: 0.8868 - accuracy: 0.9955 - auc: 0.9518 - val_loss: 0.2302 - val_recall_9: 0.8404 - val_precision_9: 0.8068 - val_mean_io_u_9: 0.8442 - val_accuracy: 0.9935 - val_auc: 0.9242 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1581 - recall_9: 0.8957 - precision_9: 0.8627 - mean_io_u_9: 0.8872 - accuracy: 0.9956 - auc: 0.9519\n",
      "Epoch 36: val_loss did not improve from 0.16569\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1581 - recall_9: 0.8957 - precision_9: 0.8627 - mean_io_u_9: 0.8872 - accuracy: 0.9956 - auc: 0.9519 - val_loss: 0.1878 - val_recall_9: 0.8654 - val_precision_9: 0.8454 - val_mean_io_u_9: 0.8683 - val_accuracy: 0.9947 - val_auc: 0.9367 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1561 - recall_9: 0.8952 - precision_9: 0.8660 - mean_io_u_9: 0.8881 - accuracy: 0.9956 - auc: 0.9517\n",
      "Epoch 37: val_loss did not improve from 0.16569\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1561 - recall_9: 0.8951 - precision_9: 0.8660 - mean_io_u_9: 0.8881 - accuracy: 0.9956 - auc: 0.9516 - val_loss: 0.2264 - val_recall_9: 0.8429 - val_precision_9: 0.8099 - val_mean_io_u_9: 0.8463 - val_accuracy: 0.9936 - val_auc: 0.9255 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1551 - recall_9: 0.8953 - precision_9: 0.8672 - mean_io_u_9: 0.8886 - accuracy: 0.9956 - auc: 0.9516\n",
      "Epoch 38: val_loss did not improve from 0.16569\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1551 - recall_9: 0.8952 - precision_9: 0.8673 - mean_io_u_9: 0.8886 - accuracy: 0.9956 - auc: 0.9516 - val_loss: 0.1672 - val_recall_9: 0.8871 - val_precision_9: 0.8564 - val_mean_io_u_9: 0.8817 - val_accuracy: 0.9953 - val_auc: 0.9465 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1520 - recall_9: 0.8985 - precision_9: 0.8689 - mean_io_u_9: 0.8908 - accuracy: 0.9957 - auc: 0.9531\n",
      "Epoch 39: val_loss did not improve from 0.16569\n",
      "\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1520 - recall_9: 0.8985 - precision_9: 0.8689 - mean_io_u_9: 0.8908 - accuracy: 0.9957 - auc: 0.9531 - val_loss: 0.1783 - val_recall_9: 0.8844 - val_precision_9: 0.8430 - val_mean_io_u_9: 0.8760 - val_accuracy: 0.9949 - val_auc: 0.9450 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1468 - recall_9: 0.9018 - precision_9: 0.8734 - mean_io_u_9: 0.8938 - accuracy: 0.9959 - auc: 0.9548\n",
      "Epoch 40: val_loss improved from 0.16569 to 0.16135, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 19s 299ms/step - loss: 0.1468 - recall_9: 0.9018 - precision_9: 0.8734 - mean_io_u_9: 0.8938 - accuracy: 0.9959 - auc: 0.9548 - val_loss: 0.1614 - val_recall_9: 0.8855 - val_precision_9: 0.8660 - val_mean_io_u_9: 0.8846 - val_accuracy: 0.9955 - val_auc: 0.9465 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1424 - recall_9: 0.9048 - precision_9: 0.8771 - mean_io_u_9: 0.8968 - accuracy: 0.9960 - auc: 0.9563\n",
      "Epoch 41: val_loss improved from 0.16135 to 0.15608, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.1424 - recall_9: 0.9048 - precision_9: 0.8771 - mean_io_u_9: 0.8968 - accuracy: 0.9960 - auc: 0.9563 - val_loss: 0.1561 - val_recall_9: 0.8918 - val_precision_9: 0.8683 - val_mean_io_u_9: 0.8880 - val_accuracy: 0.9956 - val_auc: 0.9496 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1416 - recall_9: 0.9035 - precision_9: 0.8793 - mean_io_u_9: 0.8970 - accuracy: 0.9960 - auc: 0.9558\n",
      "Epoch 42: val_loss improved from 0.15608 to 0.15223, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.1416 - recall_9: 0.9035 - precision_9: 0.8792 - mean_io_u_9: 0.8969 - accuracy: 0.9960 - auc: 0.9558 - val_loss: 0.1522 - val_recall_9: 0.8955 - val_precision_9: 0.8708 - val_mean_io_u_9: 0.8909 - val_accuracy: 0.9957 - val_auc: 0.9515 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1406 - recall_9: 0.9045 - precision_9: 0.8798 - mean_io_u_9: 0.8975 - accuracy: 0.9961 - auc: 0.9563\n",
      "Epoch 43: val_loss improved from 0.15223 to 0.14147, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 20s 308ms/step - loss: 0.1406 - recall_9: 0.9045 - precision_9: 0.8798 - mean_io_u_9: 0.8975 - accuracy: 0.9961 - auc: 0.9563 - val_loss: 0.1415 - val_recall_9: 0.9034 - val_precision_9: 0.8795 - val_mean_io_u_9: 0.8973 - val_accuracy: 0.9960 - val_auc: 0.9555 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1404 - recall_9: 0.9041 - precision_9: 0.8805 - mean_io_u_9: 0.8976 - accuracy: 0.9961 - auc: 0.9561\n",
      "Epoch 44: val_loss did not improve from 0.14147\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1403 - recall_9: 0.9041 - precision_9: 0.8806 - mean_io_u_9: 0.8977 - accuracy: 0.9961 - auc: 0.9561 - val_loss: 0.1425 - val_recall_9: 0.9038 - val_precision_9: 0.8777 - val_mean_io_u_9: 0.8973 - val_accuracy: 0.9960 - val_auc: 0.9556 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1392 - recall_9: 0.9054 - precision_9: 0.8810 - mean_io_u_9: 0.8985 - accuracy: 0.9961 - auc: 0.9567\n",
      "Epoch 45: val_loss did not improve from 0.14147\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1392 - recall_9: 0.9054 - precision_9: 0.8810 - mean_io_u_9: 0.8985 - accuracy: 0.9961 - auc: 0.9567 - val_loss: 0.1427 - val_recall_9: 0.9019 - val_precision_9: 0.8790 - val_mean_io_u_9: 0.8966 - val_accuracy: 0.9960 - val_auc: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1390 - recall_9: 0.9053 - precision_9: 0.8815 - mean_io_u_9: 0.8985 - accuracy: 0.9961 - auc: 0.9566\n",
      "Epoch 46: val_loss did not improve from 0.14147\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1390 - recall_9: 0.9053 - precision_9: 0.8815 - mean_io_u_9: 0.8984 - accuracy: 0.9961 - auc: 0.9566 - val_loss: 0.1438 - val_recall_9: 0.9014 - val_precision_9: 0.8776 - val_mean_io_u_9: 0.8961 - val_accuracy: 0.9960 - val_auc: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1387 - recall_9: 0.9066 - precision_9: 0.8808 - mean_io_u_9: 0.8990 - accuracy: 0.9961 - auc: 0.9573\n",
      "Epoch 47: val_loss did not improve from 0.14147\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1387 - recall_9: 0.9066 - precision_9: 0.8807 - mean_io_u_9: 0.8990 - accuracy: 0.9961 - auc: 0.9572 - val_loss: 0.1444 - val_recall_9: 0.9005 - val_precision_9: 0.8776 - val_mean_io_u_9: 0.8956 - val_accuracy: 0.9959 - val_auc: 0.9540 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1386 - recall_9: 0.9060 - precision_9: 0.8814 - mean_io_u_9: 0.8989 - accuracy: 0.9961 - auc: 0.9571\n",
      "Epoch 48: val_loss improved from 0.14147 to 0.13965, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 324ms/step - loss: 0.1386 - recall_9: 0.9060 - precision_9: 0.8814 - mean_io_u_9: 0.8989 - accuracy: 0.9961 - auc: 0.9571 - val_loss: 0.1396 - val_recall_9: 0.9055 - val_precision_9: 0.8802 - val_mean_io_u_9: 0.8985 - val_accuracy: 0.9961 - val_auc: 0.9565 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1380 - recall_9: 0.9066 - precision_9: 0.8818 - mean_io_u_9: 0.8993 - accuracy: 0.9961 - auc: 0.9573\n",
      "Epoch 49: val_loss improved from 0.13965 to 0.13907, saving model to ./iter_wDice-17.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-17.model/assets\n",
      "65/65 [==============================] - 21s 327ms/step - loss: 0.1380 - recall_9: 0.9066 - precision_9: 0.8818 - mean_io_u_9: 0.8993 - accuracy: 0.9961 - auc: 0.9573 - val_loss: 0.1391 - val_recall_9: 0.9040 - val_precision_9: 0.8823 - val_mean_io_u_9: 0.8987 - val_accuracy: 0.9961 - val_auc: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1376 - recall_9: 0.9058 - precision_9: 0.8830 - mean_io_u_9: 0.8993 - accuracy: 0.9961 - auc: 0.9569\n",
      "Epoch 50: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1376 - recall_9: 0.9058 - precision_9: 0.8830 - mean_io_u_9: 0.8993 - accuracy: 0.9961 - auc: 0.9569 - val_loss: 0.1773 - val_recall_9: 0.8706 - val_precision_9: 0.8563 - val_mean_io_u_9: 0.8750 - val_accuracy: 0.9950 - val_auc: 0.9390 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1368 - recall_9: 0.9063 - precision_9: 0.8837 - mean_io_u_9: 0.9000 - accuracy: 0.9962 - auc: 0.9571\n",
      "Epoch 51: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1368 - recall_9: 0.9063 - precision_9: 0.8836 - mean_io_u_9: 0.8999 - accuracy: 0.9962 - auc: 0.9571 - val_loss: 0.1395 - val_recall_9: 0.9022 - val_precision_9: 0.8834 - val_mean_io_u_9: 0.8985 - val_accuracy: 0.9961 - val_auc: 0.9548 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1370 - recall_9: 0.9060 - precision_9: 0.8837 - mean_io_u_9: 0.8998 - accuracy: 0.9962 - auc: 0.9571\n",
      "Epoch 52: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1370 - recall_9: 0.9060 - precision_9: 0.8837 - mean_io_u_9: 0.8998 - accuracy: 0.9962 - auc: 0.9571 - val_loss: 0.1444 - val_recall_9: 0.8987 - val_precision_9: 0.8792 - val_mean_io_u_9: 0.8954 - val_accuracy: 0.9959 - val_auc: 0.9532 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1364 - recall_9: 0.9070 - precision_9: 0.8836 - mean_io_u_9: 0.9001 - accuracy: 0.9962 - auc: 0.9576\n",
      "Epoch 53: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1364 - recall_9: 0.9070 - precision_9: 0.8836 - mean_io_u_9: 0.9001 - accuracy: 0.9962 - auc: 0.9576 - val_loss: 0.1457 - val_recall_9: 0.8985 - val_precision_9: 0.8775 - val_mean_io_u_9: 0.8949 - val_accuracy: 0.9959 - val_auc: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1363 - recall_9: 0.9080 - precision_9: 0.8830 - mean_io_u_9: 0.9005 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 54: val_loss did not improve from 0.13907\n",
      "\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1363 - recall_9: 0.9080 - precision_9: 0.8830 - mean_io_u_9: 0.9005 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1417 - val_recall_9: 0.9017 - val_precision_9: 0.8806 - val_mean_io_u_9: 0.8972 - val_accuracy: 0.9960 - val_auc: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1357 - recall_9: 0.9065 - precision_9: 0.8851 - mean_io_u_9: 0.9004 - accuracy: 0.9962 - auc: 0.9573\n",
      "Epoch 55: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1357 - recall_9: 0.9065 - precision_9: 0.8851 - mean_io_u_9: 0.9004 - accuracy: 0.9962 - auc: 0.9573 - val_loss: 0.1393 - val_recall_9: 0.9033 - val_precision_9: 0.8827 - val_mean_io_u_9: 0.8988 - val_accuracy: 0.9961 - val_auc: 0.9553 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1354 - recall_9: 0.9081 - precision_9: 0.8842 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 56: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.1354 - recall_9: 0.9081 - precision_9: 0.8842 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1411 - val_recall_9: 0.9024 - val_precision_9: 0.8807 - val_mean_io_u_9: 0.8978 - val_accuracy: 0.9960 - val_auc: 0.9549 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1355 - recall_9: 0.9080 - precision_9: 0.8841 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 57: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1355 - recall_9: 0.9080 - precision_9: 0.8841 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1409 - val_recall_9: 0.9019 - val_precision_9: 0.8815 - val_mean_io_u_9: 0.8977 - val_accuracy: 0.9960 - val_auc: 0.9547 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1356 - recall_9: 0.9077 - precision_9: 0.8842 - mean_io_u_9: 0.9008 - accuracy: 0.9962 - auc: 0.9578\n",
      "Epoch 58: val_loss did not improve from 0.13907\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1356 - recall_9: 0.9077 - precision_9: 0.8842 - mean_io_u_9: 0.9008 - accuracy: 0.9962 - auc: 0.9578 - val_loss: 0.1421 - val_recall_9: 0.9003 - val_precision_9: 0.8812 - val_mean_io_u_9: 0.8967 - val_accuracy: 0.9960 - val_auc: 0.9539 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1351 - recall_9: 0.9075 - precision_9: 0.8851 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9578\n",
      "Epoch 59: val_loss did not improve from 0.13907\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1351 - recall_9: 0.9075 - precision_9: 0.8851 - mean_io_u_9: 0.9009 - accuracy: 0.9962 - auc: 0.9578 - val_loss: 0.1415 - val_recall_9: 0.9005 - val_precision_9: 0.8819 - val_mean_io_u_9: 0.8971 - val_accuracy: 0.9960 - val_auc: 0.9540 - lr: 1.0000e-05\n",
      "Epoch 59: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f03607eb160>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 4.4031 - recall_10: 0.9839 - precision_10: 0.1044 - mean_io_u_10: 0.5283 - accuracy: 0.8476 - auc: 0.9402\n",
      "Epoch 1: val_loss improved from inf to 2.47382, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 26s 358ms/step - loss: 4.4031 - recall_10: 0.9839 - precision_10: 0.1044 - mean_io_u_10: 0.5283 - accuracy: 0.8476 - auc: 0.9402 - val_loss: 2.4738 - val_recall_10: 0.8038 - val_precision_10: 0.1714 - val_mean_io_u_10: 0.5297 - val_accuracy: 0.9264 - val_auc: 0.8738 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 2.3695 - recall_10: 0.9901 - precision_10: 0.2007 - mean_io_u_10: 0.5778 - accuracy: 0.9288 - auc: 0.9607\n",
      "Epoch 2: val_loss improved from 2.47382 to 1.34554, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 338ms/step - loss: 2.3695 - recall_10: 0.9901 - precision_10: 0.2007 - mean_io_u_10: 0.5778 - accuracy: 0.9288 - auc: 0.9607 - val_loss: 1.3455 - val_recall_10: 0.5669 - val_precision_10: 0.2454 - val_mean_io_u_10: 0.4951 - val_accuracy: 0.9608 - val_auc: 0.8178 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 1.3696 - recall_10: 0.9799 - precision_10: 0.3404 - mean_io_u_10: 0.6626 - accuracy: 0.9654 - auc: 0.9711\n",
      "Epoch 3: val_loss improved from 1.34554 to 0.69534, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 1.3685 - recall_10: 0.9798 - precision_10: 0.3406 - mean_io_u_10: 0.6627 - accuracy: 0.9655 - auc: 0.9711 - val_loss: 0.6953 - val_recall_10: 0.6798 - val_precision_10: 0.4883 - val_mean_io_u_10: 0.6006 - val_accuracy: 0.9814 - val_auc: 0.8728 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.7489 - recall_10: 0.9489 - precision_10: 0.5307 - mean_io_u_10: 0.7601 - accuracy: 0.9840 - auc: 0.9580\n",
      "Epoch 4: val_loss did not improve from 0.69534\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.7489 - recall_10: 0.9489 - precision_10: 0.5307 - mean_io_u_10: 0.7601 - accuracy: 0.9840 - auc: 0.9580 - val_loss: 20.0639 - val_recall_10: 0.6389 - val_precision_10: 0.0141 - val_mean_io_u_10: 0.5711 - val_accuracy: 0.1870 - val_auc: 0.3786 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4514 - recall_10: 0.9055 - precision_10: 0.6788 - mean_io_u_10: 0.8169 - accuracy: 0.9906 - auc: 0.9519\n",
      "Epoch 5: val_loss did not improve from 0.69534\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.4513 - recall_10: 0.9053 - precision_10: 0.6788 - mean_io_u_10: 0.8168 - accuracy: 0.9906 - auc: 0.9519 - val_loss: 19.0767 - val_recall_10: 0.6892 - val_precision_10: 0.0160 - val_mean_io_u_10: 0.1272 - val_accuracy: 0.2281 - val_auc: 0.4476 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3584 - recall_10: 0.8797 - precision_10: 0.7313 - mean_io_u_10: 0.8302 - accuracy: 0.9920 - auc: 0.9446\n",
      "Epoch 6: val_loss improved from 0.69534 to 0.54160, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 343ms/step - loss: 0.3583 - recall_10: 0.8798 - precision_10: 0.7313 - mean_io_u_10: 0.8302 - accuracy: 0.9920 - auc: 0.9446 - val_loss: 0.5416 - val_recall_10: 0.8389 - val_precision_10: 0.7256 - val_mean_io_u_10: 0.8247 - val_accuracy: 0.9914 - val_auc: 0.9137 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3169 - recall_10: 0.8674 - precision_10: 0.7579 - mean_io_u_10: 0.8366 - accuracy: 0.9926 - auc: 0.9386\n",
      "Epoch 7: val_loss improved from 0.54160 to 0.27659, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 344ms/step - loss: 0.3169 - recall_10: 0.8673 - precision_10: 0.7580 - mean_io_u_10: 0.8365 - accuracy: 0.9926 - auc: 0.9385 - val_loss: 0.2766 - val_recall_10: 0.8047 - val_precision_10: 0.8088 - val_mean_io_u_10: 0.8221 - val_accuracy: 0.9930 - val_auc: 0.9095 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2936 - recall_10: 0.8628 - precision_10: 0.7740 - mean_io_u_10: 0.8411 - accuracy: 0.9930 - auc: 0.9362\n",
      "Epoch 8: val_loss improved from 0.27659 to 0.25984, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.2934 - recall_10: 0.8629 - precision_10: 0.7742 - mean_io_u_10: 0.8412 - accuracy: 0.9930 - auc: 0.9363 - val_loss: 0.2598 - val_recall_10: 0.8208 - val_precision_10: 0.8171 - val_mean_io_u_10: 0.8372 - val_accuracy: 0.9935 - val_auc: 0.9150 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2808 - recall_10: 0.8578 - precision_10: 0.7848 - mean_io_u_10: 0.8433 - accuracy: 0.9932 - auc: 0.9332\n",
      "Epoch 9: val_loss did not improve from 0.25984\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.2807 - recall_10: 0.8578 - precision_10: 0.7848 - mean_io_u_10: 0.8433 - accuracy: 0.9932 - auc: 0.9332 - val_loss: 0.2661 - val_recall_10: 0.8811 - val_precision_10: 0.7707 - val_mean_io_u_10: 0.8472 - val_accuracy: 0.9931 - val_auc: 0.9421 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2736 - recall_10: 0.8569 - precision_10: 0.7893 - mean_io_u_10: 0.8446 - accuracy: 0.9933 - auc: 0.9326\n",
      "Epoch 10: val_loss did not improve from 0.25984\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2736 - recall_10: 0.8569 - precision_10: 0.7893 - mean_io_u_10: 0.8446 - accuracy: 0.9933 - auc: 0.9326 - val_loss: 0.2732 - val_recall_10: 0.8332 - val_precision_10: 0.7931 - val_mean_io_u_10: 0.8380 - val_accuracy: 0.9931 - val_auc: 0.9199 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2658 - recall_10: 0.8559 - precision_10: 0.7961 - mean_io_u_10: 0.8469 - accuracy: 0.9935 - auc: 0.9317\n",
      "Epoch 11: val_loss improved from 0.25984 to 0.24788, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 358ms/step - loss: 0.2658 - recall_10: 0.8559 - precision_10: 0.7961 - mean_io_u_10: 0.8469 - accuracy: 0.9935 - auc: 0.9317 - val_loss: 0.2479 - val_recall_10: 0.8514 - val_precision_10: 0.8105 - val_mean_io_u_10: 0.8504 - val_accuracy: 0.9937 - val_auc: 0.9284 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2599 - recall_10: 0.8575 - precision_10: 0.7996 - mean_io_u_10: 0.8488 - accuracy: 0.9936 - auc: 0.9322\n",
      "Epoch 12: val_loss did not improve from 0.24788\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.2599 - recall_10: 0.8575 - precision_10: 0.7996 - mean_io_u_10: 0.8488 - accuracy: 0.9936 - auc: 0.9322 - val_loss: 0.2565 - val_recall_10: 0.8691 - val_precision_10: 0.7890 - val_mean_io_u_10: 0.8495 - val_accuracy: 0.9934 - val_auc: 0.9359 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2587 - recall_10: 0.8536 - precision_10: 0.8023 - mean_io_u_10: 0.8484 - accuracy: 0.9936 - auc: 0.9300\n",
      "Epoch 13: val_loss did not improve from 0.24788\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2587 - recall_10: 0.8536 - precision_10: 0.8023 - mean_io_u_10: 0.8484 - accuracy: 0.9936 - auc: 0.9300 - val_loss: 0.2485 - val_recall_10: 0.8652 - val_precision_10: 0.7997 - val_mean_io_u_10: 0.8520 - val_accuracy: 0.9937 - val_auc: 0.9348 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2536 - recall_10: 0.8589 - precision_10: 0.8034 - mean_io_u_10: 0.8506 - accuracy: 0.9937 - auc: 0.9326\n",
      "Epoch 14: val_loss improved from 0.24788 to 0.24123, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 335ms/step - loss: 0.2537 - recall_10: 0.8588 - precision_10: 0.8033 - mean_io_u_10: 0.8506 - accuracy: 0.9937 - auc: 0.9325 - val_loss: 0.2412 - val_recall_10: 0.8460 - val_precision_10: 0.8217 - val_mean_io_u_10: 0.8519 - val_accuracy: 0.9939 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2491 - recall_10: 0.8558 - precision_10: 0.8098 - mean_io_u_10: 0.8519 - accuracy: 0.9938 - auc: 0.9311\n",
      "Epoch 15: val_loss did not improve from 0.24123\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2491 - recall_10: 0.8559 - precision_10: 0.8099 - mean_io_u_10: 0.8519 - accuracy: 0.9938 - auc: 0.9312 - val_loss: 0.2430 - val_recall_10: 0.8479 - val_precision_10: 0.8179 - val_mean_io_u_10: 0.8516 - val_accuracy: 0.9939 - val_auc: 0.9265 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2453 - recall_10: 0.8611 - precision_10: 0.8098 - mean_io_u_10: 0.8539 - accuracy: 0.9939 - auc: 0.9336\n",
      "Epoch 16: val_loss did not improve from 0.24123\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2453 - recall_10: 0.8611 - precision_10: 0.8098 - mean_io_u_10: 0.8539 - accuracy: 0.9939 - auc: 0.9336 - val_loss: 0.2428 - val_recall_10: 0.8344 - val_precision_10: 0.8285 - val_mean_io_u_10: 0.8494 - val_accuracy: 0.9939 - val_auc: 0.9205 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2420 - recall_10: 0.8617 - precision_10: 0.8128 - mean_io_u_10: 0.8551 - accuracy: 0.9939 - auc: 0.9338\n",
      "Epoch 17: val_loss did not improve from 0.24123\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2418 - recall_10: 0.8617 - precision_10: 0.8129 - mean_io_u_10: 0.8552 - accuracy: 0.9939 - auc: 0.9338 - val_loss: 0.2562 - val_recall_10: 0.8255 - val_precision_10: 0.8195 - val_mean_io_u_10: 0.8422 - val_accuracy: 0.9936 - val_auc: 0.9163 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2373 - recall_10: 0.8630 - precision_10: 0.8169 - mean_io_u_10: 0.8573 - accuracy: 0.9940 - auc: 0.9345\n",
      "Epoch 18: val_loss improved from 0.24123 to 0.22581, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 353ms/step - loss: 0.2373 - recall_10: 0.8630 - precision_10: 0.8169 - mean_io_u_10: 0.8573 - accuracy: 0.9940 - auc: 0.9345 - val_loss: 0.2258 - val_recall_10: 0.8598 - val_precision_10: 0.8302 - val_mean_io_u_10: 0.8605 - val_accuracy: 0.9943 - val_auc: 0.9329 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2324 - recall_10: 0.8648 - precision_10: 0.8209 - mean_io_u_10: 0.8596 - accuracy: 0.9942 - auc: 0.9353\n",
      "Epoch 19: val_loss did not improve from 0.22581\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2323 - recall_10: 0.8649 - precision_10: 0.8209 - mean_io_u_10: 0.8596 - accuracy: 0.9942 - auc: 0.9354 - val_loss: 0.2375 - val_recall_10: 0.8632 - val_precision_10: 0.8134 - val_mean_io_u_10: 0.8563 - val_accuracy: 0.9940 - val_auc: 0.9335 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2318 - recall_10: 0.8652 - precision_10: 0.8210 - mean_io_u_10: 0.8594 - accuracy: 0.9942 - auc: 0.9359\n",
      "Epoch 20: val_loss did not improve from 0.22581\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2317 - recall_10: 0.8653 - precision_10: 0.8211 - mean_io_u_10: 0.8595 - accuracy: 0.9942 - auc: 0.9360 - val_loss: 0.2309 - val_recall_10: 0.8396 - val_precision_10: 0.8397 - val_mean_io_u_10: 0.8556 - val_accuracy: 0.9942 - val_auc: 0.9231 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2253 - recall_10: 0.8683 - precision_10: 0.8262 - mean_io_u_10: 0.8627 - accuracy: 0.9943 - auc: 0.9374\n",
      "Epoch 21: val_loss did not improve from 0.22581\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2253 - recall_10: 0.8683 - precision_10: 0.8262 - mean_io_u_10: 0.8627 - accuracy: 0.9943 - auc: 0.9374 - val_loss: 0.2332 - val_recall_10: 0.8688 - val_precision_10: 0.8156 - val_mean_io_u_10: 0.8594 - val_accuracy: 0.9941 - val_auc: 0.9361 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2213 - recall_10: 0.8709 - precision_10: 0.8288 - mean_io_u_10: 0.8648 - accuracy: 0.9944 - auc: 0.9387\n",
      "Epoch 22: val_loss improved from 0.22581 to 0.21990, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 351ms/step - loss: 0.2213 - recall_10: 0.8709 - precision_10: 0.8288 - mean_io_u_10: 0.8648 - accuracy: 0.9944 - auc: 0.9387 - val_loss: 0.2199 - val_recall_10: 0.8715 - val_precision_10: 0.8284 - val_mean_io_u_10: 0.8653 - val_accuracy: 0.9944 - val_auc: 0.9386 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2215 - recall_10: 0.8721 - precision_10: 0.8274 - mean_io_u_10: 0.8647 - accuracy: 0.9944 - auc: 0.9392\n",
      "Epoch 23: val_loss improved from 0.21990 to 0.21665, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 326ms/step - loss: 0.2215 - recall_10: 0.8721 - precision_10: 0.8274 - mean_io_u_10: 0.8647 - accuracy: 0.9944 - auc: 0.9392 - val_loss: 0.2167 - val_recall_10: 0.8682 - val_precision_10: 0.8345 - val_mean_io_u_10: 0.8658 - val_accuracy: 0.9945 - val_auc: 0.9369 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2138 - recall_10: 0.8733 - precision_10: 0.8357 - mean_io_u_10: 0.8684 - accuracy: 0.9946 - auc: 0.9399\n",
      "Epoch 24: val_loss did not improve from 0.21665\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2138 - recall_10: 0.8733 - precision_10: 0.8358 - mean_io_u_10: 0.8684 - accuracy: 0.9946 - auc: 0.9399 - val_loss: 0.2257 - val_recall_10: 0.8644 - val_precision_10: 0.8261 - val_mean_io_u_10: 0.8611 - val_accuracy: 0.9943 - val_auc: 0.9345 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2091 - recall_10: 0.8775 - precision_10: 0.8378 - mean_io_u_10: 0.8708 - accuracy: 0.9947 - auc: 0.9421\n",
      "Epoch 25: val_loss did not improve from 0.21665\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2092 - recall_10: 0.8774 - precision_10: 0.8378 - mean_io_u_10: 0.8707 - accuracy: 0.9947 - auc: 0.9421 - val_loss: 0.2278 - val_recall_10: 0.8688 - val_precision_10: 0.8209 - val_mean_io_u_10: 0.8613 - val_accuracy: 0.9942 - val_auc: 0.9363 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2046 - recall_10: 0.8802 - precision_10: 0.8411 - mean_io_u_10: 0.8731 - accuracy: 0.9948 - auc: 0.9433\n",
      "Epoch 26: val_loss improved from 0.21665 to 0.21415, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 350ms/step - loss: 0.2046 - recall_10: 0.8802 - precision_10: 0.8411 - mean_io_u_10: 0.8731 - accuracy: 0.9948 - auc: 0.9433 - val_loss: 0.2141 - val_recall_10: 0.8451 - val_precision_10: 0.8555 - val_mean_io_u_10: 0.8628 - val_accuracy: 0.9946 - val_auc: 0.9258 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2008 - recall_10: 0.8817 - precision_10: 0.8445 - mean_io_u_10: 0.8749 - accuracy: 0.9949 - auc: 0.9444\n",
      "Epoch 27: val_loss improved from 0.21415 to 0.20503, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 334ms/step - loss: 0.2008 - recall_10: 0.8817 - precision_10: 0.8445 - mean_io_u_10: 0.8749 - accuracy: 0.9949 - auc: 0.9444 - val_loss: 0.2050 - val_recall_10: 0.8706 - val_precision_10: 0.8470 - val_mean_io_u_10: 0.8715 - val_accuracy: 0.9948 - val_auc: 0.9380 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2018 - recall_10: 0.8804 - precision_10: 0.8441 - mean_io_u_10: 0.8743 - accuracy: 0.9949 - auc: 0.9436\n",
      "Epoch 28: val_loss improved from 0.20503 to 0.19665, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.2018 - recall_10: 0.8804 - precision_10: 0.8441 - mean_io_u_10: 0.8743 - accuracy: 0.9949 - auc: 0.9436 - val_loss: 0.1966 - val_recall_10: 0.8877 - val_precision_10: 0.8437 - val_mean_io_u_10: 0.8775 - val_accuracy: 0.9950 - val_auc: 0.9466 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1956 - recall_10: 0.8861 - precision_10: 0.8470 - mean_io_u_10: 0.8779 - accuracy: 0.9951 - auc: 0.9465\n",
      "Epoch 29: val_loss improved from 0.19665 to 0.19354, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 357ms/step - loss: 0.1956 - recall_10: 0.8861 - precision_10: 0.8470 - mean_io_u_10: 0.8779 - accuracy: 0.9951 - auc: 0.9465 - val_loss: 0.1935 - val_recall_10: 0.8723 - val_precision_10: 0.8594 - val_mean_io_u_10: 0.8763 - val_accuracy: 0.9951 - val_auc: 0.9395 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1900 - recall_10: 0.8879 - precision_10: 0.8526 - mean_io_u_10: 0.8806 - accuracy: 0.9952 - auc: 0.9476\n",
      "Epoch 30: val_loss improved from 0.19354 to 0.18668, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 328ms/step - loss: 0.1900 - recall_10: 0.8879 - precision_10: 0.8526 - mean_io_u_10: 0.8806 - accuracy: 0.9952 - auc: 0.9476 - val_loss: 0.1867 - val_recall_10: 0.8818 - val_precision_10: 0.8601 - val_mean_io_u_10: 0.8804 - val_accuracy: 0.9953 - val_auc: 0.9440 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1894 - recall_10: 0.8876 - precision_10: 0.8533 - mean_io_u_10: 0.8807 - accuracy: 0.9952 - auc: 0.9476\n",
      "Epoch 31: val_loss did not improve from 0.18668\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1894 - recall_10: 0.8875 - precision_10: 0.8534 - mean_io_u_10: 0.8807 - accuracy: 0.9952 - auc: 0.9476 - val_loss: 0.1950 - val_recall_10: 0.8801 - val_precision_10: 0.8519 - val_mean_io_u_10: 0.8772 - val_accuracy: 0.9951 - val_auc: 0.9434 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1862 - recall_10: 0.8909 - precision_10: 0.8545 - mean_io_u_10: 0.8827 - accuracy: 0.9953 - auc: 0.9492\n",
      "Epoch 32: val_loss improved from 0.18668 to 0.18313, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 331ms/step - loss: 0.1863 - recall_10: 0.8909 - precision_10: 0.8545 - mean_io_u_10: 0.8827 - accuracy: 0.9953 - auc: 0.9492 - val_loss: 0.1831 - val_recall_10: 0.8800 - val_precision_10: 0.8663 - val_mean_io_u_10: 0.8814 - val_accuracy: 0.9954 - val_auc: 0.9438 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1841 - recall_10: 0.8903 - precision_10: 0.8575 - mean_io_u_10: 0.8835 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 33: val_loss did not improve from 0.18313\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.1841 - recall_10: 0.8903 - precision_10: 0.8575 - mean_io_u_10: 0.8835 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.1952 - val_recall_10: 0.8728 - val_precision_10: 0.8566 - val_mean_io_u_10: 0.8762 - val_accuracy: 0.9951 - val_auc: 0.9393 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1838 - recall_10: 0.8912 - precision_10: 0.8571 - mean_io_u_10: 0.8838 - accuracy: 0.9954 - auc: 0.9492\n",
      "Epoch 34: val_loss did not improve from 0.18313\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1838 - recall_10: 0.8912 - precision_10: 0.8571 - mean_io_u_10: 0.8838 - accuracy: 0.9954 - auc: 0.9492 - val_loss: 0.1882 - val_recall_10: 0.8904 - val_precision_10: 0.8518 - val_mean_io_u_10: 0.8821 - val_accuracy: 0.9952 - val_auc: 0.9482 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1789 - recall_10: 0.8931 - precision_10: 0.8616 - mean_io_u_10: 0.8860 - accuracy: 0.9955 - auc: 0.9505\n",
      "Epoch 35: val_loss did not improve from 0.18313\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1790 - recall_10: 0.8931 - precision_10: 0.8615 - mean_io_u_10: 0.8860 - accuracy: 0.9955 - auc: 0.9505 - val_loss: 0.1921 - val_recall_10: 0.8863 - val_precision_10: 0.8504 - val_mean_io_u_10: 0.8794 - val_accuracy: 0.9951 - val_auc: 0.9460 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1771 - recall_10: 0.8932 - precision_10: 0.8637 - mean_io_u_10: 0.8870 - accuracy: 0.9955 - auc: 0.9508\n",
      "Epoch 36: val_loss improved from 0.18313 to 0.17094, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 329ms/step - loss: 0.1771 - recall_10: 0.8932 - precision_10: 0.8637 - mean_io_u_10: 0.8870 - accuracy: 0.9955 - auc: 0.9508 - val_loss: 0.1709 - val_recall_10: 0.8999 - val_precision_10: 0.8656 - val_mean_io_u_10: 0.8912 - val_accuracy: 0.9957 - val_auc: 0.9533 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1733 - recall_10: 0.8958 - precision_10: 0.8663 - mean_io_u_10: 0.8891 - accuracy: 0.9956 - auc: 0.9518\n",
      "Epoch 37: val_loss did not improve from 0.17094\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1733 - recall_10: 0.8958 - precision_10: 0.8663 - mean_io_u_10: 0.8891 - accuracy: 0.9956 - auc: 0.9518 - val_loss: 0.1944 - val_recall_10: 0.8826 - val_precision_10: 0.8501 - val_mean_io_u_10: 0.8779 - val_accuracy: 0.9951 - val_auc: 0.9443 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1750 - recall_10: 0.8961 - precision_10: 0.8639 - mean_io_u_10: 0.8882 - accuracy: 0.9956 - auc: 0.9521\n",
      "Epoch 38: val_loss did not improve from 0.17094\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.1749 - recall_10: 0.8961 - precision_10: 0.8640 - mean_io_u_10: 0.8883 - accuracy: 0.9956 - auc: 0.9521 - val_loss: 0.1812 - val_recall_10: 0.8938 - val_precision_10: 0.8575 - val_mean_io_u_10: 0.8860 - val_accuracy: 0.9954 - val_auc: 0.9496 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1709 - recall_10: 0.8978 - precision_10: 0.8676 - mean_io_u_10: 0.8906 - accuracy: 0.9957 - auc: 0.9527\n",
      "Epoch 39: val_loss did not improve from 0.17094\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1709 - recall_10: 0.8978 - precision_10: 0.8676 - mean_io_u_10: 0.8906 - accuracy: 0.9957 - auc: 0.9527 - val_loss: 0.1878 - val_recall_10: 0.8730 - val_precision_10: 0.8657 - val_mean_io_u_10: 0.8789 - val_accuracy: 0.9953 - val_auc: 0.9398 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1703 - recall_10: 0.8991 - precision_10: 0.8672 - mean_io_u_10: 0.8908 - accuracy: 0.9957 - auc: 0.9536\n",
      "Epoch 40: val_loss did not improve from 0.17094\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1703 - recall_10: 0.8991 - precision_10: 0.8672 - mean_io_u_10: 0.8908 - accuracy: 0.9957 - auc: 0.9536 - val_loss: 0.1766 - val_recall_10: 0.8981 - val_precision_10: 0.8602 - val_mean_io_u_10: 0.8884 - val_accuracy: 0.9955 - val_auc: 0.9525 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1663 - recall_10: 0.9005 - precision_10: 0.8710 - mean_io_u_10: 0.8930 - accuracy: 0.9958 - auc: 0.9542\n",
      "Epoch 41: val_loss did not improve from 0.17094\n",
      "\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1664 - recall_10: 0.9005 - precision_10: 0.8709 - mean_io_u_10: 0.8929 - accuracy: 0.9958 - auc: 0.9542 - val_loss: 0.1725 - val_recall_10: 0.9023 - val_precision_10: 0.8616 - val_mean_io_u_10: 0.8912 - val_accuracy: 0.9956 - val_auc: 0.9539 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1603 - recall_10: 0.9051 - precision_10: 0.8748 - mean_io_u_10: 0.8965 - accuracy: 0.9960 - auc: 0.9564\n",
      "Epoch 42: val_loss improved from 0.17094 to 0.15730, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 333ms/step - loss: 0.1603 - recall_10: 0.9051 - precision_10: 0.8748 - mean_io_u_10: 0.8965 - accuracy: 0.9960 - auc: 0.9564 - val_loss: 0.1573 - val_recall_10: 0.9049 - val_precision_10: 0.8784 - val_mean_io_u_10: 0.8983 - val_accuracy: 0.9960 - val_auc: 0.9557 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1564 - recall_10: 0.9044 - precision_10: 0.8803 - mean_io_u_10: 0.8979 - accuracy: 0.9961 - auc: 0.9561\n",
      "Epoch 43: val_loss did not improve from 0.15730\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1564 - recall_10: 0.9044 - precision_10: 0.8803 - mean_io_u_10: 0.8979 - accuracy: 0.9961 - auc: 0.9561 - val_loss: 0.1621 - val_recall_10: 0.9014 - val_precision_10: 0.8755 - val_mean_io_u_10: 0.8951 - val_accuracy: 0.9959 - val_auc: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1552 - recall_10: 0.9059 - precision_10: 0.8805 - mean_io_u_10: 0.8988 - accuracy: 0.9961 - auc: 0.9569\n",
      "Epoch 44: val_loss improved from 0.15730 to 0.15442, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 339ms/step - loss: 0.1552 - recall_10: 0.9059 - precision_10: 0.8805 - mean_io_u_10: 0.8988 - accuracy: 0.9961 - auc: 0.9569 - val_loss: 0.1544 - val_recall_10: 0.9055 - val_precision_10: 0.8817 - val_mean_io_u_10: 0.8993 - val_accuracy: 0.9961 - val_auc: 0.9564 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1542 - recall_10: 0.9073 - precision_10: 0.8807 - mean_io_u_10: 0.8995 - accuracy: 0.9961 - auc: 0.9575\n",
      "Epoch 45: val_loss improved from 0.15442 to 0.15380, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 360ms/step - loss: 0.1542 - recall_10: 0.9073 - precision_10: 0.8807 - mean_io_u_10: 0.8995 - accuracy: 0.9961 - auc: 0.9575 - val_loss: 0.1538 - val_recall_10: 0.9059 - val_precision_10: 0.8821 - val_mean_io_u_10: 0.9000 - val_accuracy: 0.9961 - val_auc: 0.9565 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1540 - recall_10: 0.9062 - precision_10: 0.8817 - mean_io_u_10: 0.8995 - accuracy: 0.9961 - auc: 0.9569\n",
      "Epoch 46: val_loss did not improve from 0.15380\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 0.1541 - recall_10: 0.9062 - precision_10: 0.8817 - mean_io_u_10: 0.8995 - accuracy: 0.9961 - auc: 0.9569 - val_loss: 0.1556 - val_recall_10: 0.9039 - val_precision_10: 0.8815 - val_mean_io_u_10: 0.8987 - val_accuracy: 0.9961 - val_auc: 0.9558 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1535 - recall_10: 0.9073 - precision_10: 0.8815 - mean_io_u_10: 0.8999 - accuracy: 0.9961 - auc: 0.9575\n",
      "Epoch 47: val_loss did not improve from 0.15380\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.1535 - recall_10: 0.9073 - precision_10: 0.8815 - mean_io_u_10: 0.8999 - accuracy: 0.9961 - auc: 0.9575 - val_loss: 0.1558 - val_recall_10: 0.9009 - val_precision_10: 0.8837 - val_mean_io_u_10: 0.8976 - val_accuracy: 0.9961 - val_auc: 0.9543 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1530 - recall_10: 0.9074 - precision_10: 0.8821 - mean_io_u_10: 0.9001 - accuracy: 0.9961 - auc: 0.9575\n",
      "Epoch 48: val_loss improved from 0.15380 to 0.15247, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.1530 - recall_10: 0.9074 - precision_10: 0.8821 - mean_io_u_10: 0.9001 - accuracy: 0.9961 - auc: 0.9575 - val_loss: 0.1525 - val_recall_10: 0.9059 - val_precision_10: 0.8837 - val_mean_io_u_10: 0.9008 - val_accuracy: 0.9962 - val_auc: 0.9566 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1523 - recall_10: 0.9082 - precision_10: 0.8823 - mean_io_u_10: 0.9005 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 49: val_loss did not improve from 0.15247\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1523 - recall_10: 0.9082 - precision_10: 0.8823 - mean_io_u_10: 0.9005 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1532 - val_recall_10: 0.9055 - val_precision_10: 0.8832 - val_mean_io_u_10: 0.9003 - val_accuracy: 0.9961 - val_auc: 0.9564 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1517 - recall_10: 0.9066 - precision_10: 0.8842 - mean_io_u_10: 0.9006 - accuracy: 0.9962 - auc: 0.9572\n",
      "Epoch 50: val_loss did not improve from 0.15247\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1518 - recall_10: 0.9066 - precision_10: 0.8842 - mean_io_u_10: 0.9006 - accuracy: 0.9962 - auc: 0.9571 - val_loss: 0.1550 - val_recall_10: 0.9014 - val_precision_10: 0.8844 - val_mean_io_u_10: 0.8986 - val_accuracy: 0.9961 - val_auc: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1513 - recall_10: 0.9081 - precision_10: 0.8837 - mean_io_u_10: 0.9009 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 51: val_loss did not improve from 0.15247\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1514 - recall_10: 0.9080 - precision_10: 0.8836 - mean_io_u_10: 0.9009 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1560 - val_recall_10: 0.9048 - val_precision_10: 0.8802 - val_mean_io_u_10: 0.8986 - val_accuracy: 0.9961 - val_auc: 0.9561 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1512 - recall_10: 0.9081 - precision_10: 0.8837 - mean_io_u_10: 0.9010 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 52: val_loss improved from 0.15247 to 0.15171, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 340ms/step - loss: 0.1512 - recall_10: 0.9081 - precision_10: 0.8837 - mean_io_u_10: 0.9010 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1517 - val_recall_10: 0.9081 - val_precision_10: 0.8830 - val_mean_io_u_10: 0.9014 - val_accuracy: 0.9962 - val_auc: 0.9576 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1508 - recall_10: 0.9078 - precision_10: 0.8845 - mean_io_u_10: 0.9012 - accuracy: 0.9962 - auc: 0.9578\n",
      "Epoch 53: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.1508 - recall_10: 0.9078 - precision_10: 0.8845 - mean_io_u_10: 0.9012 - accuracy: 0.9962 - auc: 0.9578 - val_loss: 0.1568 - val_recall_10: 0.9007 - val_precision_10: 0.8827 - val_mean_io_u_10: 0.8978 - val_accuracy: 0.9961 - val_auc: 0.9542 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1510 - recall_10: 0.9078 - precision_10: 0.8841 - mean_io_u_10: 0.9011 - accuracy: 0.9962 - auc: 0.9579\n",
      "Epoch 54: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1510 - recall_10: 0.9078 - precision_10: 0.8841 - mean_io_u_10: 0.9011 - accuracy: 0.9962 - auc: 0.9579 - val_loss: 0.1563 - val_recall_10: 0.9058 - val_precision_10: 0.8792 - val_mean_io_u_10: 0.8989 - val_accuracy: 0.9961 - val_auc: 0.9568 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1504 - recall_10: 0.9083 - precision_10: 0.8845 - mean_io_u_10: 0.9016 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 55: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1504 - recall_10: 0.9083 - precision_10: 0.8845 - mean_io_u_10: 0.9016 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1545 - val_recall_10: 0.9031 - val_precision_10: 0.8836 - val_mean_io_u_10: 0.8993 - val_accuracy: 0.9961 - val_auc: 0.9551 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1502 - recall_10: 0.9083 - precision_10: 0.8847 - mean_io_u_10: 0.9017 - accuracy: 0.9962 - auc: 0.9580\n",
      "Epoch 56: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1503 - recall_10: 0.9083 - precision_10: 0.8847 - mean_io_u_10: 0.9017 - accuracy: 0.9962 - auc: 0.9580 - val_loss: 0.1612 - val_recall_10: 0.8981 - val_precision_10: 0.8793 - val_mean_io_u_10: 0.8946 - val_accuracy: 0.9959 - val_auc: 0.9529 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1498 - recall_10: 0.9083 - precision_10: 0.8853 - mean_io_u_10: 0.9017 - accuracy: 0.9962 - auc: 0.9581\n",
      "Epoch 57: val_loss did not improve from 0.15171\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1498 - recall_10: 0.9083 - precision_10: 0.8853 - mean_io_u_10: 0.9017 - accuracy: 0.9962 - auc: 0.9581 - val_loss: 0.1595 - val_recall_10: 0.9046 - val_precision_10: 0.8762 - val_mean_io_u_10: 0.8972 - val_accuracy: 0.9960 - val_auc: 0.9559 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1493 - recall_10: 0.9086 - precision_10: 0.8856 - mean_io_u_10: 0.9021 - accuracy: 0.9962 - auc: 0.9583\n",
      "Epoch 58: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1493 - recall_10: 0.9086 - precision_10: 0.8856 - mean_io_u_10: 0.9021 - accuracy: 0.9962 - auc: 0.9583 - val_loss: 0.1546 - val_recall_10: 0.9054 - val_precision_10: 0.8817 - val_mean_io_u_10: 0.8999 - val_accuracy: 0.9961 - val_auc: 0.9563 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1491 - recall_10: 0.9082 - precision_10: 0.8862 - mean_io_u_10: 0.9021 - accuracy: 0.9962 - auc: 0.9581\n",
      "Epoch 59: val_loss did not improve from 0.15171\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1491 - recall_10: 0.9082 - precision_10: 0.8862 - mean_io_u_10: 0.9021 - accuracy: 0.9962 - auc: 0.9581 - val_loss: 0.1517 - val_recall_10: 0.9063 - val_precision_10: 0.8845 - val_mean_io_u_10: 0.9011 - val_accuracy: 0.9962 - val_auc: 0.9568 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1488 - recall_10: 0.9090 - precision_10: 0.8860 - mean_io_u_10: 0.9023 - accuracy: 0.9963 - auc: 0.9584\n",
      "Epoch 60: val_loss improved from 0.15171 to 0.15096, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 335ms/step - loss: 0.1488 - recall_10: 0.9090 - precision_10: 0.8859 - mean_io_u_10: 0.9023 - accuracy: 0.9963 - auc: 0.9584 - val_loss: 0.1510 - val_recall_10: 0.9069 - val_precision_10: 0.8849 - val_mean_io_u_10: 0.9016 - val_accuracy: 0.9962 - val_auc: 0.9571 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1484 - recall_10: 0.9086 - precision_10: 0.8868 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9582\n",
      "Epoch 61: val_loss improved from 0.15096 to 0.15073, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.1484 - recall_10: 0.9086 - precision_10: 0.8867 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9582 - val_loss: 0.1507 - val_recall_10: 0.9062 - val_precision_10: 0.8859 - val_mean_io_u_10: 0.9016 - val_accuracy: 0.9962 - val_auc: 0.9567 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1484 - recall_10: 0.9086 - precision_10: 0.8868 - mean_io_u_10: 0.9024 - accuracy: 0.9963 - auc: 0.9582\n",
      "Epoch 62: val_loss did not improve from 0.15073\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 0.1485 - recall_10: 0.9085 - precision_10: 0.8867 - mean_io_u_10: 0.9023 - accuracy: 0.9963 - auc: 0.9582 - val_loss: 0.1520 - val_recall_10: 0.9058 - val_precision_10: 0.8845 - val_mean_io_u_10: 0.9010 - val_accuracy: 0.9962 - val_auc: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1482 - recall_10: 0.9086 - precision_10: 0.8870 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9583\n",
      "Epoch 63: val_loss improved from 0.15073 to 0.15011, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 23s 349ms/step - loss: 0.1482 - recall_10: 0.9086 - precision_10: 0.8870 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9583 - val_loss: 0.1501 - val_recall_10: 0.9072 - val_precision_10: 0.8857 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1485 - recall_10: 0.9093 - precision_10: 0.8862 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9585\n",
      "Epoch 64: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1485 - recall_10: 0.9093 - precision_10: 0.8862 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9585 - val_loss: 0.1503 - val_recall_10: 0.9072 - val_precision_10: 0.8856 - val_mean_io_u_10: 0.9019 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1485 - recall_10: 0.9092 - precision_10: 0.8863 - mean_io_u_10: 0.9024 - accuracy: 0.9963 - auc: 0.9586\n",
      "Epoch 65: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1485 - recall_10: 0.9092 - precision_10: 0.8863 - mean_io_u_10: 0.9024 - accuracy: 0.9963 - auc: 0.9586 - val_loss: 0.1503 - val_recall_10: 0.9076 - val_precision_10: 0.8852 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9575 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1484 - recall_10: 0.9095 - precision_10: 0.8861 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9587\n",
      "Epoch 66: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1485 - recall_10: 0.9095 - precision_10: 0.8860 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9587 - val_loss: 0.1503 - val_recall_10: 0.9080 - val_precision_10: 0.8849 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9577 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1482 - recall_10: 0.9090 - precision_10: 0.8867 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9585\n",
      "Epoch 67: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.1482 - recall_10: 0.9090 - precision_10: 0.8867 - mean_io_u_10: 0.9025 - accuracy: 0.9963 - auc: 0.9585 - val_loss: 0.1510 - val_recall_10: 0.9068 - val_precision_10: 0.8850 - val_mean_io_u_10: 0.9014 - val_accuracy: 0.9962 - val_auc: 0.9572 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1483 - recall_10: 0.9091 - precision_10: 0.8864 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9586\n",
      "Epoch 68: val_loss did not improve from 0.15011\n",
      "\n",
      "Epoch 68: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1483 - recall_10: 0.9091 - precision_10: 0.8864 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9586 - val_loss: 0.1504 - val_recall_10: 0.9070 - val_precision_10: 0.8856 - val_mean_io_u_10: 0.9016 - val_accuracy: 0.9962 - val_auc: 0.9572 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1480 - recall_10: 0.9089 - precision_10: 0.8871 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9583\n",
      "Epoch 69: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1480 - recall_10: 0.9088 - precision_10: 0.8871 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9583 - val_loss: 0.1514 - val_recall_10: 0.9056 - val_precision_10: 0.8855 - val_mean_io_u_10: 0.9008 - val_accuracy: 0.9962 - val_auc: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1483 - recall_10: 0.9083 - precision_10: 0.8871 - mean_io_u_10: 0.9024 - accuracy: 0.9963 - auc: 0.9582\n",
      "Epoch 70: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1483 - recall_10: 0.9083 - precision_10: 0.8871 - mean_io_u_10: 0.9024 - accuracy: 0.9963 - auc: 0.9582 - val_loss: 0.1504 - val_recall_10: 0.9073 - val_precision_10: 0.8853 - val_mean_io_u_10: 0.9018 - val_accuracy: 0.9962 - val_auc: 0.9572 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1475 - recall_10: 0.9100 - precision_10: 0.8867 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9589\n",
      "Epoch 71: val_loss did not improve from 0.15011\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1475 - recall_10: 0.9100 - precision_10: 0.8867 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9589 - val_loss: 0.1512 - val_recall_10: 0.9066 - val_precision_10: 0.8849 - val_mean_io_u_10: 0.9014 - val_accuracy: 0.9962 - val_auc: 0.9570 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1480 - recall_10: 0.9099 - precision_10: 0.8863 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9589\n",
      "Epoch 72: val_loss improved from 0.15011 to 0.15008, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.1480 - recall_10: 0.9099 - precision_10: 0.8863 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9589 - val_loss: 0.1501 - val_recall_10: 0.9077 - val_precision_10: 0.8853 - val_mean_io_u_10: 0.9019 - val_accuracy: 0.9962 - val_auc: 0.9576 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1480 - recall_10: 0.9099 - precision_10: 0.8864 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9588\n",
      "Epoch 73: val_loss did not improve from 0.15008\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1480 - recall_10: 0.9099 - precision_10: 0.8864 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9588 - val_loss: 0.1501 - val_recall_10: 0.9073 - val_precision_10: 0.8857 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1479 - recall_10: 0.9090 - precision_10: 0.8871 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9585\n",
      "Epoch 74: val_loss improved from 0.15008 to 0.14964, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.1479 - recall_10: 0.9090 - precision_10: 0.8870 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9585 - val_loss: 0.1496 - val_recall_10: 0.9071 - val_precision_10: 0.8864 - val_mean_io_u_10: 0.9021 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1478 - recall_10: 0.9088 - precision_10: 0.8874 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9584\n",
      "Epoch 75: val_loss did not improve from 0.14964\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1478 - recall_10: 0.9088 - precision_10: 0.8874 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9584 - val_loss: 0.1506 - val_recall_10: 0.9067 - val_precision_10: 0.8855 - val_mean_io_u_10: 0.9017 - val_accuracy: 0.9962 - val_auc: 0.9570 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1476 - recall_10: 0.9087 - precision_10: 0.8878 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9584\n",
      "Epoch 76: val_loss improved from 0.14964 to 0.14963, saving model to ./iter_wDice-25.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-25.model/assets\n",
      "65/65 [==============================] - 22s 345ms/step - loss: 0.1476 - recall_10: 0.9086 - precision_10: 0.8878 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9584 - val_loss: 0.1496 - val_recall_10: 0.9064 - val_precision_10: 0.8871 - val_mean_io_u_10: 0.9019 - val_accuracy: 0.9962 - val_auc: 0.9570 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1478 - recall_10: 0.9085 - precision_10: 0.8876 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9582\n",
      "Epoch 77: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1478 - recall_10: 0.9085 - precision_10: 0.8876 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9582 - val_loss: 0.1497 - val_recall_10: 0.9072 - val_precision_10: 0.8862 - val_mean_io_u_10: 0.9021 - val_accuracy: 0.9962 - val_auc: 0.9574 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1477 - recall_10: 0.9094 - precision_10: 0.8870 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9587\n",
      "Epoch 78: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.1477 - recall_10: 0.9094 - precision_10: 0.8870 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9587 - val_loss: 0.1504 - val_recall_10: 0.9069 - val_precision_10: 0.8856 - val_mean_io_u_10: 0.9017 - val_accuracy: 0.9962 - val_auc: 0.9571 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1480 - recall_10: 0.9089 - precision_10: 0.8870 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9585\n",
      "Epoch 79: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1480 - recall_10: 0.9089 - precision_10: 0.8870 - mean_io_u_10: 0.9026 - accuracy: 0.9963 - auc: 0.9585 - val_loss: 0.1506 - val_recall_10: 0.9072 - val_precision_10: 0.8851 - val_mean_io_u_10: 0.9017 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1476 - recall_10: 0.9094 - precision_10: 0.8870 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9587\n",
      "Epoch 80: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1476 - recall_10: 0.9094 - precision_10: 0.8871 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9587 - val_loss: 0.1498 - val_recall_10: 0.9068 - val_precision_10: 0.8865 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1475 - recall_10: 0.9088 - precision_10: 0.8877 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9585\n",
      "Epoch 81: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1475 - recall_10: 0.9088 - precision_10: 0.8877 - mean_io_u_10: 0.9027 - accuracy: 0.9963 - auc: 0.9585 - val_loss: 0.1501 - val_recall_10: 0.9071 - val_precision_10: 0.8858 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9573 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1478 - recall_10: 0.9096 - precision_10: 0.8868 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9588\n",
      "Epoch 82: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1478 - recall_10: 0.9096 - precision_10: 0.8868 - mean_io_u_10: 0.9028 - accuracy: 0.9963 - auc: 0.9588 - val_loss: 0.1517 - val_recall_10: 0.9062 - val_precision_10: 0.8845 - val_mean_io_u_10: 0.9009 - val_accuracy: 0.9962 - val_auc: 0.9570 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1476 - recall_10: 0.9097 - precision_10: 0.8870 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9588\n",
      "Epoch 83: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1476 - recall_10: 0.9097 - precision_10: 0.8870 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9588 - val_loss: 0.1500 - val_recall_10: 0.9071 - val_precision_10: 0.8861 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9572 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1475 - recall_10: 0.9094 - precision_10: 0.8873 - mean_io_u_10: 0.9030 - accuracy: 0.9963 - auc: 0.9586\n",
      "Epoch 84: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1475 - recall_10: 0.9093 - precision_10: 0.8873 - mean_io_u_10: 0.9029 - accuracy: 0.9963 - auc: 0.9586 - val_loss: 0.1522 - val_recall_10: 0.9055 - val_precision_10: 0.8845 - val_mean_io_u_10: 0.9008 - val_accuracy: 0.9962 - val_auc: 0.9565 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1473 - recall_10: 0.9098 - precision_10: 0.8873 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9588\n",
      "Epoch 85: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1473 - recall_10: 0.9097 - precision_10: 0.8873 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9588 - val_loss: 0.1506 - val_recall_10: 0.9068 - val_precision_10: 0.8854 - val_mean_io_u_10: 0.9017 - val_accuracy: 0.9962 - val_auc: 0.9571 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1474 - recall_10: 0.9098 - precision_10: 0.8871 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9589\n",
      "Epoch 86: val_loss did not improve from 0.14963\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1474 - recall_10: 0.9098 - precision_10: 0.8871 - mean_io_u_10: 0.9031 - accuracy: 0.9963 - auc: 0.9589 - val_loss: 0.1502 - val_recall_10: 0.9075 - val_precision_10: 0.8855 - val_mean_io_u_10: 0.9020 - val_accuracy: 0.9962 - val_auc: 0.9574 - lr: 1.0000e-05\n",
      "Epoch 86: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f045c4718b0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 6.6497 - recall_11: 0.9829 - precision_11: 0.1050 - mean_io_u_11: 0.5303 - accuracy: 0.8488 - auc: 0.9392\n",
      "Epoch 1: val_loss improved from inf to 5.68281, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 27s 372ms/step - loss: 6.6430 - recall_11: 0.9829 - precision_11: 0.1051 - mean_io_u_11: 0.5306 - accuracy: 0.8490 - auc: 0.9393 - val_loss: 5.6828 - val_recall_11: 0.9308 - val_precision_11: 0.1173 - val_mean_io_u_11: 0.4929 - val_accuracy: 0.8724 - val_auc: 0.9041 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 3.5629 - recall_11: 0.9934 - precision_11: 0.1953 - mean_io_u_11: 0.5739 - accuracy: 0.9261 - auc: 0.9614\n",
      "Epoch 2: val_loss improved from 5.68281 to 2.60094, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 326ms/step - loss: 3.5629 - recall_11: 0.9934 - precision_11: 0.1953 - mean_io_u_11: 0.5739 - accuracy: 0.9261 - auc: 0.9614 - val_loss: 2.6009 - val_recall_11: 0.8445 - val_precision_11: 0.2135 - val_mean_io_u_11: 0.5344 - val_accuracy: 0.9411 - val_auc: 0.9106 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 2.0026 - recall_11: 0.9836 - precision_11: 0.3270 - mean_io_u_11: 0.6569 - accuracy: 0.9632 - auc: 0.9723\n",
      "Epoch 3: val_loss improved from 2.60094 to 0.92745, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 333ms/step - loss: 2.0008 - recall_11: 0.9835 - precision_11: 0.3272 - mean_io_u_11: 0.6570 - accuracy: 0.9633 - auc: 0.9722 - val_loss: 0.9274 - val_recall_11: 0.7938 - val_precision_11: 0.4700 - val_mean_io_u_11: 0.5939 - val_accuracy: 0.9801 - val_auc: 0.9130 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.1005 - recall_11: 0.9599 - precision_11: 0.4948 - mean_io_u_11: 0.7432 - accuracy: 0.9816 - auc: 0.9640\n",
      "Epoch 4: val_loss improved from 0.92745 to 0.67881, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 23s 352ms/step - loss: 1.1005 - recall_11: 0.9599 - precision_11: 0.4948 - mean_io_u_11: 0.7432 - accuracy: 0.9816 - auc: 0.9640 - val_loss: 0.6788 - val_recall_11: 0.4128 - val_precision_11: 0.7012 - val_mean_io_u_11: 0.5320 - val_accuracy: 0.9862 - val_auc: 0.7683 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.6311 - recall_11: 0.9170 - precision_11: 0.6524 - mean_io_u_11: 0.8080 - accuracy: 0.9897 - auc: 0.9461\n",
      "Epoch 5: val_loss improved from 0.67881 to 0.40135, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 324ms/step - loss: 0.6310 - recall_11: 0.9169 - precision_11: 0.6524 - mean_io_u_11: 0.8080 - accuracy: 0.9897 - auc: 0.9461 - val_loss: 0.4014 - val_recall_11: 0.7995 - val_precision_11: 0.7454 - val_mean_io_u_11: 0.7795 - val_accuracy: 0.9915 - val_auc: 0.9112 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4670 - recall_11: 0.8887 - precision_11: 0.7200 - mean_io_u_11: 0.8283 - accuracy: 0.9918 - auc: 0.9491\n",
      "Epoch 6: val_loss improved from 0.40135 to 0.37953, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.4670 - recall_11: 0.8887 - precision_11: 0.7200 - mean_io_u_11: 0.8283 - accuracy: 0.9918 - auc: 0.9491 - val_loss: 0.3795 - val_recall_11: 0.8185 - val_precision_11: 0.7539 - val_mean_io_u_11: 0.8101 - val_accuracy: 0.9919 - val_auc: 0.9160 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.4008 - recall_11: 0.8710 - precision_11: 0.7518 - mean_io_u_11: 0.8351 - accuracy: 0.9925 - auc: 0.9403\n",
      "Epoch 7: val_loss improved from 0.37953 to 0.32295, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 326ms/step - loss: 0.4008 - recall_11: 0.8710 - precision_11: 0.7518 - mean_io_u_11: 0.8351 - accuracy: 0.9925 - auc: 0.9403 - val_loss: 0.3230 - val_recall_11: 0.8253 - val_precision_11: 0.8008 - val_mean_io_u_11: 0.8328 - val_accuracy: 0.9931 - val_auc: 0.9186 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3636 - recall_11: 0.8655 - precision_11: 0.7711 - mean_io_u_11: 0.8404 - accuracy: 0.9929 - auc: 0.9374\n",
      "Epoch 8: val_loss improved from 0.32295 to 0.31814, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 302ms/step - loss: 0.3633 - recall_11: 0.8656 - precision_11: 0.7713 - mean_io_u_11: 0.8406 - accuracy: 0.9930 - auc: 0.9375 - val_loss: 0.3181 - val_recall_11: 0.8291 - val_precision_11: 0.8035 - val_mean_io_u_11: 0.8372 - val_accuracy: 0.9933 - val_auc: 0.9197 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3472 - recall_11: 0.8634 - precision_11: 0.7778 - mean_io_u_11: 0.8425 - accuracy: 0.9931 - auc: 0.9358\n",
      "Epoch 9: val_loss did not improve from 0.31814\n",
      "65/65 [==============================] - 12s 186ms/step - loss: 0.3471 - recall_11: 0.8635 - precision_11: 0.7779 - mean_io_u_11: 0.8425 - accuracy: 0.9931 - auc: 0.9359 - val_loss: 0.3194 - val_recall_11: 0.8574 - val_precision_11: 0.7862 - val_mean_io_u_11: 0.8424 - val_accuracy: 0.9932 - val_auc: 0.9321 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3344 - recall_11: 0.8622 - precision_11: 0.7846 - mean_io_u_11: 0.8446 - accuracy: 0.9933 - auc: 0.9350\n",
      "Epoch 10: val_loss improved from 0.31814 to 0.31573, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.3346 - recall_11: 0.8622 - precision_11: 0.7844 - mean_io_u_11: 0.8445 - accuracy: 0.9932 - auc: 0.9350 - val_loss: 0.3157 - val_recall_11: 0.8440 - val_precision_11: 0.7988 - val_mean_io_u_11: 0.8417 - val_accuracy: 0.9934 - val_auc: 0.9261 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3347 - recall_11: 0.8582 - precision_11: 0.7846 - mean_io_u_11: 0.8431 - accuracy: 0.9932 - auc: 0.9328\n",
      "Epoch 11: val_loss did not improve from 0.31573\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.3347 - recall_11: 0.8582 - precision_11: 0.7846 - mean_io_u_11: 0.8431 - accuracy: 0.9932 - auc: 0.9328 - val_loss: 0.3273 - val_recall_11: 0.8590 - val_precision_11: 0.7774 - val_mean_io_u_11: 0.8407 - val_accuracy: 0.9930 - val_auc: 0.9310 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3217 - recall_11: 0.8564 - precision_11: 0.7935 - mean_io_u_11: 0.8458 - accuracy: 0.9934 - auc: 0.9319\n",
      "Epoch 12: val_loss improved from 0.31573 to 0.30245, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 19s 298ms/step - loss: 0.3219 - recall_11: 0.8563 - precision_11: 0.7935 - mean_io_u_11: 0.8458 - accuracy: 0.9934 - auc: 0.9318 - val_loss: 0.3025 - val_recall_11: 0.8632 - val_precision_11: 0.7978 - val_mean_io_u_11: 0.8498 - val_accuracy: 0.9936 - val_auc: 0.9338 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3153 - recall_11: 0.8588 - precision_11: 0.7958 - mean_io_u_11: 0.8476 - accuracy: 0.9935 - auc: 0.9325\n",
      "Epoch 13: val_loss improved from 0.30245 to 0.29168, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.3152 - recall_11: 0.8588 - precision_11: 0.7959 - mean_io_u_11: 0.8476 - accuracy: 0.9935 - auc: 0.9325 - val_loss: 0.2917 - val_recall_11: 0.8611 - val_precision_11: 0.8095 - val_mean_io_u_11: 0.8534 - val_accuracy: 0.9938 - val_auc: 0.9332 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3091 - recall_11: 0.8597 - precision_11: 0.7995 - mean_io_u_11: 0.8493 - accuracy: 0.9936 - auc: 0.9330\n",
      "Epoch 14: val_loss did not improve from 0.29168\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.3092 - recall_11: 0.8596 - precision_11: 0.7995 - mean_io_u_11: 0.8493 - accuracy: 0.9936 - auc: 0.9330 - val_loss: 0.3190 - val_recall_11: 0.8546 - val_precision_11: 0.7904 - val_mean_io_u_11: 0.8441 - val_accuracy: 0.9933 - val_auc: 0.9298 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3070 - recall_11: 0.8578 - precision_11: 0.8016 - mean_io_u_11: 0.8496 - accuracy: 0.9936 - auc: 0.9317\n",
      "Epoch 15: val_loss did not improve from 0.29168\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.3070 - recall_11: 0.8578 - precision_11: 0.8016 - mean_io_u_11: 0.8496 - accuracy: 0.9936 - auc: 0.9317 - val_loss: 0.2922 - val_recall_11: 0.8725 - val_precision_11: 0.8020 - val_mean_io_u_11: 0.8558 - val_accuracy: 0.9938 - val_auc: 0.9383 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2997 - recall_11: 0.8618 - precision_11: 0.8050 - mean_io_u_11: 0.8524 - accuracy: 0.9937 - auc: 0.9337\n",
      "Epoch 16: val_loss improved from 0.29168 to 0.28389, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 328ms/step - loss: 0.2996 - recall_11: 0.8618 - precision_11: 0.8050 - mean_io_u_11: 0.8525 - accuracy: 0.9937 - auc: 0.9337 - val_loss: 0.2839 - val_recall_11: 0.8425 - val_precision_11: 0.8296 - val_mean_io_u_11: 0.8527 - val_accuracy: 0.9940 - val_auc: 0.9249 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2940 - recall_11: 0.8578 - precision_11: 0.8122 - mean_io_u_11: 0.8535 - accuracy: 0.9939 - auc: 0.9317\n",
      "Epoch 17: val_loss did not improve from 0.28389\n",
      "65/65 [==============================] - 12s 188ms/step - loss: 0.2940 - recall_11: 0.8578 - precision_11: 0.8122 - mean_io_u_11: 0.8535 - accuracy: 0.9939 - auc: 0.9317 - val_loss: 0.3086 - val_recall_11: 0.8581 - val_precision_11: 0.7957 - val_mean_io_u_11: 0.8478 - val_accuracy: 0.9935 - val_auc: 0.9307 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2922 - recall_11: 0.8600 - precision_11: 0.8119 - mean_io_u_11: 0.8544 - accuracy: 0.9939 - auc: 0.9327\n",
      "Epoch 18: val_loss did not improve from 0.28389\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2921 - recall_11: 0.8600 - precision_11: 0.8120 - mean_io_u_11: 0.8545 - accuracy: 0.9939 - auc: 0.9327 - val_loss: 0.2894 - val_recall_11: 0.8497 - val_precision_11: 0.8188 - val_mean_io_u_11: 0.8522 - val_accuracy: 0.9939 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2916 - recall_11: 0.8582 - precision_11: 0.8134 - mean_io_u_11: 0.8541 - accuracy: 0.9939 - auc: 0.9321\n",
      "Epoch 19: val_loss did not improve from 0.28389\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.2914 - recall_11: 0.8584 - precision_11: 0.8136 - mean_io_u_11: 0.8542 - accuracy: 0.9939 - auc: 0.9321 - val_loss: 0.3075 - val_recall_11: 0.8427 - val_precision_11: 0.8086 - val_mean_io_u_11: 0.8463 - val_accuracy: 0.9936 - val_auc: 0.9237 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2895 - recall_11: 0.8584 - precision_11: 0.8148 - mean_io_u_11: 0.8547 - accuracy: 0.9939 - auc: 0.9321\n",
      "Epoch 20: val_loss did not improve from 0.28389\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.2894 - recall_11: 0.8585 - precision_11: 0.8148 - mean_io_u_11: 0.8547 - accuracy: 0.9939 - auc: 0.9321 - val_loss: 0.3235 - val_recall_11: 0.7998 - val_precision_11: 0.8197 - val_mean_io_u_11: 0.8310 - val_accuracy: 0.9932 - val_auc: 0.9053 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2829 - recall_11: 0.8617 - precision_11: 0.8183 - mean_io_u_11: 0.8574 - accuracy: 0.9941 - auc: 0.9337\n",
      "Epoch 21: val_loss did not improve from 0.28389\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2829 - recall_11: 0.8618 - precision_11: 0.8183 - mean_io_u_11: 0.8574 - accuracy: 0.9941 - auc: 0.9337 - val_loss: 0.4759 - val_recall_11: 0.7709 - val_precision_11: 0.6991 - val_mean_io_u_11: 0.7805 - val_accuracy: 0.9899 - val_auc: 0.8904 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2692 - recall_11: 0.8665 - precision_11: 0.8281 - mean_io_u_11: 0.8628 - accuracy: 0.9944 - auc: 0.9360\n",
      "Epoch 22: val_loss did not improve from 0.28389\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.2691 - recall_11: 0.8666 - precision_11: 0.8281 - mean_io_u_11: 0.8628 - accuracy: 0.9944 - auc: 0.9360 - val_loss: 0.2866 - val_recall_11: 0.8428 - val_precision_11: 0.8265 - val_mean_io_u_11: 0.8519 - val_accuracy: 0.9940 - val_auc: 0.9251 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2637 - recall_11: 0.8691 - precision_11: 0.8315 - mean_io_u_11: 0.8653 - accuracy: 0.9945 - auc: 0.9374\n",
      "Epoch 23: val_loss improved from 0.28389 to 0.26694, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.2635 - recall_11: 0.8692 - precision_11: 0.8316 - mean_io_u_11: 0.8654 - accuracy: 0.9945 - auc: 0.9374 - val_loss: 0.2669 - val_recall_11: 0.8674 - val_precision_11: 0.8288 - val_mean_io_u_11: 0.8636 - val_accuracy: 0.9944 - val_auc: 0.9364 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2602 - recall_11: 0.8714 - precision_11: 0.8332 - mean_io_u_11: 0.8669 - accuracy: 0.9945 - auc: 0.9385\n",
      "Epoch 24: val_loss improved from 0.26694 to 0.25150, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.2601 - recall_11: 0.8714 - precision_11: 0.8333 - mean_io_u_11: 0.8669 - accuracy: 0.9945 - auc: 0.9385 - val_loss: 0.2515 - val_recall_11: 0.8690 - val_precision_11: 0.8435 - val_mean_io_u_11: 0.8699 - val_accuracy: 0.9947 - val_auc: 0.9371 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2594 - recall_11: 0.8713 - precision_11: 0.8341 - mean_io_u_11: 0.8671 - accuracy: 0.9946 - auc: 0.9385\n",
      "Epoch 25: val_loss improved from 0.25150 to 0.25006, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 303ms/step - loss: 0.2595 - recall_11: 0.8712 - precision_11: 0.8340 - mean_io_u_11: 0.8671 - accuracy: 0.9946 - auc: 0.9385 - val_loss: 0.2501 - val_recall_11: 0.8785 - val_precision_11: 0.8376 - val_mean_io_u_11: 0.8718 - val_accuracy: 0.9947 - val_auc: 0.9416 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2569 - recall_11: 0.8718 - precision_11: 0.8360 - mean_io_u_11: 0.8681 - accuracy: 0.9946 - auc: 0.9387\n",
      "Epoch 26: val_loss did not improve from 0.25006\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.2570 - recall_11: 0.8717 - precision_11: 0.8360 - mean_io_u_11: 0.8680 - accuracy: 0.9946 - auc: 0.9387 - val_loss: 0.2625 - val_recall_11: 0.8630 - val_precision_11: 0.8363 - val_mean_io_u_11: 0.8646 - val_accuracy: 0.9945 - val_auc: 0.9340 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2559 - recall_11: 0.8739 - precision_11: 0.8355 - mean_io_u_11: 0.8688 - accuracy: 0.9946 - auc: 0.9397\n",
      "Epoch 27: val_loss did not improve from 0.25006\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.2558 - recall_11: 0.8740 - precision_11: 0.8355 - mean_io_u_11: 0.8688 - accuracy: 0.9946 - auc: 0.9397 - val_loss: 0.2622 - val_recall_11: 0.8612 - val_precision_11: 0.8382 - val_mean_io_u_11: 0.8644 - val_accuracy: 0.9945 - val_auc: 0.9331 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2529 - recall_11: 0.8740 - precision_11: 0.8383 - mean_io_u_11: 0.8698 - accuracy: 0.9947 - auc: 0.9398\n",
      "Epoch 28: val_loss improved from 0.25006 to 0.24513, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.2529 - recall_11: 0.8740 - precision_11: 0.8383 - mean_io_u_11: 0.8698 - accuracy: 0.9947 - auc: 0.9398 - val_loss: 0.2451 - val_recall_11: 0.8771 - val_precision_11: 0.8439 - val_mean_io_u_11: 0.8733 - val_accuracy: 0.9949 - val_auc: 0.9409 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2521 - recall_11: 0.8763 - precision_11: 0.8375 - mean_io_u_11: 0.8705 - accuracy: 0.9947 - auc: 0.9409\n",
      "Epoch 29: val_loss did not improve from 0.24513\n",
      "65/65 [==============================] - 12s 187ms/step - loss: 0.2521 - recall_11: 0.8763 - precision_11: 0.8375 - mean_io_u_11: 0.8705 - accuracy: 0.9947 - auc: 0.9409 - val_loss: 0.2788 - val_recall_11: 0.8558 - val_precision_11: 0.8258 - val_mean_io_u_11: 0.8582 - val_accuracy: 0.9941 - val_auc: 0.9303 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2506 - recall_11: 0.8759 - precision_11: 0.8392 - mean_io_u_11: 0.8710 - accuracy: 0.9947 - auc: 0.9407\n",
      "Epoch 30: val_loss improved from 0.24513 to 0.24364, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.2506 - recall_11: 0.8760 - precision_11: 0.8393 - mean_io_u_11: 0.8710 - accuracy: 0.9947 - auc: 0.9407 - val_loss: 0.2436 - val_recall_11: 0.8822 - val_precision_11: 0.8415 - val_mean_io_u_11: 0.8748 - val_accuracy: 0.9949 - val_auc: 0.9434 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2496 - recall_11: 0.8771 - precision_11: 0.8393 - mean_io_u_11: 0.8716 - accuracy: 0.9948 - auc: 0.9413\n",
      "Epoch 31: val_loss did not improve from 0.24364\n",
      "65/65 [==============================] - 13s 198ms/step - loss: 0.2494 - recall_11: 0.8772 - precision_11: 0.8394 - mean_io_u_11: 0.8717 - accuracy: 0.9948 - auc: 0.9413 - val_loss: 0.2611 - val_recall_11: 0.8641 - val_precision_11: 0.8371 - val_mean_io_u_11: 0.8657 - val_accuracy: 0.9945 - val_auc: 0.9345 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2470 - recall_11: 0.8766 - precision_11: 0.8421 - mean_io_u_11: 0.8723 - accuracy: 0.9948 - auc: 0.9411\n",
      "Epoch 32: val_loss did not improve from 0.24364\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2469 - recall_11: 0.8767 - precision_11: 0.8422 - mean_io_u_11: 0.8723 - accuracy: 0.9948 - auc: 0.9412 - val_loss: 0.2806 - val_recall_11: 0.8496 - val_precision_11: 0.8279 - val_mean_io_u_11: 0.8566 - val_accuracy: 0.9941 - val_auc: 0.9275 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2464 - recall_11: 0.8787 - precision_11: 0.8412 - mean_io_u_11: 0.8729 - accuracy: 0.9948 - auc: 0.9421\n",
      "Epoch 33: val_loss did not improve from 0.24364\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2465 - recall_11: 0.8786 - precision_11: 0.8412 - mean_io_u_11: 0.8729 - accuracy: 0.9948 - auc: 0.9421 - val_loss: 0.2939 - val_recall_11: 0.8342 - val_precision_11: 0.8252 - val_mean_io_u_11: 0.8487 - val_accuracy: 0.9938 - val_auc: 0.9199 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2454 - recall_11: 0.8786 - precision_11: 0.8422 - mean_io_u_11: 0.8732 - accuracy: 0.9948 - auc: 0.9421\n",
      "Epoch 34: val_loss improved from 0.24364 to 0.23869, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.2454 - recall_11: 0.8786 - precision_11: 0.8422 - mean_io_u_11: 0.8732 - accuracy: 0.9948 - auc: 0.9421 - val_loss: 0.2387 - val_recall_11: 0.8776 - val_precision_11: 0.8491 - val_mean_io_u_11: 0.8756 - val_accuracy: 0.9950 - val_auc: 0.9413 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2459 - recall_11: 0.8795 - precision_11: 0.8411 - mean_io_u_11: 0.8732 - accuracy: 0.9948 - auc: 0.9424\n",
      "Epoch 35: val_loss improved from 0.23869 to 0.23822, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 334ms/step - loss: 0.2460 - recall_11: 0.8794 - precision_11: 0.8411 - mean_io_u_11: 0.8731 - accuracy: 0.9948 - auc: 0.9424 - val_loss: 0.2382 - val_recall_11: 0.8822 - val_precision_11: 0.8463 - val_mean_io_u_11: 0.8768 - val_accuracy: 0.9950 - val_auc: 0.9435 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2431 - recall_11: 0.8795 - precision_11: 0.8438 - mean_io_u_11: 0.8742 - accuracy: 0.9949 - auc: 0.9424\n",
      "Epoch 36: val_loss did not improve from 0.23822\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2431 - recall_11: 0.8795 - precision_11: 0.8438 - mean_io_u_11: 0.8742 - accuracy: 0.9949 - auc: 0.9424 - val_loss: 0.2993 - val_recall_11: 0.8381 - val_precision_11: 0.8171 - val_mean_io_u_11: 0.8481 - val_accuracy: 0.9937 - val_auc: 0.9215 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2412 - recall_11: 0.8795 - precision_11: 0.8456 - mean_io_u_11: 0.8748 - accuracy: 0.9949 - auc: 0.9425\n",
      "Epoch 37: val_loss did not improve from 0.23822\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2412 - recall_11: 0.8795 - precision_11: 0.8456 - mean_io_u_11: 0.8748 - accuracy: 0.9949 - auc: 0.9425 - val_loss: 0.2588 - val_recall_11: 0.8652 - val_precision_11: 0.8379 - val_mean_io_u_11: 0.8663 - val_accuracy: 0.9946 - val_auc: 0.9350 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2417 - recall_11: 0.8799 - precision_11: 0.8448 - mean_io_u_11: 0.8747 - accuracy: 0.9949 - auc: 0.9427\n",
      "Epoch 38: val_loss improved from 0.23822 to 0.23422, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.2417 - recall_11: 0.8799 - precision_11: 0.8448 - mean_io_u_11: 0.8747 - accuracy: 0.9949 - auc: 0.9427 - val_loss: 0.2342 - val_recall_11: 0.8807 - val_precision_11: 0.8519 - val_mean_io_u_11: 0.8779 - val_accuracy: 0.9951 - val_auc: 0.9430 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2396 - recall_11: 0.8807 - precision_11: 0.8462 - mean_io_u_11: 0.8756 - accuracy: 0.9950 - auc: 0.9431\n",
      "Epoch 39: val_loss did not improve from 0.23422\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2395 - recall_11: 0.8808 - precision_11: 0.8463 - mean_io_u_11: 0.8757 - accuracy: 0.9950 - auc: 0.9432 - val_loss: 0.2347 - val_recall_11: 0.8830 - val_precision_11: 0.8493 - val_mean_io_u_11: 0.8782 - val_accuracy: 0.9951 - val_auc: 0.9438 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2386 - recall_11: 0.8805 - precision_11: 0.8474 - mean_io_u_11: 0.8759 - accuracy: 0.9950 - auc: 0.9430\n",
      "Epoch 40: val_loss did not improve from 0.23422\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2386 - recall_11: 0.8805 - precision_11: 0.8474 - mean_io_u_11: 0.8759 - accuracy: 0.9950 - auc: 0.9430 - val_loss: 0.3025 - val_recall_11: 0.8287 - val_precision_11: 0.8204 - val_mean_io_u_11: 0.8454 - val_accuracy: 0.9936 - val_auc: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2372 - recall_11: 0.8820 - precision_11: 0.8476 - mean_io_u_11: 0.8766 - accuracy: 0.9950 - auc: 0.9437\n",
      "Epoch 41: val_loss did not improve from 0.23422\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2373 - recall_11: 0.8819 - precision_11: 0.8476 - mean_io_u_11: 0.8766 - accuracy: 0.9950 - auc: 0.9437 - val_loss: 0.2464 - val_recall_11: 0.8756 - val_precision_11: 0.8431 - val_mean_io_u_11: 0.8723 - val_accuracy: 0.9948 - val_auc: 0.9402 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2360 - recall_11: 0.8815 - precision_11: 0.8491 - mean_io_u_11: 0.8769 - accuracy: 0.9950 - auc: 0.9437\n",
      "Epoch 42: val_loss improved from 0.23422 to 0.23113, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 344ms/step - loss: 0.2362 - recall_11: 0.8814 - precision_11: 0.8490 - mean_io_u_11: 0.8768 - accuracy: 0.9950 - auc: 0.9436 - val_loss: 0.2311 - val_recall_11: 0.8877 - val_precision_11: 0.8495 - val_mean_io_u_11: 0.8803 - val_accuracy: 0.9951 - val_auc: 0.9461 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2360 - recall_11: 0.8827 - precision_11: 0.8483 - mean_io_u_11: 0.8772 - accuracy: 0.9950 - auc: 0.9442\n",
      "Epoch 43: val_loss did not improve from 0.23113\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2360 - recall_11: 0.8827 - precision_11: 0.8483 - mean_io_u_11: 0.8772 - accuracy: 0.9950 - auc: 0.9442 - val_loss: 0.2986 - val_recall_11: 0.8328 - val_precision_11: 0.8211 - val_mean_io_u_11: 0.8471 - val_accuracy: 0.9937 - val_auc: 0.9191 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2345 - recall_11: 0.8839 - precision_11: 0.8488 - mean_io_u_11: 0.8779 - accuracy: 0.9951 - auc: 0.9449\n",
      "Epoch 44: val_loss did not improve from 0.23113\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2344 - recall_11: 0.8840 - precision_11: 0.8488 - mean_io_u_11: 0.8780 - accuracy: 0.9951 - auc: 0.9449 - val_loss: 0.2542 - val_recall_11: 0.8719 - val_precision_11: 0.8375 - val_mean_io_u_11: 0.8691 - val_accuracy: 0.9946 - val_auc: 0.9386 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2328 - recall_11: 0.8854 - precision_11: 0.8493 - mean_io_u_11: 0.8788 - accuracy: 0.9951 - auc: 0.9455\n",
      "Epoch 45: val_loss did not improve from 0.23113\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2328 - recall_11: 0.8854 - precision_11: 0.8493 - mean_io_u_11: 0.8788 - accuracy: 0.9951 - auc: 0.9455 - val_loss: 0.2787 - val_recall_11: 0.8509 - val_precision_11: 0.8286 - val_mean_io_u_11: 0.8573 - val_accuracy: 0.9941 - val_auc: 0.9279 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2325 - recall_11: 0.8850 - precision_11: 0.8499 - mean_io_u_11: 0.8788 - accuracy: 0.9951 - auc: 0.9452\n",
      "Epoch 46: val_loss did not improve from 0.23113\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2325 - recall_11: 0.8850 - precision_11: 0.8499 - mean_io_u_11: 0.8788 - accuracy: 0.9951 - auc: 0.9452 - val_loss: 0.2720 - val_recall_11: 0.8475 - val_precision_11: 0.8373 - val_mean_io_u_11: 0.8580 - val_accuracy: 0.9943 - val_auc: 0.9267 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2311 - recall_11: 0.8852 - precision_11: 0.8512 - mean_io_u_11: 0.8794 - accuracy: 0.9951 - auc: 0.9453\n",
      "Epoch 47: val_loss improved from 0.23113 to 0.22785, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 337ms/step - loss: 0.2311 - recall_11: 0.8852 - precision_11: 0.8512 - mean_io_u_11: 0.8794 - accuracy: 0.9951 - auc: 0.9453 - val_loss: 0.2279 - val_recall_11: 0.8847 - val_precision_11: 0.8547 - val_mean_io_u_11: 0.8807 - val_accuracy: 0.9952 - val_auc: 0.9449 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2310 - recall_11: 0.8857 - precision_11: 0.8508 - mean_io_u_11: 0.8795 - accuracy: 0.9951 - auc: 0.9455\n",
      "Epoch 48: val_loss did not improve from 0.22785\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2310 - recall_11: 0.8858 - precision_11: 0.8508 - mean_io_u_11: 0.8795 - accuracy: 0.9951 - auc: 0.9456 - val_loss: 0.3223 - val_recall_11: 0.8133 - val_precision_11: 0.8109 - val_mean_io_u_11: 0.8356 - val_accuracy: 0.9932 - val_auc: 0.9094 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2292 - recall_11: 0.8848 - precision_11: 0.8532 - mean_io_u_11: 0.8798 - accuracy: 0.9952 - auc: 0.9452\n",
      "Epoch 49: val_loss did not improve from 0.22785\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2292 - recall_11: 0.8848 - precision_11: 0.8532 - mean_io_u_11: 0.8798 - accuracy: 0.9952 - auc: 0.9452 - val_loss: 0.2347 - val_recall_11: 0.8802 - val_precision_11: 0.8511 - val_mean_io_u_11: 0.8776 - val_accuracy: 0.9951 - val_auc: 0.9427 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2280 - recall_11: 0.8861 - precision_11: 0.8534 - mean_io_u_11: 0.8805 - accuracy: 0.9952 - auc: 0.9458\n",
      "Epoch 50: val_loss did not improve from 0.22785\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2281 - recall_11: 0.8860 - precision_11: 0.8534 - mean_io_u_11: 0.8805 - accuracy: 0.9952 - auc: 0.9458 - val_loss: 0.2818 - val_recall_11: 0.8409 - val_precision_11: 0.8322 - val_mean_io_u_11: 0.8541 - val_accuracy: 0.9941 - val_auc: 0.9231 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2273 - recall_11: 0.8875 - precision_11: 0.8531 - mean_io_u_11: 0.8811 - accuracy: 0.9952 - auc: 0.9466\n",
      "Epoch 51: val_loss did not improve from 0.22785\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2274 - recall_11: 0.8875 - precision_11: 0.8531 - mean_io_u_11: 0.8811 - accuracy: 0.9952 - auc: 0.9466 - val_loss: 0.2992 - val_recall_11: 0.8313 - val_precision_11: 0.8213 - val_mean_io_u_11: 0.8463 - val_accuracy: 0.9937 - val_auc: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2263 - recall_11: 0.8885 - precision_11: 0.8533 - mean_io_u_11: 0.8815 - accuracy: 0.9952 - auc: 0.9470\n",
      "Epoch 52: val_loss improved from 0.22785 to 0.22253, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.2263 - recall_11: 0.8885 - precision_11: 0.8533 - mean_io_u_11: 0.8815 - accuracy: 0.9952 - auc: 0.9470 - val_loss: 0.2225 - val_recall_11: 0.8885 - val_precision_11: 0.8571 - val_mean_io_u_11: 0.8834 - val_accuracy: 0.9953 - val_auc: 0.9467 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2252 - recall_11: 0.8872 - precision_11: 0.8553 - mean_io_u_11: 0.8816 - accuracy: 0.9953 - auc: 0.9464\n",
      "Epoch 53: val_loss did not improve from 0.22253\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.2252 - recall_11: 0.8872 - precision_11: 0.8553 - mean_io_u_11: 0.8816 - accuracy: 0.9953 - auc: 0.9464 - val_loss: 0.2889 - val_recall_11: 0.8421 - val_precision_11: 0.8241 - val_mean_io_u_11: 0.8520 - val_accuracy: 0.9939 - val_auc: 0.9233 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2245 - recall_11: 0.8894 - precision_11: 0.8544 - mean_io_u_11: 0.8822 - accuracy: 0.9953 - auc: 0.9475\n",
      "Epoch 54: val_loss did not improve from 0.22253\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2245 - recall_11: 0.8894 - precision_11: 0.8544 - mean_io_u_11: 0.8822 - accuracy: 0.9953 - auc: 0.9475 - val_loss: 0.2904 - val_recall_11: 0.8345 - val_precision_11: 0.8282 - val_mean_io_u_11: 0.8502 - val_accuracy: 0.9939 - val_auc: 0.9198 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2246 - recall_11: 0.8881 - precision_11: 0.8551 - mean_io_u_11: 0.8820 - accuracy: 0.9953 - auc: 0.9468\n",
      "Epoch 55: val_loss did not improve from 0.22253\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2246 - recall_11: 0.8881 - precision_11: 0.8551 - mean_io_u_11: 0.8820 - accuracy: 0.9953 - auc: 0.9468 - val_loss: 0.3024 - val_recall_11: 0.8289 - val_precision_11: 0.8195 - val_mean_io_u_11: 0.8451 - val_accuracy: 0.9936 - val_auc: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2229 - recall_11: 0.8897 - precision_11: 0.8556 - mean_io_u_11: 0.8829 - accuracy: 0.9953 - auc: 0.9477\n",
      "Epoch 56: val_loss did not improve from 0.22253\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2229 - recall_11: 0.8897 - precision_11: 0.8556 - mean_io_u_11: 0.8829 - accuracy: 0.9953 - auc: 0.9477 - val_loss: 0.3035 - val_recall_11: 0.8256 - val_precision_11: 0.8209 - val_mean_io_u_11: 0.8442 - val_accuracy: 0.9936 - val_auc: 0.9153 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2220 - recall_11: 0.8881 - precision_11: 0.8577 - mean_io_u_11: 0.8829 - accuracy: 0.9953 - auc: 0.9468\n",
      "Epoch 57: val_loss did not improve from 0.22253\n",
      "\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2220 - recall_11: 0.8881 - precision_11: 0.8577 - mean_io_u_11: 0.8829 - accuracy: 0.9953 - auc: 0.9468 - val_loss: 0.2703 - val_recall_11: 0.8550 - val_precision_11: 0.8332 - val_mean_io_u_11: 0.8606 - val_accuracy: 0.9943 - val_auc: 0.9297 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2214 - recall_11: 0.8921 - precision_11: 0.8553 - mean_io_u_11: 0.8839 - accuracy: 0.9953 - auc: 0.9487\n",
      "Epoch 58: val_loss improved from 0.22253 to 0.22109, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 335ms/step - loss: 0.2213 - recall_11: 0.8922 - precision_11: 0.8554 - mean_io_u_11: 0.8840 - accuracy: 0.9953 - auc: 0.9488 - val_loss: 0.2211 - val_recall_11: 0.8900 - val_precision_11: 0.8571 - val_mean_io_u_11: 0.8842 - val_accuracy: 0.9953 - val_auc: 0.9472 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2197 - recall_11: 0.8916 - precision_11: 0.8574 - mean_io_u_11: 0.8844 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 59: val_loss improved from 0.22109 to 0.21355, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.2197 - recall_11: 0.8916 - precision_11: 0.8574 - mean_io_u_11: 0.8844 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2135 - val_recall_11: 0.8927 - val_precision_11: 0.8627 - val_mean_io_u_11: 0.8874 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2193 - recall_11: 0.8911 - precision_11: 0.8582 - mean_io_u_11: 0.8844 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 60: val_loss did not improve from 0.21355\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.2193 - recall_11: 0.8911 - precision_11: 0.8582 - mean_io_u_11: 0.8844 - accuracy: 0.9954 - auc: 0.9483 - val_loss: 0.2138 - val_recall_11: 0.8938 - val_precision_11: 0.8616 - val_mean_io_u_11: 0.8875 - val_accuracy: 0.9955 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2193 - recall_11: 0.8924 - precision_11: 0.8572 - mean_io_u_11: 0.8847 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 61: val_loss improved from 0.21355 to 0.21289, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 333ms/step - loss: 0.2193 - recall_11: 0.8924 - precision_11: 0.8572 - mean_io_u_11: 0.8847 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.2129 - val_recall_11: 0.8941 - val_precision_11: 0.8623 - val_mean_io_u_11: 0.8880 - val_accuracy: 0.9955 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2181 - recall_11: 0.8923 - precision_11: 0.8585 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 62: val_loss did not improve from 0.21289\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2181 - recall_11: 0.8923 - precision_11: 0.8585 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.2131 - val_recall_11: 0.8931 - val_precision_11: 0.8629 - val_mean_io_u_11: 0.8877 - val_accuracy: 0.9955 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2180 - recall_11: 0.8911 - precision_11: 0.8594 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 63: val_loss did not improve from 0.21289\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2181 - recall_11: 0.8911 - precision_11: 0.8594 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9484 - val_loss: 0.2131 - val_recall_11: 0.8928 - val_precision_11: 0.8631 - val_mean_io_u_11: 0.8876 - val_accuracy: 0.9955 - val_auc: 0.9488 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2183 - recall_11: 0.8923 - precision_11: 0.8583 - mean_io_u_11: 0.8850 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 64: val_loss did not improve from 0.21289\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2183 - recall_11: 0.8923 - precision_11: 0.8583 - mean_io_u_11: 0.8850 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.2181 - val_recall_11: 0.8897 - val_precision_11: 0.8603 - val_mean_io_u_11: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9473 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2182 - recall_11: 0.8912 - precision_11: 0.8592 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 65: val_loss did not improve from 0.21289\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2182 - recall_11: 0.8911 - precision_11: 0.8592 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9483 - val_loss: 0.2361 - val_recall_11: 0.8758 - val_precision_11: 0.8524 - val_mean_io_u_11: 0.8762 - val_accuracy: 0.9950 - val_auc: 0.9404 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2184 - recall_11: 0.8906 - precision_11: 0.8593 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9481\n",
      "Epoch 66: val_loss did not improve from 0.21289\n",
      "\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2185 - recall_11: 0.8906 - precision_11: 0.8593 - mean_io_u_11: 0.8848 - accuracy: 0.9954 - auc: 0.9481 - val_loss: 0.2199 - val_recall_11: 0.8878 - val_precision_11: 0.8599 - val_mean_io_u_11: 0.8840 - val_accuracy: 0.9954 - val_auc: 0.9463 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2178 - recall_11: 0.8916 - precision_11: 0.8592 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 67: val_loss improved from 0.21289 to 0.21216, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 348ms/step - loss: 0.2178 - recall_11: 0.8916 - precision_11: 0.8592 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.2122 - val_recall_11: 0.8934 - val_precision_11: 0.8636 - val_mean_io_u_11: 0.8881 - val_accuracy: 0.9955 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2178 - recall_11: 0.8918 - precision_11: 0.8592 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 68: val_loss did not improve from 0.21216\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2178 - recall_11: 0.8918 - precision_11: 0.8592 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.2182 - val_recall_11: 0.8889 - val_precision_11: 0.8607 - val_mean_io_u_11: 0.8849 - val_accuracy: 0.9954 - val_auc: 0.9469 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2173 - recall_11: 0.8912 - precision_11: 0.8601 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9484\n",
      "Epoch 69: val_loss did not improve from 0.21216\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2173 - recall_11: 0.8912 - precision_11: 0.8601 - mean_io_u_11: 0.8851 - accuracy: 0.9954 - auc: 0.9484 - val_loss: 0.2125 - val_recall_11: 0.8922 - val_precision_11: 0.8641 - val_mean_io_u_11: 0.8876 - val_accuracy: 0.9955 - val_auc: 0.9485 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2172 - recall_11: 0.8913 - precision_11: 0.8600 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9484\n",
      "Epoch 70: val_loss improved from 0.21216 to 0.21158, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.2172 - recall_11: 0.8913 - precision_11: 0.8600 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2116 - val_recall_11: 0.8932 - val_precision_11: 0.8643 - val_mean_io_u_11: 0.8883 - val_accuracy: 0.9955 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2168 - recall_11: 0.8914 - precision_11: 0.8604 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 71: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 0.2168 - recall_11: 0.8914 - precision_11: 0.8604 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2208 - val_recall_11: 0.8863 - val_precision_11: 0.8602 - val_mean_io_u_11: 0.8835 - val_accuracy: 0.9954 - val_auc: 0.9456 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2170 - recall_11: 0.8913 - precision_11: 0.8603 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 72: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2170 - recall_11: 0.8913 - precision_11: 0.8603 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2247 - val_recall_11: 0.8851 - val_precision_11: 0.8571 - val_mean_io_u_11: 0.8820 - val_accuracy: 0.9953 - val_auc: 0.9449 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2172 - recall_11: 0.8926 - precision_11: 0.8590 - mean_io_u_11: 0.8854 - accuracy: 0.9954 - auc: 0.9490\n",
      "Epoch 73: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2172 - recall_11: 0.8927 - precision_11: 0.8591 - mean_io_u_11: 0.8854 - accuracy: 0.9954 - auc: 0.9491 - val_loss: 0.2136 - val_recall_11: 0.8924 - val_precision_11: 0.8627 - val_mean_io_u_11: 0.8872 - val_accuracy: 0.9955 - val_auc: 0.9486 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2171 - recall_11: 0.8917 - precision_11: 0.8598 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9487\n",
      "Epoch 74: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2172 - recall_11: 0.8917 - precision_11: 0.8597 - mean_io_u_11: 0.8853 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.2341 - val_recall_11: 0.8779 - val_precision_11: 0.8529 - val_mean_io_u_11: 0.8772 - val_accuracy: 0.9951 - val_auc: 0.9414 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2168 - recall_11: 0.8914 - precision_11: 0.8604 - mean_io_u_11: 0.8854 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 75: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2168 - recall_11: 0.8914 - precision_11: 0.8604 - mean_io_u_11: 0.8854 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2196 - val_recall_11: 0.8874 - val_precision_11: 0.8605 - val_mean_io_u_11: 0.8842 - val_accuracy: 0.9954 - val_auc: 0.9461 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2164 - recall_11: 0.8910 - precision_11: 0.8610 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9483\n",
      "Epoch 76: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2164 - recall_11: 0.8910 - precision_11: 0.8610 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9483 - val_loss: 0.2170 - val_recall_11: 0.8894 - val_precision_11: 0.8616 - val_mean_io_u_11: 0.8855 - val_accuracy: 0.9954 - val_auc: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2166 - recall_11: 0.8914 - precision_11: 0.8605 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 77: val_loss did not improve from 0.21158\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2166 - recall_11: 0.8914 - precision_11: 0.8605 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9485 - val_loss: 0.2125 - val_recall_11: 0.8917 - val_precision_11: 0.8644 - val_mean_io_u_11: 0.8876 - val_accuracy: 0.9955 - val_auc: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2164 - recall_11: 0.8915 - precision_11: 0.8607 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 78: val_loss improved from 0.21158 to 0.21055, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 335ms/step - loss: 0.2164 - recall_11: 0.8915 - precision_11: 0.8607 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.2106 - val_recall_11: 0.8941 - val_precision_11: 0.8645 - val_mean_io_u_11: 0.8888 - val_accuracy: 0.9956 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2168 - recall_11: 0.8923 - precision_11: 0.8597 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9489\n",
      "Epoch 79: val_loss improved from 0.21055 to 0.21051, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 338ms/step - loss: 0.2168 - recall_11: 0.8923 - precision_11: 0.8597 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9489 - val_loss: 0.2105 - val_recall_11: 0.8940 - val_precision_11: 0.8646 - val_mean_io_u_11: 0.8888 - val_accuracy: 0.9956 - val_auc: 0.9494 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2164 - recall_11: 0.8916 - precision_11: 0.8605 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9486\n",
      "Epoch 80: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 14s 214ms/step - loss: 0.2163 - recall_11: 0.8917 - precision_11: 0.8606 - mean_io_u_11: 0.8856 - accuracy: 0.9954 - auc: 0.9487 - val_loss: 0.2119 - val_recall_11: 0.8924 - val_precision_11: 0.8645 - val_mean_io_u_11: 0.8878 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 81/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2164 - recall_11: 0.8920 - precision_11: 0.8603 - mean_io_u_11: 0.8856 - accuracy: 0.9954 - auc: 0.9488\n",
      "Epoch 81: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2164 - recall_11: 0.8919 - precision_11: 0.8602 - mean_io_u_11: 0.8855 - accuracy: 0.9954 - auc: 0.9488 - val_loss: 0.2131 - val_recall_11: 0.8926 - val_precision_11: 0.8631 - val_mean_io_u_11: 0.8874 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 82/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2159 - recall_11: 0.8924 - precision_11: 0.8604 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9490\n",
      "Epoch 82: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 13s 202ms/step - loss: 0.2159 - recall_11: 0.8924 - precision_11: 0.8604 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.2263 - val_recall_11: 0.8838 - val_precision_11: 0.8564 - val_mean_io_u_11: 0.8811 - val_accuracy: 0.9952 - val_auc: 0.9442 - lr: 1.0000e-05\n",
      "Epoch 83/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2160 - recall_11: 0.8923 - precision_11: 0.8605 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9489\n",
      "Epoch 83: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2160 - recall_11: 0.8923 - precision_11: 0.8605 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9489 - val_loss: 0.2403 - val_recall_11: 0.8737 - val_precision_11: 0.8496 - val_mean_io_u_11: 0.8743 - val_accuracy: 0.9949 - val_auc: 0.9392 - lr: 1.0000e-05\n",
      "Epoch 84/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2161 - recall_11: 0.8924 - precision_11: 0.8602 - mean_io_u_11: 0.8858 - accuracy: 0.9954 - auc: 0.9491\n",
      "Epoch 84: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2161 - recall_11: 0.8924 - precision_11: 0.8602 - mean_io_u_11: 0.8858 - accuracy: 0.9954 - auc: 0.9491 - val_loss: 0.2198 - val_recall_11: 0.8874 - val_precision_11: 0.8602 - val_mean_io_u_11: 0.8839 - val_accuracy: 0.9954 - val_auc: 0.9461 - lr: 1.0000e-05\n",
      "Epoch 85/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2155 - recall_11: 0.8918 - precision_11: 0.8613 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9488\n",
      "Epoch 85: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2155 - recall_11: 0.8918 - precision_11: 0.8613 - mean_io_u_11: 0.8859 - accuracy: 0.9955 - auc: 0.9488 - val_loss: 0.2121 - val_recall_11: 0.8926 - val_precision_11: 0.8641 - val_mean_io_u_11: 0.8877 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 86/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2161 - recall_11: 0.8925 - precision_11: 0.8601 - mean_io_u_11: 0.8858 - accuracy: 0.9954 - auc: 0.9491\n",
      "Epoch 86: val_loss did not improve from 0.21051\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2160 - recall_11: 0.8926 - precision_11: 0.8602 - mean_io_u_11: 0.8859 - accuracy: 0.9954 - auc: 0.9491 - val_loss: 0.2106 - val_recall_11: 0.8944 - val_precision_11: 0.8642 - val_mean_io_u_11: 0.8888 - val_accuracy: 0.9956 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 87/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2156 - recall_11: 0.8933 - precision_11: 0.8601 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 87: val_loss improved from 0.21051 to 0.20985, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.2156 - recall_11: 0.8933 - precision_11: 0.8601 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2099 - val_recall_11: 0.8941 - val_precision_11: 0.8652 - val_mean_io_u_11: 0.8890 - val_accuracy: 0.9956 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 88/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2152 - recall_11: 0.8921 - precision_11: 0.8614 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9489\n",
      "Epoch 88: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 14s 215ms/step - loss: 0.2152 - recall_11: 0.8921 - precision_11: 0.8614 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9489 - val_loss: 0.2153 - val_recall_11: 0.8900 - val_precision_11: 0.8627 - val_mean_io_u_11: 0.8861 - val_accuracy: 0.9955 - val_auc: 0.9475 - lr: 1.0000e-05\n",
      "Epoch 89/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2150 - recall_11: 0.8924 - precision_11: 0.8613 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9490\n",
      "Epoch 89: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2150 - recall_11: 0.8924 - precision_11: 0.8613 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.2118 - val_recall_11: 0.8937 - val_precision_11: 0.8636 - val_mean_io_u_11: 0.8881 - val_accuracy: 0.9955 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 90/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2158 - recall_11: 0.8928 - precision_11: 0.8603 - mean_io_u_11: 0.8860 - accuracy: 0.9955 - auc: 0.9492\n",
      "Epoch 90: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2158 - recall_11: 0.8928 - precision_11: 0.8603 - mean_io_u_11: 0.8860 - accuracy: 0.9955 - auc: 0.9491 - val_loss: 0.2248 - val_recall_11: 0.8850 - val_precision_11: 0.8568 - val_mean_io_u_11: 0.8819 - val_accuracy: 0.9953 - val_auc: 0.9449 - lr: 1.0000e-05\n",
      "Epoch 91/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2153 - recall_11: 0.8935 - precision_11: 0.8602 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 91: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2155 - recall_11: 0.8934 - precision_11: 0.8601 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2171 - val_recall_11: 0.8888 - val_precision_11: 0.8619 - val_mean_io_u_11: 0.8852 - val_accuracy: 0.9954 - val_auc: 0.9469 - lr: 1.0000e-05\n",
      "Epoch 92/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2147 - recall_11: 0.8916 - precision_11: 0.8622 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9487\n",
      "Epoch 92: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2147 - recall_11: 0.8917 - precision_11: 0.8621 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9487 - val_loss: 0.2152 - val_recall_11: 0.8891 - val_precision_11: 0.8634 - val_mean_io_u_11: 0.8859 - val_accuracy: 0.9955 - val_auc: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 93/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2146 - recall_11: 0.8923 - precision_11: 0.8617 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9489\n",
      "Epoch 93: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2146 - recall_11: 0.8923 - precision_11: 0.8617 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.2175 - val_recall_11: 0.8886 - val_precision_11: 0.8614 - val_mean_io_u_11: 0.8850 - val_accuracy: 0.9954 - val_auc: 0.9469 - lr: 1.0000e-05\n",
      "Epoch 94/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2152 - recall_11: 0.8933 - precision_11: 0.8605 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 94: val_loss did not improve from 0.20985\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2152 - recall_11: 0.8932 - precision_11: 0.8605 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2129 - val_recall_11: 0.8932 - val_precision_11: 0.8627 - val_mean_io_u_11: 0.8876 - val_accuracy: 0.9955 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 95/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2142 - recall_11: 0.8935 - precision_11: 0.8613 - mean_io_u_11: 0.8866 - accuracy: 0.9955 - auc: 0.9496\n",
      "Epoch 95: val_loss improved from 0.20985 to 0.20923, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 22s 341ms/step - loss: 0.2142 - recall_11: 0.8935 - precision_11: 0.8613 - mean_io_u_11: 0.8866 - accuracy: 0.9955 - auc: 0.9496 - val_loss: 0.2092 - val_recall_11: 0.8932 - val_precision_11: 0.8664 - val_mean_io_u_11: 0.8890 - val_accuracy: 0.9956 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 96/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2150 - recall_11: 0.8926 - precision_11: 0.8611 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9491\n",
      "Epoch 96: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 0.2150 - recall_11: 0.8926 - precision_11: 0.8611 - mean_io_u_11: 0.8861 - accuracy: 0.9955 - auc: 0.9491 - val_loss: 0.2111 - val_recall_11: 0.8929 - val_precision_11: 0.8647 - val_mean_io_u_11: 0.8881 - val_accuracy: 0.9956 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 97/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2143 - recall_11: 0.8924 - precision_11: 0.8620 - mean_io_u_11: 0.8864 - accuracy: 0.9955 - auc: 0.9491\n",
      "Epoch 97: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2144 - recall_11: 0.8924 - precision_11: 0.8619 - mean_io_u_11: 0.8863 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.2168 - val_recall_11: 0.8884 - val_precision_11: 0.8624 - val_mean_io_u_11: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9467 - lr: 1.0000e-05\n",
      "Epoch 98/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2144 - recall_11: 0.8917 - precision_11: 0.8623 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9487\n",
      "Epoch 98: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2144 - recall_11: 0.8917 - precision_11: 0.8623 - mean_io_u_11: 0.8862 - accuracy: 0.9955 - auc: 0.9487 - val_loss: 0.2167 - val_recall_11: 0.8889 - val_precision_11: 0.8621 - val_mean_io_u_11: 0.8854 - val_accuracy: 0.9954 - val_auc: 0.9470 - lr: 1.0000e-05\n",
      "Epoch 99/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2142 - recall_11: 0.8923 - precision_11: 0.8621 - mean_io_u_11: 0.8864 - accuracy: 0.9955 - auc: 0.9490\n",
      "Epoch 99: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2142 - recall_11: 0.8923 - precision_11: 0.8621 - mean_io_u_11: 0.8864 - accuracy: 0.9955 - auc: 0.9490 - val_loss: 0.2120 - val_recall_11: 0.8918 - val_precision_11: 0.8647 - val_mean_io_u_11: 0.8876 - val_accuracy: 0.9955 - val_auc: 0.9484 - lr: 1.0000e-05\n",
      "Epoch 100/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2135 - recall_11: 0.8926 - precision_11: 0.8625 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9492\n",
      "Epoch 100: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2135 - recall_11: 0.8926 - precision_11: 0.8625 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9492 - val_loss: 0.2175 - val_recall_11: 0.8885 - val_precision_11: 0.8616 - val_mean_io_u_11: 0.8850 - val_accuracy: 0.9954 - val_auc: 0.9467 - lr: 1.0000e-05\n",
      "Epoch 101/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2146 - recall_11: 0.8919 - precision_11: 0.8620 - mean_io_u_11: 0.8863 - accuracy: 0.9955 - auc: 0.9488\n",
      "Epoch 101: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2146 - recall_11: 0.8919 - precision_11: 0.8620 - mean_io_u_11: 0.8863 - accuracy: 0.9955 - auc: 0.9488 - val_loss: 0.2094 - val_recall_11: 0.8938 - val_precision_11: 0.8659 - val_mean_io_u_11: 0.8890 - val_accuracy: 0.9956 - val_auc: 0.9493 - lr: 1.0000e-05\n",
      "Epoch 102/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2143 - recall_11: 0.8928 - precision_11: 0.8616 - mean_io_u_11: 0.8865 - accuracy: 0.9955 - auc: 0.9492\n",
      "Epoch 102: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2143 - recall_11: 0.8929 - precision_11: 0.8616 - mean_io_u_11: 0.8865 - accuracy: 0.9955 - auc: 0.9492 - val_loss: 0.2209 - val_recall_11: 0.8857 - val_precision_11: 0.8601 - val_mean_io_u_11: 0.8831 - val_accuracy: 0.9953 - val_auc: 0.9454 - lr: 1.0000e-05\n",
      "Epoch 103/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2137 - recall_11: 0.8930 - precision_11: 0.8620 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9493\n",
      "Epoch 103: val_loss did not improve from 0.20923\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2138 - recall_11: 0.8930 - precision_11: 0.8620 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9493 - val_loss: 0.2199 - val_recall_11: 0.8865 - val_precision_11: 0.8606 - val_mean_io_u_11: 0.8836 - val_accuracy: 0.9954 - val_auc: 0.9458 - lr: 1.0000e-05\n",
      "Epoch 104/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2139 - recall_11: 0.8928 - precision_11: 0.8621 - mean_io_u_11: 0.8865 - accuracy: 0.9955 - auc: 0.9492\n",
      "Epoch 104: val_loss improved from 0.20923 to 0.20907, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 313ms/step - loss: 0.2140 - recall_11: 0.8927 - precision_11: 0.8620 - mean_io_u_11: 0.8865 - accuracy: 0.9955 - auc: 0.9491 - val_loss: 0.2091 - val_recall_11: 0.8943 - val_precision_11: 0.8657 - val_mean_io_u_11: 0.8892 - val_accuracy: 0.9956 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 105/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2136 - recall_11: 0.8931 - precision_11: 0.8620 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 105: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2137 - recall_11: 0.8931 - precision_11: 0.8620 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2107 - val_recall_11: 0.8924 - val_precision_11: 0.8655 - val_mean_io_u_11: 0.8882 - val_accuracy: 0.9956 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 106/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2137 - recall_11: 0.8933 - precision_11: 0.8618 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 106: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2136 - recall_11: 0.8933 - precision_11: 0.8618 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2371 - val_recall_11: 0.8748 - val_precision_11: 0.8519 - val_mean_io_u_11: 0.8755 - val_accuracy: 0.9950 - val_auc: 0.9399 - lr: 1.0000e-05\n",
      "Epoch 107/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2134 - recall_11: 0.8932 - precision_11: 0.8622 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 107: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2134 - recall_11: 0.8932 - precision_11: 0.8622 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2170 - val_recall_11: 0.8893 - val_precision_11: 0.8613 - val_mean_io_u_11: 0.8851 - val_accuracy: 0.9954 - val_auc: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 108/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2133 - recall_11: 0.8935 - precision_11: 0.8620 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 108: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2134 - recall_11: 0.8935 - precision_11: 0.8619 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2165 - val_recall_11: 0.8893 - val_precision_11: 0.8618 - val_mean_io_u_11: 0.8854 - val_accuracy: 0.9954 - val_auc: 0.9471 - lr: 1.0000e-05\n",
      "Epoch 109/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2135 - recall_11: 0.8933 - precision_11: 0.8619 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 109: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2135 - recall_11: 0.8933 - precision_11: 0.8619 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2100 - val_recall_11: 0.8925 - val_precision_11: 0.8661 - val_mean_io_u_11: 0.8885 - val_accuracy: 0.9956 - val_auc: 0.9488 - lr: 1.0000e-05\n",
      "Epoch 110/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2135 - recall_11: 0.8921 - precision_11: 0.8629 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9489\n",
      "Epoch 110: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2135 - recall_11: 0.8921 - precision_11: 0.8629 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9489 - val_loss: 0.2203 - val_recall_11: 0.8850 - val_precision_11: 0.8613 - val_mean_io_u_11: 0.8833 - val_accuracy: 0.9954 - val_auc: 0.9451 - lr: 1.0000e-05\n",
      "Epoch 111/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2126 - recall_11: 0.8922 - precision_11: 0.8637 - mean_io_u_11: 0.8869 - accuracy: 0.9955 - auc: 0.9490\n",
      "Epoch 111: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2126 - recall_11: 0.8922 - precision_11: 0.8636 - mean_io_u_11: 0.8869 - accuracy: 0.9955 - auc: 0.9489 - val_loss: 0.2095 - val_recall_11: 0.8932 - val_precision_11: 0.8660 - val_mean_io_u_11: 0.8888 - val_accuracy: 0.9956 - val_auc: 0.9491 - lr: 1.0000e-05\n",
      "Epoch 112/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2130 - recall_11: 0.8932 - precision_11: 0.8624 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 112: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2130 - recall_11: 0.8932 - precision_11: 0.8624 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2216 - val_recall_11: 0.8848 - val_precision_11: 0.8601 - val_mean_io_u_11: 0.8828 - val_accuracy: 0.9953 - val_auc: 0.9449 - lr: 1.0000e-05\n",
      "Epoch 113/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2128 - recall_11: 0.8925 - precision_11: 0.8632 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9491\n",
      "Epoch 113: val_loss did not improve from 0.20907\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2128 - recall_11: 0.8925 - precision_11: 0.8632 - mean_io_u_11: 0.8868 - accuracy: 0.9955 - auc: 0.9491 - val_loss: 0.2347 - val_recall_11: 0.8749 - val_precision_11: 0.8541 - val_mean_io_u_11: 0.8764 - val_accuracy: 0.9950 - val_auc: 0.9400 - lr: 1.0000e-05\n",
      "Epoch 114/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2126 - recall_11: 0.8931 - precision_11: 0.8629 - mean_io_u_11: 0.8870 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 114: val_loss improved from 0.20907 to 0.20852, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 331ms/step - loss: 0.2126 - recall_11: 0.8931 - precision_11: 0.8629 - mean_io_u_11: 0.8870 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2085 - val_recall_11: 0.8945 - val_precision_11: 0.8660 - val_mean_io_u_11: 0.8894 - val_accuracy: 0.9956 - val_auc: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 115/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2127 - recall_11: 0.8940 - precision_11: 0.8622 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9498\n",
      "Epoch 115: val_loss did not improve from 0.20852\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2128 - recall_11: 0.8939 - precision_11: 0.8622 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9498 - val_loss: 0.2209 - val_recall_11: 0.8864 - val_precision_11: 0.8593 - val_mean_io_u_11: 0.8832 - val_accuracy: 0.9953 - val_auc: 0.9457 - lr: 1.0000e-05\n",
      "Epoch 116/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2138 - recall_11: 0.8935 - precision_11: 0.8614 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 116: val_loss improved from 0.20852 to 0.20718, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 23s 349ms/step - loss: 0.2138 - recall_11: 0.8935 - precision_11: 0.8614 - mean_io_u_11: 0.8867 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2072 - val_recall_11: 0.8953 - val_precision_11: 0.8667 - val_mean_io_u_11: 0.8900 - val_accuracy: 0.9956 - val_auc: 0.9502 - lr: 1.0000e-05\n",
      "Epoch 117/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2130 - recall_11: 0.8930 - precision_11: 0.8626 - mean_io_u_11: 0.8869 - accuracy: 0.9955 - auc: 0.9493\n",
      "Epoch 117: val_loss did not improve from 0.20718\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2130 - recall_11: 0.8930 - precision_11: 0.8626 - mean_io_u_11: 0.8869 - accuracy: 0.9955 - auc: 0.9493 - val_loss: 0.2072 - val_recall_11: 0.8942 - val_precision_11: 0.8675 - val_mean_io_u_11: 0.8898 - val_accuracy: 0.9956 - val_auc: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 118/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2122 - recall_11: 0.8934 - precision_11: 0.8630 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 118: val_loss improved from 0.20718 to 0.20704, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 20s 312ms/step - loss: 0.2122 - recall_11: 0.8935 - precision_11: 0.8630 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2070 - val_recall_11: 0.8939 - val_precision_11: 0.8679 - val_mean_io_u_11: 0.8897 - val_accuracy: 0.9956 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 119/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2125 - recall_11: 0.8930 - precision_11: 0.8630 - mean_io_u_11: 0.8870 - accuracy: 0.9955 - auc: 0.9493\n",
      "Epoch 119: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2126 - recall_11: 0.8929 - precision_11: 0.8630 - mean_io_u_11: 0.8870 - accuracy: 0.9955 - auc: 0.9493 - val_loss: 0.2082 - val_recall_11: 0.8934 - val_precision_11: 0.8670 - val_mean_io_u_11: 0.8892 - val_accuracy: 0.9956 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 120/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2120 - recall_11: 0.8932 - precision_11: 0.8635 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 120: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2120 - recall_11: 0.8932 - precision_11: 0.8635 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2341 - val_recall_11: 0.8762 - val_precision_11: 0.8535 - val_mean_io_u_11: 0.8768 - val_accuracy: 0.9951 - val_auc: 0.9406 - lr: 1.0000e-05\n",
      "Epoch 121/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2121 - recall_11: 0.8935 - precision_11: 0.8631 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 121: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2123 - recall_11: 0.8933 - precision_11: 0.8630 - mean_io_u_11: 0.8871 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2382 - val_recall_11: 0.8720 - val_precision_11: 0.8526 - val_mean_io_u_11: 0.8746 - val_accuracy: 0.9950 - val_auc: 0.9384 - lr: 1.0000e-05\n",
      "Epoch 122/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2123 - recall_11: 0.8930 - precision_11: 0.8632 - mean_io_u_11: 0.8871 - accuracy: 0.9955 - auc: 0.9493\n",
      "Epoch 122: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2123 - recall_11: 0.8930 - precision_11: 0.8632 - mean_io_u_11: 0.8871 - accuracy: 0.9955 - auc: 0.9493 - val_loss: 0.2071 - val_recall_11: 0.8943 - val_precision_11: 0.8675 - val_mean_io_u_11: 0.8899 - val_accuracy: 0.9956 - val_auc: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 123/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2122 - recall_11: 0.8937 - precision_11: 0.8628 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9497\n",
      "Epoch 123: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2122 - recall_11: 0.8937 - precision_11: 0.8628 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9497 - val_loss: 0.2087 - val_recall_11: 0.8942 - val_precision_11: 0.8660 - val_mean_io_u_11: 0.8891 - val_accuracy: 0.9956 - val_auc: 0.9495 - lr: 1.0000e-05\n",
      "Epoch 124/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2122 - recall_11: 0.8932 - precision_11: 0.8632 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9494\n",
      "Epoch 124: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2122 - recall_11: 0.8932 - precision_11: 0.8632 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9494 - val_loss: 0.2117 - val_recall_11: 0.8915 - val_precision_11: 0.8648 - val_mean_io_u_11: 0.8875 - val_accuracy: 0.9955 - val_auc: 0.9483 - lr: 1.0000e-05\n",
      "Epoch 125/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2122 - recall_11: 0.8942 - precision_11: 0.8624 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9499\n",
      "Epoch 125: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2122 - recall_11: 0.8942 - precision_11: 0.8624 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9499 - val_loss: 0.2250 - val_recall_11: 0.8840 - val_precision_11: 0.8570 - val_mean_io_u_11: 0.8814 - val_accuracy: 0.9952 - val_auc: 0.9445 - lr: 1.0000e-05\n",
      "Epoch 126/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2117 - recall_11: 0.8943 - precision_11: 0.8627 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9500\n",
      "Epoch 126: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2117 - recall_11: 0.8943 - precision_11: 0.8627 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9500 - val_loss: 0.2172 - val_recall_11: 0.8879 - val_precision_11: 0.8620 - val_mean_io_u_11: 0.8848 - val_accuracy: 0.9954 - val_auc: 0.9465 - lr: 1.0000e-05\n",
      "Epoch 127/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2125 - recall_11: 0.8935 - precision_11: 0.8625 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9496\n",
      "Epoch 127: val_loss did not improve from 0.20704\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2125 - recall_11: 0.8935 - precision_11: 0.8625 - mean_io_u_11: 0.8872 - accuracy: 0.9955 - auc: 0.9496 - val_loss: 0.2120 - val_recall_11: 0.8931 - val_precision_11: 0.8633 - val_mean_io_u_11: 0.8877 - val_accuracy: 0.9955 - val_auc: 0.9490 - lr: 1.0000e-05\n",
      "Epoch 128/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2122 - recall_11: 0.8946 - precision_11: 0.8620 - mean_io_u_11: 0.8874 - accuracy: 0.9955 - auc: 0.9501\n",
      "Epoch 128: val_loss improved from 0.20704 to 0.20642, saving model to ./iter_wDice-40.model\n",
      "INFO:tensorflow:Assets written to: ./iter_wDice-40.model/assets\n",
      "65/65 [==============================] - 21s 329ms/step - loss: 0.2122 - recall_11: 0.8946 - precision_11: 0.8620 - mean_io_u_11: 0.8874 - accuracy: 0.9955 - auc: 0.9501 - val_loss: 0.2064 - val_recall_11: 0.8953 - val_precision_11: 0.8674 - val_mean_io_u_11: 0.8902 - val_accuracy: 0.9956 - val_auc: 0.9501 - lr: 1.0000e-05\n",
      "Epoch 129/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2117 - recall_11: 0.8932 - precision_11: 0.8635 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9495\n",
      "Epoch 129: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2117 - recall_11: 0.8932 - precision_11: 0.8635 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9495 - val_loss: 0.2067 - val_recall_11: 0.8950 - val_precision_11: 0.8674 - val_mean_io_u_11: 0.8901 - val_accuracy: 0.9956 - val_auc: 0.9500 - lr: 1.0000e-05\n",
      "Epoch 130/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2121 - recall_11: 0.8942 - precision_11: 0.8624 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9499\n",
      "Epoch 130: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2121 - recall_11: 0.8942 - precision_11: 0.8624 - mean_io_u_11: 0.8873 - accuracy: 0.9955 - auc: 0.9499 - val_loss: 0.2108 - val_recall_11: 0.8934 - val_precision_11: 0.8642 - val_mean_io_u_11: 0.8882 - val_accuracy: 0.9955 - val_auc: 0.9492 - lr: 1.0000e-05\n",
      "Epoch 131/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2110 - recall_11: 0.8942 - precision_11: 0.8635 - mean_io_u_11: 0.8878 - accuracy: 0.9955 - auc: 0.9499\n",
      "Epoch 131: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2111 - recall_11: 0.8941 - precision_11: 0.8635 - mean_io_u_11: 0.8878 - accuracy: 0.9955 - auc: 0.9499 - val_loss: 0.2181 - val_recall_11: 0.8864 - val_precision_11: 0.8622 - val_mean_io_u_11: 0.8841 - val_accuracy: 0.9954 - val_auc: 0.9458 - lr: 1.0000e-05\n",
      "Epoch 132/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2113 - recall_11: 0.8935 - precision_11: 0.8637 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9496\n",
      "Epoch 132: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2113 - recall_11: 0.8935 - precision_11: 0.8637 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9496 - val_loss: 0.2084 - val_recall_11: 0.8944 - val_precision_11: 0.8660 - val_mean_io_u_11: 0.8892 - val_accuracy: 0.9956 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 133/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2114 - recall_11: 0.8950 - precision_11: 0.8625 - mean_io_u_11: 0.8878 - accuracy: 0.9955 - auc: 0.9502\n",
      "Epoch 133: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2114 - recall_11: 0.8951 - precision_11: 0.8625 - mean_io_u_11: 0.8878 - accuracy: 0.9955 - auc: 0.9503 - val_loss: 0.2110 - val_recall_11: 0.8925 - val_precision_11: 0.8647 - val_mean_io_u_11: 0.8877 - val_accuracy: 0.9955 - val_auc: 0.9487 - lr: 1.0000e-05\n",
      "Epoch 134/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2111 - recall_11: 0.8942 - precision_11: 0.8633 - mean_io_u_11: 0.8877 - accuracy: 0.9955 - auc: 0.9500\n",
      "Epoch 134: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2111 - recall_11: 0.8942 - precision_11: 0.8633 - mean_io_u_11: 0.8877 - accuracy: 0.9955 - auc: 0.9500 - val_loss: 0.2067 - val_recall_11: 0.8955 - val_precision_11: 0.8667 - val_mean_io_u_11: 0.8901 - val_accuracy: 0.9956 - val_auc: 0.9502 - lr: 1.0000e-05\n",
      "Epoch 135/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2108 - recall_11: 0.8944 - precision_11: 0.8635 - mean_io_u_11: 0.8879 - accuracy: 0.9955 - auc: 0.9500\n",
      "Epoch 135: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 203ms/step - loss: 0.2108 - recall_11: 0.8944 - precision_11: 0.8635 - mean_io_u_11: 0.8879 - accuracy: 0.9955 - auc: 0.9500 - val_loss: 0.2142 - val_recall_11: 0.8904 - val_precision_11: 0.8631 - val_mean_io_u_11: 0.8862 - val_accuracy: 0.9955 - val_auc: 0.9477 - lr: 1.0000e-05\n",
      "Epoch 136/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2113 - recall_11: 0.8940 - precision_11: 0.8633 - mean_io_u_11: 0.8876 - accuracy: 0.9955 - auc: 0.9498\n",
      "Epoch 136: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2114 - recall_11: 0.8940 - precision_11: 0.8633 - mean_io_u_11: 0.8876 - accuracy: 0.9955 - auc: 0.9498 - val_loss: 0.2075 - val_recall_11: 0.8946 - val_precision_11: 0.8667 - val_mean_io_u_11: 0.8896 - val_accuracy: 0.9956 - val_auc: 0.9497 - lr: 1.0000e-05\n",
      "Epoch 137/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2115 - recall_11: 0.8941 - precision_11: 0.8629 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9499\n",
      "Epoch 137: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2115 - recall_11: 0.8941 - precision_11: 0.8629 - mean_io_u_11: 0.8875 - accuracy: 0.9955 - auc: 0.9499 - val_loss: 0.2078 - val_recall_11: 0.8951 - val_precision_11: 0.8659 - val_mean_io_u_11: 0.8895 - val_accuracy: 0.9956 - val_auc: 0.9500 - lr: 1.0000e-05\n",
      "Epoch 138/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2112 - recall_11: 0.8944 - precision_11: 0.8631 - mean_io_u_11: 0.8877 - accuracy: 0.9955 - auc: 0.9500\n",
      "Epoch 138: val_loss did not improve from 0.20642\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2112 - recall_11: 0.8945 - precision_11: 0.8631 - mean_io_u_11: 0.8877 - accuracy: 0.9955 - auc: 0.9500 - val_loss: 0.2078 - val_recall_11: 0.8942 - val_precision_11: 0.8667 - val_mean_io_u_11: 0.8894 - val_accuracy: 0.9956 - val_auc: 0.9496 - lr: 1.0000e-05\n",
      "Epoch 138: early stopping\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f041c4624c0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "Tensor(\"f/strided_slice:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"f/strided_slice_1:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"f/strided_slice:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"f/strided_slice_1:0\", shape=(None,), dtype=float32)\n",
      "65/65 [==============================] - ETA: 0s - loss: 1.4873 - recall_12: 0.9275 - precision_12: 0.1395 - mean_io_u_12: 0.5705 - accuracy: 0.8956 - auc: 0.9467Tensor(\"f/strided_slice:0\", shape=(None,), dtype=float32)\n",
      "Tensor(\"f/strided_slice_1:0\", shape=(None,), dtype=float32)\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.27119, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 27s 363ms/step - loss: 1.4873 - recall_12: 0.9275 - precision_12: 0.1395 - mean_io_u_12: 0.5705 - accuracy: 0.8956 - auc: 0.9467 - val_loss: 1.2712 - val_recall_12: 0.5008 - val_precision_12: 0.5639 - val_mean_io_u_12: 0.4910 - val_accuracy: 0.9840 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 1.1787 - recall_12: 0.9381 - precision_12: 0.5766 - mean_io_u_12: 0.7626 - accuracy: 0.9865 - auc: 0.9835\n",
      "Epoch 2: val_loss improved from 1.27119 to 0.96404, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 333ms/step - loss: 1.1783 - recall_12: 0.9381 - precision_12: 0.5767 - mean_io_u_12: 0.7627 - accuracy: 0.9865 - auc: 0.9834 - val_loss: 0.9640 - val_recall_12: 0.4656 - val_precision_12: 0.7280 - val_mean_io_u_12: 0.5067 - val_accuracy: 0.9872 - val_auc: 0.8868 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.9222 - recall_12: 0.9312 - precision_12: 0.6594 - mean_io_u_12: 0.8100 - accuracy: 0.9901 - auc: 0.9870\n",
      "Epoch 3: val_loss improved from 0.96404 to 0.68538, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 332ms/step - loss: 0.9222 - recall_12: 0.9312 - precision_12: 0.6594 - mean_io_u_12: 0.8100 - accuracy: 0.9901 - auc: 0.9870 - val_loss: 0.6854 - val_recall_12: 0.5921 - val_precision_12: 0.7141 - val_mean_io_u_12: 0.6106 - val_accuracy: 0.9884 - val_auc: 0.9071 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.6351 - recall_12: 0.9086 - precision_12: 0.7223 - mean_io_u_12: 0.8302 - accuracy: 0.9921 - auc: 0.9827\n",
      "Epoch 4: val_loss improved from 0.68538 to 0.39141, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 345ms/step - loss: 0.6346 - recall_12: 0.9086 - precision_12: 0.7224 - mean_io_u_12: 0.8302 - accuracy: 0.9921 - auc: 0.9827 - val_loss: 0.3914 - val_recall_12: 0.7873 - val_precision_12: 0.7168 - val_mean_io_u_12: 0.7469 - val_accuracy: 0.9906 - val_auc: 0.9818 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3936 - recall_12: 0.8771 - precision_12: 0.7785 - mean_io_u_12: 0.8281 - accuracy: 0.9933 - auc: 0.9811\n",
      "Epoch 5: val_loss improved from 0.39141 to 0.31958, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.3935 - recall_12: 0.8770 - precision_12: 0.7785 - mean_io_u_12: 0.8280 - accuracy: 0.9933 - auc: 0.9811 - val_loss: 0.3196 - val_recall_12: 0.7606 - val_precision_12: 0.7693 - val_mean_io_u_12: 0.7436 - val_accuracy: 0.9916 - val_auc: 0.9621 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2865 - recall_12: 0.8623 - precision_12: 0.8054 - mean_io_u_12: 0.8092 - accuracy: 0.9938 - auc: 0.9861\n",
      "Epoch 6: val_loss improved from 0.31958 to 0.24795, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 24s 366ms/step - loss: 0.2865 - recall_12: 0.8623 - precision_12: 0.8054 - mean_io_u_12: 0.8092 - accuracy: 0.9938 - auc: 0.9861 - val_loss: 0.2480 - val_recall_12: 0.8282 - val_precision_12: 0.8034 - val_mean_io_u_12: 0.7687 - val_accuracy: 0.9932 - val_auc: 0.9736 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2362 - recall_12: 0.8656 - precision_12: 0.8226 - mean_io_u_12: 0.7902 - accuracy: 0.9942 - auc: 0.9850\n",
      "Epoch 7: val_loss improved from 0.24795 to 0.21069, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.2362 - recall_12: 0.8656 - precision_12: 0.8226 - mean_io_u_12: 0.7901 - accuracy: 0.9942 - auc: 0.9850 - val_loss: 0.2107 - val_recall_12: 0.8517 - val_precision_12: 0.8306 - val_mean_io_u_12: 0.7886 - val_accuracy: 0.9942 - val_auc: 0.9741 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2126 - recall_12: 0.8680 - precision_12: 0.8303 - mean_io_u_12: 0.7744 - accuracy: 0.9944 - auc: 0.9832\n",
      "Epoch 8: val_loss improved from 0.21069 to 0.19459, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 320ms/step - loss: 0.2126 - recall_12: 0.8680 - precision_12: 0.8304 - mean_io_u_12: 0.7743 - accuracy: 0.9944 - auc: 0.9833 - val_loss: 0.1946 - val_recall_12: 0.8611 - val_precision_12: 0.8438 - val_mean_io_u_12: 0.7710 - val_accuracy: 0.9946 - val_auc: 0.9751 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1933 - recall_12: 0.8753 - precision_12: 0.8392 - mean_io_u_12: 0.7628 - accuracy: 0.9947 - auc: 0.9834\n",
      "Epoch 9: val_loss did not improve from 0.19459\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1932 - recall_12: 0.8753 - precision_12: 0.8392 - mean_io_u_12: 0.7627 - accuracy: 0.9947 - auc: 0.9834 - val_loss: 0.2314 - val_recall_12: 0.8089 - val_precision_12: 0.8235 - val_mean_io_u_12: 0.7158 - val_accuracy: 0.9934 - val_auc: 0.9603 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1813 - recall_12: 0.8789 - precision_12: 0.8459 - mean_io_u_12: 0.7521 - accuracy: 0.9949 - auc: 0.9834\n",
      "Epoch 10: val_loss did not improve from 0.19459\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1813 - recall_12: 0.8789 - precision_12: 0.8459 - mean_io_u_12: 0.7521 - accuracy: 0.9949 - auc: 0.9834 - val_loss: 0.1947 - val_recall_12: 0.8614 - val_precision_12: 0.8328 - val_mean_io_u_12: 0.7343 - val_accuracy: 0.9944 - val_auc: 0.9741 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1699 - recall_12: 0.8845 - precision_12: 0.8527 - mean_io_u_12: 0.7448 - accuracy: 0.9952 - auc: 0.9843\n",
      "Epoch 11: val_loss improved from 0.19459 to 0.17895, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 343ms/step - loss: 0.1699 - recall_12: 0.8845 - precision_12: 0.8527 - mean_io_u_12: 0.7448 - accuracy: 0.9952 - auc: 0.9842 - val_loss: 0.1789 - val_recall_12: 0.8781 - val_precision_12: 0.8412 - val_mean_io_u_12: 0.7560 - val_accuracy: 0.9948 - val_auc: 0.9770 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1633 - recall_12: 0.8874 - precision_12: 0.8564 - mean_io_u_12: 0.7376 - accuracy: 0.9953 - auc: 0.9845\n",
      "Epoch 12: val_loss did not improve from 0.17895\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1633 - recall_12: 0.8874 - precision_12: 0.8564 - mean_io_u_12: 0.7376 - accuracy: 0.9953 - auc: 0.9845 - val_loss: 0.1802 - val_recall_12: 0.8566 - val_precision_12: 0.8550 - val_mean_io_u_12: 0.7231 - val_accuracy: 0.9948 - val_auc: 0.9725 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1563 - recall_12: 0.8906 - precision_12: 0.8616 - mean_io_u_12: 0.7337 - accuracy: 0.9955 - auc: 0.9845\n",
      "Epoch 13: val_loss improved from 0.17895 to 0.16397, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 335ms/step - loss: 0.1563 - recall_12: 0.8906 - precision_12: 0.8616 - mean_io_u_12: 0.7337 - accuracy: 0.9955 - auc: 0.9845 - val_loss: 0.1640 - val_recall_12: 0.8848 - val_precision_12: 0.8552 - val_mean_io_u_12: 0.7332 - val_accuracy: 0.9952 - val_auc: 0.9806 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1504 - recall_12: 0.8934 - precision_12: 0.8662 - mean_io_u_12: 0.7291 - accuracy: 0.9956 - auc: 0.9852\n",
      "Epoch 14: val_loss improved from 0.16397 to 0.15287, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 23s 353ms/step - loss: 0.1504 - recall_12: 0.8934 - precision_12: 0.8662 - mean_io_u_12: 0.7291 - accuracy: 0.9956 - auc: 0.9852 - val_loss: 0.1529 - val_recall_12: 0.8856 - val_precision_12: 0.8658 - val_mean_io_u_12: 0.7325 - val_accuracy: 0.9955 - val_auc: 0.9817 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1452 - recall_12: 0.8969 - precision_12: 0.8696 - mean_io_u_12: 0.7270 - accuracy: 0.9957 - auc: 0.9856\n",
      "Epoch 15: val_loss improved from 0.15287 to 0.14419, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 345ms/step - loss: 0.1451 - recall_12: 0.8969 - precision_12: 0.8696 - mean_io_u_12: 0.7270 - accuracy: 0.9957 - auc: 0.9856 - val_loss: 0.1442 - val_recall_12: 0.8920 - val_precision_12: 0.8732 - val_mean_io_u_12: 0.7288 - val_accuracy: 0.9957 - val_auc: 0.9829 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1390 - recall_12: 0.9002 - precision_12: 0.8749 - mean_io_u_12: 0.7274 - accuracy: 0.9959 - auc: 0.9863\n",
      "Epoch 16: val_loss did not improve from 0.14419\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.1390 - recall_12: 0.9002 - precision_12: 0.8749 - mean_io_u_12: 0.7274 - accuracy: 0.9959 - auc: 0.9863 - val_loss: 0.1477 - val_recall_12: 0.8860 - val_precision_12: 0.8748 - val_mean_io_u_12: 0.7291 - val_accuracy: 0.9957 - val_auc: 0.9810 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1357 - recall_12: 0.9019 - precision_12: 0.8777 - mean_io_u_12: 0.7244 - accuracy: 0.9960 - auc: 0.9863\n",
      "Epoch 17: val_loss did not improve from 0.14419\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1356 - recall_12: 0.9019 - precision_12: 0.8777 - mean_io_u_12: 0.7244 - accuracy: 0.9960 - auc: 0.9863 - val_loss: 0.2014 - val_recall_12: 0.8316 - val_precision_12: 0.8406 - val_mean_io_u_12: 0.6996 - val_accuracy: 0.9941 - val_auc: 0.9595 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1328 - recall_12: 0.9035 - precision_12: 0.8801 - mean_io_u_12: 0.7221 - accuracy: 0.9960 - auc: 0.9865\n",
      "Epoch 18: val_loss improved from 0.14419 to 0.13201, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 322ms/step - loss: 0.1328 - recall_12: 0.9035 - precision_12: 0.8801 - mean_io_u_12: 0.7221 - accuracy: 0.9960 - auc: 0.9865 - val_loss: 0.1320 - val_recall_12: 0.8950 - val_precision_12: 0.8893 - val_mean_io_u_12: 0.7196 - val_accuracy: 0.9961 - val_auc: 0.9837 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1287 - recall_12: 0.9058 - precision_12: 0.8838 - mean_io_u_12: 0.7211 - accuracy: 0.9962 - auc: 0.9867\n",
      "Epoch 19: val_loss did not improve from 0.13201\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1287 - recall_12: 0.9058 - precision_12: 0.8838 - mean_io_u_12: 0.7211 - accuracy: 0.9962 - auc: 0.9867 - val_loss: 0.1454 - val_recall_12: 0.8942 - val_precision_12: 0.8676 - val_mean_io_u_12: 0.7310 - val_accuracy: 0.9956 - val_auc: 0.9808 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1359 - recall_12: 0.9013 - precision_12: 0.8759 - mean_io_u_12: 0.7080 - accuracy: 0.9959 - auc: 0.9854\n",
      "Epoch 20: val_loss did not improve from 0.13201\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1359 - recall_12: 0.9013 - precision_12: 0.8759 - mean_io_u_12: 0.7080 - accuracy: 0.9959 - auc: 0.9854 - val_loss: 0.1434 - val_recall_12: 0.8877 - val_precision_12: 0.8758 - val_mean_io_u_12: 0.7023 - val_accuracy: 0.9957 - val_auc: 0.9798 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1301 - recall_12: 0.9042 - precision_12: 0.8820 - mean_io_u_12: 0.7092 - accuracy: 0.9961 - auc: 0.9861\n",
      "Epoch 21: val_loss did not improve from 0.13201\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1301 - recall_12: 0.9042 - precision_12: 0.8820 - mean_io_u_12: 0.7092 - accuracy: 0.9961 - auc: 0.9861 - val_loss: 0.1382 - val_recall_12: 0.8884 - val_precision_12: 0.8827 - val_mean_io_u_12: 0.7017 - val_accuracy: 0.9959 - val_auc: 0.9810 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1275 - recall_12: 0.9058 - precision_12: 0.8844 - mean_io_u_12: 0.7087 - accuracy: 0.9962 - auc: 0.9863\n",
      "Epoch 22: val_loss improved from 0.13201 to 0.12899, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 23s 353ms/step - loss: 0.1275 - recall_12: 0.9058 - precision_12: 0.8843 - mean_io_u_12: 0.7087 - accuracy: 0.9962 - auc: 0.9863 - val_loss: 0.1290 - val_recall_12: 0.9023 - val_precision_12: 0.8845 - val_mean_io_u_12: 0.7093 - val_accuracy: 0.9961 - val_auc: 0.9841 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1227 - recall_12: 0.9094 - precision_12: 0.8882 - mean_io_u_12: 0.7084 - accuracy: 0.9963 - auc: 0.9870\n",
      "Epoch 23: val_loss improved from 0.12899 to 0.12512, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.1227 - recall_12: 0.9094 - precision_12: 0.8882 - mean_io_u_12: 0.7084 - accuracy: 0.9963 - auc: 0.9870 - val_loss: 0.1251 - val_recall_12: 0.8996 - val_precision_12: 0.8930 - val_mean_io_u_12: 0.7129 - val_accuracy: 0.9962 - val_auc: 0.9830 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1196 - recall_12: 0.9112 - precision_12: 0.8911 - mean_io_u_12: 0.7101 - accuracy: 0.9964 - auc: 0.9874\n",
      "Epoch 24: val_loss improved from 0.12512 to 0.12184, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.1196 - recall_12: 0.9112 - precision_12: 0.8912 - mean_io_u_12: 0.7102 - accuracy: 0.9964 - auc: 0.9874 - val_loss: 0.1218 - val_recall_12: 0.9006 - val_precision_12: 0.8969 - val_mean_io_u_12: 0.7173 - val_accuracy: 0.9963 - val_auc: 0.9839 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1179 - recall_12: 0.9121 - precision_12: 0.8929 - mean_io_u_12: 0.7122 - accuracy: 0.9964 - auc: 0.9874\n",
      "Epoch 25: val_loss did not improve from 0.12184\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1179 - recall_12: 0.9121 - precision_12: 0.8929 - mean_io_u_12: 0.7122 - accuracy: 0.9964 - auc: 0.9874 - val_loss: 0.1233 - val_recall_12: 0.9014 - val_precision_12: 0.8938 - val_mean_io_u_12: 0.7034 - val_accuracy: 0.9963 - val_auc: 0.9849 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1160 - recall_12: 0.9134 - precision_12: 0.8944 - mean_io_u_12: 0.7081 - accuracy: 0.9965 - auc: 0.9878\n",
      "Epoch 26: val_loss improved from 0.12184 to 0.12058, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.1160 - recall_12: 0.9134 - precision_12: 0.8944 - mean_io_u_12: 0.7081 - accuracy: 0.9965 - auc: 0.9878 - val_loss: 0.1206 - val_recall_12: 0.9003 - val_precision_12: 0.8993 - val_mean_io_u_12: 0.7070 - val_accuracy: 0.9964 - val_auc: 0.9839 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1145 - recall_12: 0.9143 - precision_12: 0.8959 - mean_io_u_12: 0.7088 - accuracy: 0.9965 - auc: 0.9877\n",
      "Epoch 27: val_loss did not improve from 0.12058\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1145 - recall_12: 0.9143 - precision_12: 0.8959 - mean_io_u_12: 0.7088 - accuracy: 0.9965 - auc: 0.9877 - val_loss: 0.1234 - val_recall_12: 0.9030 - val_precision_12: 0.8916 - val_mean_io_u_12: 0.7097 - val_accuracy: 0.9963 - val_auc: 0.9837 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1145 - recall_12: 0.9141 - precision_12: 0.8958 - mean_io_u_12: 0.7058 - accuracy: 0.9965 - auc: 0.9875\n",
      "Epoch 28: val_loss did not improve from 0.12058\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1145 - recall_12: 0.9141 - precision_12: 0.8958 - mean_io_u_12: 0.7058 - accuracy: 0.9965 - auc: 0.9875 - val_loss: 0.1357 - val_recall_12: 0.8939 - val_precision_12: 0.8806 - val_mean_io_u_12: 0.7033 - val_accuracy: 0.9959 - val_auc: 0.9808 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1142 - recall_12: 0.9147 - precision_12: 0.8954 - mean_io_u_12: 0.7057 - accuracy: 0.9965 - auc: 0.9877\n",
      "Epoch 29: val_loss improved from 0.12058 to 0.11655, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 24s 365ms/step - loss: 0.1142 - recall_12: 0.9147 - precision_12: 0.8954 - mean_io_u_12: 0.7057 - accuracy: 0.9965 - auc: 0.9877 - val_loss: 0.1166 - val_recall_12: 0.9076 - val_precision_12: 0.8978 - val_mean_io_u_12: 0.7043 - val_accuracy: 0.9965 - val_auc: 0.9853 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1119 - recall_12: 0.9158 - precision_12: 0.8983 - mean_io_u_12: 0.7032 - accuracy: 0.9966 - auc: 0.9878\n",
      "Epoch 30: val_loss did not improve from 0.11655\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1119 - recall_12: 0.9158 - precision_12: 0.8983 - mean_io_u_12: 0.7032 - accuracy: 0.9966 - auc: 0.9878 - val_loss: 0.1183 - val_recall_12: 0.9010 - val_precision_12: 0.9014 - val_mean_io_u_12: 0.7067 - val_accuracy: 0.9964 - val_auc: 0.9829 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1115 - recall_12: 0.9157 - precision_12: 0.8987 - mean_io_u_12: 0.7005 - accuracy: 0.9966 - auc: 0.9878\n",
      "Epoch 31: val_loss improved from 0.11655 to 0.11393, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 340ms/step - loss: 0.1115 - recall_12: 0.9157 - precision_12: 0.8986 - mean_io_u_12: 0.7005 - accuracy: 0.9966 - auc: 0.9878 - val_loss: 0.1139 - val_recall_12: 0.9132 - val_precision_12: 0.8964 - val_mean_io_u_12: 0.7053 - val_accuracy: 0.9965 - val_auc: 0.9859 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1103 - recall_12: 0.9164 - precision_12: 0.8999 - mean_io_u_12: 0.7006 - accuracy: 0.9967 - auc: 0.9879\n",
      "Epoch 32: val_loss did not improve from 0.11393\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1103 - recall_12: 0.9164 - precision_12: 0.8999 - mean_io_u_12: 0.7006 - accuracy: 0.9967 - auc: 0.9879 - val_loss: 0.1195 - val_recall_12: 0.9049 - val_precision_12: 0.8956 - val_mean_io_u_12: 0.6986 - val_accuracy: 0.9964 - val_auc: 0.9837 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1087 - recall_12: 0.9178 - precision_12: 0.9010 - mean_io_u_12: 0.7006 - accuracy: 0.9967 - auc: 0.9881\n",
      "Epoch 33: val_loss did not improve from 0.11393\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1087 - recall_12: 0.9178 - precision_12: 0.9010 - mean_io_u_12: 0.7006 - accuracy: 0.9967 - auc: 0.9881 - val_loss: 0.1164 - val_recall_12: 0.9088 - val_precision_12: 0.8965 - val_mean_io_u_12: 0.7030 - val_accuracy: 0.9965 - val_auc: 0.9844 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1080 - recall_12: 0.9180 - precision_12: 0.9021 - mean_io_u_12: 0.6987 - accuracy: 0.9967 - auc: 0.9881\n",
      "Epoch 34: val_loss did not improve from 0.11393\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1080 - recall_12: 0.9180 - precision_12: 0.9021 - mean_io_u_12: 0.6987 - accuracy: 0.9967 - auc: 0.9881 - val_loss: 0.1150 - val_recall_12: 0.9113 - val_precision_12: 0.8960 - val_mean_io_u_12: 0.6962 - val_accuracy: 0.9965 - val_auc: 0.9855 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1067 - recall_12: 0.9188 - precision_12: 0.9033 - mean_io_u_12: 0.6950 - accuracy: 0.9968 - auc: 0.9881\n",
      "Epoch 35: val_loss improved from 0.11393 to 0.11190, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 321ms/step - loss: 0.1067 - recall_12: 0.9188 - precision_12: 0.9033 - mean_io_u_12: 0.6950 - accuracy: 0.9968 - auc: 0.9881 - val_loss: 0.1119 - val_recall_12: 0.9124 - val_precision_12: 0.9000 - val_mean_io_u_12: 0.6974 - val_accuracy: 0.9966 - val_auc: 0.9859 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1077 - recall_12: 0.9180 - precision_12: 0.9025 - mean_io_u_12: 0.6935 - accuracy: 0.9967 - auc: 0.9879\n",
      "Epoch 36: val_loss did not improve from 0.11190\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.1077 - recall_12: 0.9180 - precision_12: 0.9024 - mean_io_u_12: 0.6935 - accuracy: 0.9967 - auc: 0.9879 - val_loss: 0.1161 - val_recall_12: 0.9036 - val_precision_12: 0.9015 - val_mean_io_u_12: 0.6887 - val_accuracy: 0.9965 - val_auc: 0.9835 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1062 - recall_12: 0.9191 - precision_12: 0.9037 - mean_io_u_12: 0.6939 - accuracy: 0.9968 - auc: 0.9882\n",
      "Epoch 37: val_loss did not improve from 0.11190\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1062 - recall_12: 0.9191 - precision_12: 0.9037 - mean_io_u_12: 0.6939 - accuracy: 0.9968 - auc: 0.9882 - val_loss: 0.1146 - val_recall_12: 0.9098 - val_precision_12: 0.8978 - val_mean_io_u_12: 0.6968 - val_accuracy: 0.9965 - val_auc: 0.9852 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1047 - recall_12: 0.9201 - precision_12: 0.9051 - mean_io_u_12: 0.6936 - accuracy: 0.9968 - auc: 0.9883\n",
      "Epoch 38: val_loss did not improve from 0.11190\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1047 - recall_12: 0.9201 - precision_12: 0.9051 - mean_io_u_12: 0.6936 - accuracy: 0.9968 - auc: 0.9883 - val_loss: 0.1139 - val_recall_12: 0.9086 - val_precision_12: 0.9005 - val_mean_io_u_12: 0.6878 - val_accuracy: 0.9965 - val_auc: 0.9846 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1052 - recall_12: 0.9200 - precision_12: 0.9043 - mean_io_u_12: 0.6888 - accuracy: 0.9968 - auc: 0.9883\n",
      "Epoch 39: val_loss did not improve from 0.11190\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1052 - recall_12: 0.9200 - precision_12: 0.9043 - mean_io_u_12: 0.6888 - accuracy: 0.9968 - auc: 0.9883 - val_loss: 0.1146 - val_recall_12: 0.9071 - val_precision_12: 0.9007 - val_mean_io_u_12: 0.6975 - val_accuracy: 0.9965 - val_auc: 0.9832 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1036 - recall_12: 0.9207 - precision_12: 0.9062 - mean_io_u_12: 0.6916 - accuracy: 0.9969 - auc: 0.9884\n",
      "Epoch 40: val_loss did not improve from 0.11190\n",
      "\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.1036 - recall_12: 0.9207 - precision_12: 0.9062 - mean_io_u_12: 0.6916 - accuracy: 0.9969 - auc: 0.9884 - val_loss: 0.1159 - val_recall_12: 0.9035 - val_precision_12: 0.9020 - val_mean_io_u_12: 0.6942 - val_accuracy: 0.9965 - val_auc: 0.9823 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0994 - recall_12: 0.9232 - precision_12: 0.9109 - mean_io_u_12: 0.6896 - accuracy: 0.9970 - auc: 0.9890\n",
      "Epoch 41: val_loss improved from 0.11190 to 0.10852, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 344ms/step - loss: 0.0994 - recall_12: 0.9232 - precision_12: 0.9109 - mean_io_u_12: 0.6896 - accuracy: 0.9970 - auc: 0.9890 - val_loss: 0.1085 - val_recall_12: 0.9121 - val_precision_12: 0.9058 - val_mean_io_u_12: 0.6928 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0975 - recall_12: 0.9251 - precision_12: 0.9123 - mean_io_u_12: 0.6919 - accuracy: 0.9970 - auc: 0.9892\n",
      "Epoch 42: val_loss improved from 0.10852 to 0.10814, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 334ms/step - loss: 0.0975 - recall_12: 0.9251 - precision_12: 0.9123 - mean_io_u_12: 0.6919 - accuracy: 0.9970 - auc: 0.9892 - val_loss: 0.1081 - val_recall_12: 0.9132 - val_precision_12: 0.9054 - val_mean_io_u_12: 0.6958 - val_accuracy: 0.9967 - val_auc: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0969 - recall_12: 0.9253 - precision_12: 0.9131 - mean_io_u_12: 0.6939 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 43: val_loss did not improve from 0.10814\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.0969 - recall_12: 0.9253 - precision_12: 0.9131 - mean_io_u_12: 0.6939 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1082 - val_recall_12: 0.9141 - val_precision_12: 0.9045 - val_mean_io_u_12: 0.6976 - val_accuracy: 0.9967 - val_auc: 0.9853 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0966 - recall_12: 0.9255 - precision_12: 0.9134 - mean_io_u_12: 0.6956 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 44: val_loss improved from 0.10814 to 0.10755, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 23s 355ms/step - loss: 0.0966 - recall_12: 0.9255 - precision_12: 0.9134 - mean_io_u_12: 0.6955 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1076 - val_recall_12: 0.9148 - val_precision_12: 0.9047 - val_mean_io_u_12: 0.6994 - val_accuracy: 0.9967 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0963 - recall_12: 0.9257 - precision_12: 0.9139 - mean_io_u_12: 0.6950 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 45: val_loss improved from 0.10755 to 0.10731, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 342ms/step - loss: 0.0963 - recall_12: 0.9256 - precision_12: 0.9139 - mean_io_u_12: 0.6950 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1073 - val_recall_12: 0.9143 - val_precision_12: 0.9055 - val_mean_io_u_12: 0.6985 - val_accuracy: 0.9967 - val_auc: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0959 - recall_12: 0.9264 - precision_12: 0.9139 - mean_io_u_12: 0.6957 - accuracy: 0.9971 - auc: 0.9892\n",
      "Epoch 46: val_loss did not improve from 0.10731\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0959 - recall_12: 0.9264 - precision_12: 0.9139 - mean_io_u_12: 0.6957 - accuracy: 0.9971 - auc: 0.9892 - val_loss: 0.1080 - val_recall_12: 0.9145 - val_precision_12: 0.9043 - val_mean_io_u_12: 0.6998 - val_accuracy: 0.9967 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0960 - recall_12: 0.9261 - precision_12: 0.9139 - mean_io_u_12: 0.6954 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 47: val_loss did not improve from 0.10731\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0961 - recall_12: 0.9261 - precision_12: 0.9138 - mean_io_u_12: 0.6954 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1082 - val_recall_12: 0.9143 - val_precision_12: 0.9039 - val_mean_io_u_12: 0.6986 - val_accuracy: 0.9967 - val_auc: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0956 - recall_12: 0.9263 - precision_12: 0.9143 - mean_io_u_12: 0.6957 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 48: val_loss did not improve from 0.10731\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0956 - recall_12: 0.9263 - precision_12: 0.9143 - mean_io_u_12: 0.6957 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1076 - val_recall_12: 0.9138 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7006 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0954 - recall_12: 0.9262 - precision_12: 0.9148 - mean_io_u_12: 0.6967 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 49: val_loss did not improve from 0.10731\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.0954 - recall_12: 0.9262 - precision_12: 0.9148 - mean_io_u_12: 0.6967 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1076 - val_recall_12: 0.9146 - val_precision_12: 0.9047 - val_mean_io_u_12: 0.7001 - val_accuracy: 0.9967 - val_auc: 0.9855 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0950 - recall_12: 0.9266 - precision_12: 0.9151 - mean_io_u_12: 0.6970 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 50: val_loss did not improve from 0.10731\n",
      "\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.0951 - recall_12: 0.9266 - precision_12: 0.9151 - mean_io_u_12: 0.6971 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1075 - val_recall_12: 0.9149 - val_precision_12: 0.9048 - val_mean_io_u_12: 0.7004 - val_accuracy: 0.9967 - val_auc: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0947 - recall_12: 0.9270 - precision_12: 0.9151 - mean_io_u_12: 0.6971 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 51: val_loss did not improve from 0.10731\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.0947 - recall_12: 0.9270 - precision_12: 0.9151 - mean_io_u_12: 0.6971 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1074 - val_recall_12: 0.9145 - val_precision_12: 0.9054 - val_mean_io_u_12: 0.7001 - val_accuracy: 0.9967 - val_auc: 0.9853 - lr: 1.0000e-05\n",
      "Epoch 52/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0947 - recall_12: 0.9266 - precision_12: 0.9157 - mean_io_u_12: 0.6970 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 52: val_loss improved from 0.10731 to 0.10722, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 328ms/step - loss: 0.0947 - recall_12: 0.9266 - precision_12: 0.9157 - mean_io_u_12: 0.6970 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9147 - val_precision_12: 0.9055 - val_mean_io_u_12: 0.7007 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0947 - recall_12: 0.9268 - precision_12: 0.9153 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 53: val_loss improved from 0.10722 to 0.10721, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 22s 343ms/step - loss: 0.0947 - recall_12: 0.9268 - precision_12: 0.9153 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9144 - val_precision_12: 0.9057 - val_mean_io_u_12: 0.7007 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0945 - recall_12: 0.9272 - precision_12: 0.9154 - mean_io_u_12: 0.6972 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 54: val_loss improved from 0.10721 to 0.10714, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 325ms/step - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9154 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9149 - val_precision_12: 0.9054 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 55/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0945 - recall_12: 0.9273 - precision_12: 0.9155 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9892\n",
      "Epoch 55: val_loss improved from 0.10714 to 0.10712, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 23s 362ms/step - loss: 0.0945 - recall_12: 0.9273 - precision_12: 0.9155 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9892 - val_loss: 0.1071 - val_recall_12: 0.9150 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 56/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0945 - recall_12: 0.9272 - precision_12: 0.9153 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 56: val_loss did not improve from 0.10712\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 0.0945 - recall_12: 0.9272 - precision_12: 0.9153 - mean_io_u_12: 0.6974 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9143 - val_precision_12: 0.9057 - val_mean_io_u_12: 0.7008 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0945 - recall_12: 0.9268 - precision_12: 0.9157 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 57: val_loss did not improve from 0.10712\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.0945 - recall_12: 0.9268 - precision_12: 0.9157 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1072 - val_recall_12: 0.9147 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 58/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0944 - recall_12: 0.9269 - precision_12: 0.9158 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 58: val_loss improved from 0.10712 to 0.10702, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 331ms/step - loss: 0.0944 - recall_12: 0.9270 - precision_12: 0.9158 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1070 - val_recall_12: 0.9149 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 59/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9153 - mean_io_u_12: 0.6975 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 59: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9153 - mean_io_u_12: 0.6975 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1070 - val_recall_12: 0.9151 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9853 - lr: 1.0000e-05\n",
      "Epoch 60/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9156 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 60: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9156 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1070 - val_recall_12: 0.9150 - val_precision_12: 0.9054 - val_mean_io_u_12: 0.7014 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0944 - recall_12: 0.9270 - precision_12: 0.9158 - mean_io_u_12: 0.6974 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 61: val_loss improved from 0.10702 to 0.10702, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 19s 293ms/step - loss: 0.0944 - recall_12: 0.9270 - precision_12: 0.9157 - mean_io_u_12: 0.6974 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1070 - val_recall_12: 0.9147 - val_precision_12: 0.9058 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9156 - mean_io_u_12: 0.6974 - accuracy: 0.9971 - auc: 0.9892\n",
      "Epoch 62: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 185ms/step - loss: 0.0944 - recall_12: 0.9272 - precision_12: 0.9155 - mean_io_u_12: 0.6974 - accuracy: 0.9971 - auc: 0.9892 - val_loss: 0.1071 - val_recall_12: 0.9146 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7008 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0943 - recall_12: 0.9271 - precision_12: 0.9158 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9890\n",
      "Epoch 63: val_loss did not improve from 0.10702\n",
      "\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 12s 183ms/step - loss: 0.0943 - recall_12: 0.9271 - precision_12: 0.9158 - mean_io_u_12: 0.6973 - accuracy: 0.9972 - auc: 0.9890 - val_loss: 0.1073 - val_recall_12: 0.9146 - val_precision_12: 0.9055 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0943 - recall_12: 0.9273 - precision_12: 0.9155 - mean_io_u_12: 0.6975 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 64: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0943 - recall_12: 0.9274 - precision_12: 0.9155 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1073 - val_recall_12: 0.9147 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 65/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0941 - recall_12: 0.9273 - precision_12: 0.9159 - mean_io_u_12: 0.6973 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 65: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0941 - recall_12: 0.9273 - precision_12: 0.9159 - mean_io_u_12: 0.6973 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9149 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 66/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0943 - recall_12: 0.9272 - precision_12: 0.9155 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9891\n",
      "Epoch 66: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0944 - recall_12: 0.9271 - precision_12: 0.9155 - mean_io_u_12: 0.6975 - accuracy: 0.9971 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9150 - val_precision_12: 0.9052 - val_mean_io_u_12: 0.7012 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 67/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0942 - recall_12: 0.9272 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9890\n",
      "Epoch 67: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 180ms/step - loss: 0.0942 - recall_12: 0.9272 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9890 - val_loss: 0.1071 - val_recall_12: 0.9153 - val_precision_12: 0.9051 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 68/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0943 - recall_12: 0.9274 - precision_12: 0.9153 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9892\n",
      "Epoch 68: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0943 - recall_12: 0.9274 - precision_12: 0.9154 - mean_io_u_12: 0.6976 - accuracy: 0.9971 - auc: 0.9892 - val_loss: 0.1072 - val_recall_12: 0.9150 - val_precision_12: 0.9052 - val_mean_io_u_12: 0.7010 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 69/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0943 - recall_12: 0.9273 - precision_12: 0.9155 - mean_io_u_12: 0.6973 - accuracy: 0.9971 - auc: 0.9890\n",
      "Epoch 69: val_loss did not improve from 0.10702\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0944 - recall_12: 0.9273 - precision_12: 0.9155 - mean_io_u_12: 0.6972 - accuracy: 0.9971 - auc: 0.9890 - val_loss: 0.1072 - val_recall_12: 0.9151 - val_precision_12: 0.9051 - val_mean_io_u_12: 0.7011 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 70/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9159 - mean_io_u_12: 0.6972 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 70: val_loss improved from 0.10702 to 0.10693, saving model to ./iter_DiceBCE.model\n",
      "INFO:tensorflow:Assets written to: ./iter_DiceBCE.model/assets\n",
      "65/65 [==============================] - 21s 329ms/step - loss: 0.0941 - recall_12: 0.9275 - precision_12: 0.9158 - mean_io_u_12: 0.6972 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1069 - val_recall_12: 0.9151 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7009 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 71/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0940 - recall_12: 0.9274 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 71: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0941 - recall_12: 0.9273 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9148 - val_precision_12: 0.9055 - val_mean_io_u_12: 0.7010 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 72/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0939 - recall_12: 0.9278 - precision_12: 0.9159 - mean_io_u_12: 0.6976 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 72: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0939 - recall_12: 0.9278 - precision_12: 0.9158 - mean_io_u_12: 0.6975 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9145 - val_precision_12: 0.9058 - val_mean_io_u_12: 0.7008 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 73/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0941 - recall_12: 0.9275 - precision_12: 0.9158 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 73: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9158 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9152 - val_precision_12: 0.9052 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 74/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 74: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9159 - mean_io_u_12: 0.6974 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9148 - val_precision_12: 0.9055 - val_mean_io_u_12: 0.7012 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 75/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9160 - mean_io_u_12: 0.6976 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 75: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.0940 - recall_12: 0.9275 - precision_12: 0.9160 - mean_io_u_12: 0.6976 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1071 - val_recall_12: 0.9155 - val_precision_12: 0.9050 - val_mean_io_u_12: 0.7013 - val_accuracy: 0.9967 - val_auc: 0.9852 - lr: 1.0000e-05\n",
      "Epoch 76/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0942 - recall_12: 0.9273 - precision_12: 0.9158 - mean_io_u_12: 0.6971 - accuracy: 0.9972 - auc: 0.9890\n",
      "Epoch 76: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0942 - recall_12: 0.9273 - precision_12: 0.9158 - mean_io_u_12: 0.6971 - accuracy: 0.9972 - auc: 0.9890 - val_loss: 0.1071 - val_recall_12: 0.9149 - val_precision_12: 0.9053 - val_mean_io_u_12: 0.7006 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 77/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0939 - recall_12: 0.9277 - precision_12: 0.9159 - mean_io_u_12: 0.6971 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 77: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 182ms/step - loss: 0.0940 - recall_12: 0.9277 - precision_12: 0.9158 - mean_io_u_12: 0.6970 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1072 - val_recall_12: 0.9146 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7006 - val_accuracy: 0.9967 - val_auc: 0.9850 - lr: 1.0000e-05\n",
      "Epoch 78/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0940 - recall_12: 0.9274 - precision_12: 0.9160 - mean_io_u_12: 0.6969 - accuracy: 0.9972 - auc: 0.9890\n",
      "Epoch 78: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0940 - recall_12: 0.9274 - precision_12: 0.9160 - mean_io_u_12: 0.6969 - accuracy: 0.9972 - auc: 0.9890 - val_loss: 0.1070 - val_recall_12: 0.9149 - val_precision_12: 0.9057 - val_mean_io_u_12: 0.7005 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 79/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.0939 - recall_12: 0.9274 - precision_12: 0.9163 - mean_io_u_12: 0.6968 - accuracy: 0.9972 - auc: 0.9890\n",
      "Epoch 79: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 179ms/step - loss: 0.0938 - recall_12: 0.9274 - precision_12: 0.9163 - mean_io_u_12: 0.6968 - accuracy: 0.9972 - auc: 0.9890 - val_loss: 0.1070 - val_recall_12: 0.9148 - val_precision_12: 0.9058 - val_mean_io_u_12: 0.7001 - val_accuracy: 0.9967 - val_auc: 0.9850 - lr: 1.0000e-05\n",
      "Epoch 80/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.0937 - recall_12: 0.9277 - precision_12: 0.9162 - mean_io_u_12: 0.6969 - accuracy: 0.9972 - auc: 0.9891\n",
      "Epoch 80: val_loss did not improve from 0.10693\n",
      "65/65 [==============================] - 12s 181ms/step - loss: 0.0937 - recall_12: 0.9277 - precision_12: 0.9162 - mean_io_u_12: 0.6969 - accuracy: 0.9972 - auc: 0.9891 - val_loss: 0.1070 - val_recall_12: 0.9149 - val_precision_12: 0.9056 - val_mean_io_u_12: 0.7004 - val_accuracy: 0.9967 - val_auc: 0.9851 - lr: 1.0000e-05\n",
      "Epoch 80: early stopping\n",
      "\n",
      "\n",
      " f    <function DiceBCE.<locals>.f at 0x7f046431a670>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Epoch 1/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.9258 - recall_13: 0.9803 - precision_13: 0.0945 - mean_io_u_13: 0.5422 - accuracy: 0.8303 - auc: 0.9353\n",
      "Epoch 1: val_loss improved from inf to 0.92190, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 25s 342ms/step - loss: 0.9257 - recall_13: 0.9803 - precision_13: 0.0946 - mean_io_u_13: 0.5424 - accuracy: 0.8305 - auc: 0.9354 - val_loss: 0.9219 - val_recall_13: 0.3589 - val_precision_13: 0.1288 - val_mean_io_u_13: 0.4910 - val_accuracy: 0.9447 - val_auc: 0.9157 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.8458 - recall_13: 0.9896 - precision_13: 0.2257 - mean_io_u_13: 0.5971 - accuracy: 0.9386 - auc: 0.9649\n",
      "Epoch 2: val_loss improved from 0.92190 to 0.75630, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 19s 292ms/step - loss: 0.8455 - recall_13: 0.9896 - precision_13: 0.2259 - mean_io_u_13: 0.5972 - accuracy: 0.9387 - auc: 0.9649 - val_loss: 0.7563 - val_recall_13: 0.5574 - val_precision_13: 0.3054 - val_mean_io_u_13: 0.5329 - val_accuracy: 0.9692 - val_auc: 0.8004 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.6604 - recall_13: 0.9571 - precision_13: 0.4511 - mean_io_u_13: 0.7201 - accuracy: 0.9782 - auc: 0.9615\n",
      "Epoch 3: val_loss did not improve from 0.75630\n",
      "65/65 [==============================] - 12s 184ms/step - loss: 0.6604 - recall_13: 0.9571 - precision_13: 0.4511 - mean_io_u_13: 0.7201 - accuracy: 0.9782 - auc: 0.9615 - val_loss: 0.9952 - val_recall_13: 0.0063 - val_precision_13: 0.0434 - val_mean_io_u_13: 0.4918 - val_accuracy: 0.9796 - val_auc: 0.4300 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.4350 - recall_13: 0.8910 - precision_13: 0.6835 - mean_io_u_13: 0.8141 - accuracy: 0.9906 - auc: 0.9442\n",
      "Epoch 4: val_loss improved from 0.75630 to 0.69372, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 315ms/step - loss: 0.4346 - recall_13: 0.8910 - precision_13: 0.6838 - mean_io_u_13: 0.8142 - accuracy: 0.9906 - auc: 0.9443 - val_loss: 0.6937 - val_recall_13: 0.3551 - val_precision_13: 0.6879 - val_mean_io_u_13: 0.6232 - val_accuracy: 0.9855 - val_auc: 0.6942 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3547 - recall_13: 0.8603 - precision_13: 0.7529 - mean_io_u_13: 0.8312 - accuracy: 0.9924 - auc: 0.9343\n",
      "Epoch 5: val_loss improved from 0.69372 to 0.41136, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 310ms/step - loss: 0.3548 - recall_13: 0.8602 - precision_13: 0.7529 - mean_io_u_13: 0.8311 - accuracy: 0.9924 - auc: 0.9342 - val_loss: 0.4114 - val_recall_13: 0.7054 - val_precision_13: 0.7805 - val_mean_io_u_13: 0.7673 - val_accuracy: 0.9911 - val_auc: 0.8618 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3298 - recall_13: 0.8538 - precision_13: 0.7741 - mean_io_u_13: 0.8369 - accuracy: 0.9929 - auc: 0.9303\n",
      "Epoch 6: val_loss improved from 0.41136 to 0.32578, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 306ms/step - loss: 0.3298 - recall_13: 0.8538 - precision_13: 0.7741 - mean_io_u_13: 0.8369 - accuracy: 0.9929 - auc: 0.9303 - val_loss: 0.3258 - val_recall_13: 0.8029 - val_precision_13: 0.8079 - val_mean_io_u_13: 0.8241 - val_accuracy: 0.9930 - val_auc: 0.9068 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3221 - recall_13: 0.8503 - precision_13: 0.7802 - mean_io_u_13: 0.8381 - accuracy: 0.9930 - auc: 0.9285\n",
      "Epoch 7: val_loss did not improve from 0.32578\n",
      "65/65 [==============================] - 14s 212ms/step - loss: 0.3221 - recall_13: 0.8503 - precision_13: 0.7802 - mean_io_u_13: 0.8381 - accuracy: 0.9930 - auc: 0.9285 - val_loss: 0.3340 - val_recall_13: 0.8052 - val_precision_13: 0.7938 - val_mean_io_u_13: 0.8225 - val_accuracy: 0.9927 - val_auc: 0.9066 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3141 - recall_13: 0.8534 - precision_13: 0.7849 - mean_io_u_13: 0.8410 - accuracy: 0.9931 - auc: 0.9296\n",
      "Epoch 8: val_loss improved from 0.32578 to 0.32290, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 345ms/step - loss: 0.3138 - recall_13: 0.8536 - precision_13: 0.7851 - mean_io_u_13: 0.8411 - accuracy: 0.9932 - auc: 0.9297 - val_loss: 0.3229 - val_recall_13: 0.7927 - val_precision_13: 0.8229 - val_mean_io_u_13: 0.8283 - val_accuracy: 0.9932 - val_auc: 0.9002 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3086 - recall_13: 0.8495 - precision_13: 0.7934 - mean_io_u_13: 0.8431 - accuracy: 0.9933 - auc: 0.9274\n",
      "Epoch 9: val_loss improved from 0.32290 to 0.32251, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 324ms/step - loss: 0.3086 - recall_13: 0.8495 - precision_13: 0.7934 - mean_io_u_13: 0.8431 - accuracy: 0.9933 - auc: 0.9274 - val_loss: 0.3225 - val_recall_13: 0.7783 - val_precision_13: 0.8396 - val_mean_io_u_13: 0.8268 - val_accuracy: 0.9933 - val_auc: 0.8934 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.3054 - recall_13: 0.8519 - precision_13: 0.7942 - mean_io_u_13: 0.8441 - accuracy: 0.9934 - auc: 0.9285\n",
      "Epoch 10: val_loss improved from 0.32251 to 0.29298, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 343ms/step - loss: 0.3054 - recall_13: 0.8519 - precision_13: 0.7942 - mean_io_u_13: 0.8441 - accuracy: 0.9934 - auc: 0.9285 - val_loss: 0.2930 - val_recall_13: 0.8526 - val_precision_13: 0.8056 - val_mean_io_u_13: 0.8487 - val_accuracy: 0.9936 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.3008 - recall_13: 0.8517 - precision_13: 0.7996 - mean_io_u_13: 0.8461 - accuracy: 0.9935 - auc: 0.9285\n",
      "Epoch 11: val_loss improved from 0.29298 to 0.29145, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 318ms/step - loss: 0.3008 - recall_13: 0.8517 - precision_13: 0.7996 - mean_io_u_13: 0.8461 - accuracy: 0.9935 - auc: 0.9285 - val_loss: 0.2914 - val_recall_13: 0.8244 - val_precision_13: 0.8347 - val_mean_io_u_13: 0.8465 - val_accuracy: 0.9939 - val_auc: 0.9162 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2981 - recall_13: 0.8518 - precision_13: 0.8023 - mean_io_u_13: 0.8472 - accuracy: 0.9935 - auc: 0.9285\n",
      "Epoch 12: val_loss did not improve from 0.29145\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2981 - recall_13: 0.8518 - precision_13: 0.8023 - mean_io_u_13: 0.8472 - accuracy: 0.9935 - auc: 0.9285 - val_loss: 0.2991 - val_recall_13: 0.8350 - val_precision_13: 0.8138 - val_mean_io_u_13: 0.8443 - val_accuracy: 0.9936 - val_auc: 0.9200 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2979 - recall_13: 0.8519 - precision_13: 0.8020 - mean_io_u_13: 0.8472 - accuracy: 0.9935 - auc: 0.9285\n",
      "Epoch 13: val_loss improved from 0.29145 to 0.28718, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 23s 349ms/step - loss: 0.2979 - recall_13: 0.8519 - precision_13: 0.8020 - mean_io_u_13: 0.8472 - accuracy: 0.9935 - auc: 0.9285 - val_loss: 0.2872 - val_recall_13: 0.8548 - val_precision_13: 0.8111 - val_mean_io_u_13: 0.8520 - val_accuracy: 0.9938 - val_auc: 0.9299 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2950 - recall_13: 0.8523 - precision_13: 0.8052 - mean_io_u_13: 0.8483 - accuracy: 0.9936 - auc: 0.9287\n",
      "Epoch 14: val_loss improved from 0.28718 to 0.28568, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 331ms/step - loss: 0.2950 - recall_13: 0.8523 - precision_13: 0.8052 - mean_io_u_13: 0.8483 - accuracy: 0.9936 - auc: 0.9287 - val_loss: 0.2857 - val_recall_13: 0.8424 - val_precision_13: 0.8246 - val_mean_io_u_13: 0.8514 - val_accuracy: 0.9939 - val_auc: 0.9238 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2922 - recall_13: 0.8532 - precision_13: 0.8078 - mean_io_u_13: 0.8499 - accuracy: 0.9937 - auc: 0.9289\n",
      "Epoch 15: val_loss did not improve from 0.28568\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2922 - recall_13: 0.8532 - precision_13: 0.8078 - mean_io_u_13: 0.8499 - accuracy: 0.9937 - auc: 0.9289 - val_loss: 0.2896 - val_recall_13: 0.8591 - val_precision_13: 0.8042 - val_mean_io_u_13: 0.8513 - val_accuracy: 0.9937 - val_auc: 0.9313 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2912 - recall_13: 0.8547 - precision_13: 0.8074 - mean_io_u_13: 0.8501 - accuracy: 0.9937 - auc: 0.9298\n",
      "Epoch 16: val_loss improved from 0.28568 to 0.28415, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 343ms/step - loss: 0.2912 - recall_13: 0.8547 - precision_13: 0.8074 - mean_io_u_13: 0.8501 - accuracy: 0.9937 - auc: 0.9298 - val_loss: 0.2842 - val_recall_13: 0.8479 - val_precision_13: 0.8215 - val_mean_io_u_13: 0.8513 - val_accuracy: 0.9939 - val_auc: 0.9264 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2893 - recall_13: 0.8542 - precision_13: 0.8101 - mean_io_u_13: 0.8509 - accuracy: 0.9938 - auc: 0.9296\n",
      "Epoch 17: val_loss did not improve from 0.28415\n",
      "65/65 [==============================] - 14s 213ms/step - loss: 0.2893 - recall_13: 0.8542 - precision_13: 0.8101 - mean_io_u_13: 0.8509 - accuracy: 0.9938 - auc: 0.9296 - val_loss: 0.2928 - val_recall_13: 0.8511 - val_precision_13: 0.8075 - val_mean_io_u_13: 0.8484 - val_accuracy: 0.9937 - val_auc: 0.9280 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2881 - recall_13: 0.8502 - precision_13: 0.8153 - mean_io_u_13: 0.8513 - accuracy: 0.9938 - auc: 0.9278\n",
      "Epoch 18: val_loss improved from 0.28415 to 0.27921, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.2881 - recall_13: 0.8502 - precision_13: 0.8153 - mean_io_u_13: 0.8513 - accuracy: 0.9938 - auc: 0.9278 - val_loss: 0.2792 - val_recall_13: 0.8392 - val_precision_13: 0.8368 - val_mean_io_u_13: 0.8539 - val_accuracy: 0.9941 - val_auc: 0.9225 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2848 - recall_13: 0.8555 - precision_13: 0.8145 - mean_io_u_13: 0.8532 - accuracy: 0.9939 - auc: 0.9302\n",
      "Epoch 19: val_loss did not improve from 0.27921\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2848 - recall_13: 0.8555 - precision_13: 0.8145 - mean_io_u_13: 0.8532 - accuracy: 0.9939 - auc: 0.9302 - val_loss: 0.2938 - val_recall_13: 0.8355 - val_precision_13: 0.8204 - val_mean_io_u_13: 0.8471 - val_accuracy: 0.9937 - val_auc: 0.9208 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2831 - recall_13: 0.8572 - precision_13: 0.8150 - mean_io_u_13: 0.8540 - accuracy: 0.9939 - auc: 0.9310\n",
      "Epoch 20: val_loss did not improve from 0.27921\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2831 - recall_13: 0.8572 - precision_13: 0.8150 - mean_io_u_13: 0.8540 - accuracy: 0.9939 - auc: 0.9310 - val_loss: 0.2825 - val_recall_13: 0.8480 - val_precision_13: 0.8235 - val_mean_io_u_13: 0.8536 - val_accuracy: 0.9940 - val_auc: 0.9262 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2807 - recall_13: 0.8586 - precision_13: 0.8168 - mean_io_u_13: 0.8555 - accuracy: 0.9940 - auc: 0.9315\n",
      "Epoch 21: val_loss did not improve from 0.27921\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2807 - recall_13: 0.8586 - precision_13: 0.8168 - mean_io_u_13: 0.8555 - accuracy: 0.9940 - auc: 0.9315 - val_loss: 0.2876 - val_recall_13: 0.8721 - val_precision_13: 0.7957 - val_mean_io_u_13: 0.8533 - val_accuracy: 0.9937 - val_auc: 0.9369 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2757 - recall_13: 0.8606 - precision_13: 0.8214 - mean_io_u_13: 0.8576 - accuracy: 0.9941 - auc: 0.9328\n",
      "Epoch 22: val_loss improved from 0.27921 to 0.27140, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 336ms/step - loss: 0.2756 - recall_13: 0.8606 - precision_13: 0.8214 - mean_io_u_13: 0.8576 - accuracy: 0.9941 - auc: 0.9329 - val_loss: 0.2714 - val_recall_13: 0.8810 - val_precision_13: 0.8083 - val_mean_io_u_13: 0.8613 - val_accuracy: 0.9941 - val_auc: 0.9419 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2736 - recall_13: 0.8616 - precision_13: 0.8231 - mean_io_u_13: 0.8587 - accuracy: 0.9942 - auc: 0.9332\n",
      "Epoch 23: val_loss did not improve from 0.27140\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.2735 - recall_13: 0.8616 - precision_13: 0.8232 - mean_io_u_13: 0.8587 - accuracy: 0.9942 - auc: 0.9332 - val_loss: 0.2811 - val_recall_13: 0.8358 - val_precision_13: 0.8389 - val_mean_io_u_13: 0.8531 - val_accuracy: 0.9941 - val_auc: 0.9216 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2702 - recall_13: 0.8622 - precision_13: 0.8269 - mean_io_u_13: 0.8606 - accuracy: 0.9943 - auc: 0.9334\n",
      "Epoch 24: val_loss did not improve from 0.27140\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.2701 - recall_13: 0.8623 - precision_13: 0.8269 - mean_io_u_13: 0.8607 - accuracy: 0.9943 - auc: 0.9335 - val_loss: 0.2748 - val_recall_13: 0.8530 - val_precision_13: 0.8292 - val_mean_io_u_13: 0.8578 - val_accuracy: 0.9942 - val_auc: 0.9294 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2660 - recall_13: 0.8658 - precision_13: 0.8289 - mean_io_u_13: 0.8626 - accuracy: 0.9944 - auc: 0.9353\n",
      "Epoch 25: val_loss improved from 0.27140 to 0.26176, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 330ms/step - loss: 0.2660 - recall_13: 0.8658 - precision_13: 0.8289 - mean_io_u_13: 0.8626 - accuracy: 0.9944 - auc: 0.9353 - val_loss: 0.2618 - val_recall_13: 0.8663 - val_precision_13: 0.8334 - val_mean_io_u_13: 0.8647 - val_accuracy: 0.9945 - val_auc: 0.9355 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2631 - recall_13: 0.8676 - precision_13: 0.8309 - mean_io_u_13: 0.8639 - accuracy: 0.9944 - auc: 0.9367\n",
      "Epoch 26: val_loss did not improve from 0.26176\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2632 - recall_13: 0.8675 - precision_13: 0.8309 - mean_io_u_13: 0.8639 - accuracy: 0.9944 - auc: 0.9366 - val_loss: 0.2671 - val_recall_13: 0.8670 - val_precision_13: 0.8258 - val_mean_io_u_13: 0.8623 - val_accuracy: 0.9943 - val_auc: 0.9354 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2566 - recall_13: 0.8724 - precision_13: 0.8348 - mean_io_u_13: 0.8675 - accuracy: 0.9946 - auc: 0.9386\n",
      "Epoch 27: val_loss improved from 0.26176 to 0.25794, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 314ms/step - loss: 0.2566 - recall_13: 0.8724 - precision_13: 0.8348 - mean_io_u_13: 0.8675 - accuracy: 0.9946 - auc: 0.9386 - val_loss: 0.2579 - val_recall_13: 0.8552 - val_precision_13: 0.8488 - val_mean_io_u_13: 0.8645 - val_accuracy: 0.9946 - val_auc: 0.9305 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2525 - recall_13: 0.8737 - precision_13: 0.8387 - mean_io_u_13: 0.8692 - accuracy: 0.9947 - auc: 0.9397\n",
      "Epoch 28: val_loss improved from 0.25794 to 0.25427, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 23s 352ms/step - loss: 0.2525 - recall_13: 0.8737 - precision_13: 0.8387 - mean_io_u_13: 0.8692 - accuracy: 0.9947 - auc: 0.9397 - val_loss: 0.2543 - val_recall_13: 0.8731 - val_precision_13: 0.8366 - val_mean_io_u_13: 0.8679 - val_accuracy: 0.9946 - val_auc: 0.9389 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2507 - recall_13: 0.8745 - precision_13: 0.8402 - mean_io_u_13: 0.8703 - accuracy: 0.9947 - auc: 0.9399\n",
      "Epoch 29: val_loss improved from 0.25427 to 0.25212, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 323ms/step - loss: 0.2506 - recall_13: 0.8745 - precision_13: 0.8402 - mean_io_u_13: 0.8704 - accuracy: 0.9947 - auc: 0.9399 - val_loss: 0.2521 - val_recall_13: 0.8687 - val_precision_13: 0.8435 - val_mean_io_u_13: 0.8683 - val_accuracy: 0.9947 - val_auc: 0.9373 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2494 - recall_13: 0.8761 - precision_13: 0.8402 - mean_io_u_13: 0.8710 - accuracy: 0.9948 - auc: 0.9406\n",
      "Epoch 30: val_loss did not improve from 0.25212\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2493 - recall_13: 0.8762 - precision_13: 0.8402 - mean_io_u_13: 0.8710 - accuracy: 0.9948 - auc: 0.9407 - val_loss: 0.3084 - val_recall_13: 0.8272 - val_precision_13: 0.8086 - val_mean_io_u_13: 0.8391 - val_accuracy: 0.9934 - val_auc: 0.9173 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2484 - recall_13: 0.8769 - precision_13: 0.8407 - mean_io_u_13: 0.8715 - accuracy: 0.9948 - auc: 0.9411\n",
      "Epoch 31: val_loss did not improve from 0.25212\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2484 - recall_13: 0.8769 - precision_13: 0.8407 - mean_io_u_13: 0.8716 - accuracy: 0.9948 - auc: 0.9412 - val_loss: 0.2547 - val_recall_13: 0.8658 - val_precision_13: 0.8431 - val_mean_io_u_13: 0.8683 - val_accuracy: 0.9947 - val_auc: 0.9355 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2424 - recall_13: 0.8807 - precision_13: 0.8447 - mean_io_u_13: 0.8744 - accuracy: 0.9949 - auc: 0.9432\n",
      "Epoch 32: val_loss did not improve from 0.25212\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2424 - recall_13: 0.8807 - precision_13: 0.8447 - mean_io_u_13: 0.8744 - accuracy: 0.9949 - auc: 0.9432 - val_loss: 0.2646 - val_recall_13: 0.8498 - val_precision_13: 0.8456 - val_mean_io_u_13: 0.8605 - val_accuracy: 0.9945 - val_auc: 0.9283 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2394 - recall_13: 0.8820 - precision_13: 0.8472 - mean_io_u_13: 0.8761 - accuracy: 0.9950 - auc: 0.9438\n",
      "Epoch 33: val_loss improved from 0.25212 to 0.24497, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 23s 355ms/step - loss: 0.2394 - recall_13: 0.8820 - precision_13: 0.8472 - mean_io_u_13: 0.8760 - accuracy: 0.9950 - auc: 0.9437 - val_loss: 0.2450 - val_recall_13: 0.8651 - val_precision_13: 0.8559 - val_mean_io_u_13: 0.8715 - val_accuracy: 0.9949 - val_auc: 0.9357 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2364 - recall_13: 0.8823 - precision_13: 0.8506 - mean_io_u_13: 0.8771 - accuracy: 0.9951 - auc: 0.9442\n",
      "Epoch 34: val_loss improved from 0.24497 to 0.23955, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 20s 317ms/step - loss: 0.2365 - recall_13: 0.8823 - precision_13: 0.8505 - mean_io_u_13: 0.8770 - accuracy: 0.9951 - auc: 0.9442 - val_loss: 0.2395 - val_recall_13: 0.8849 - val_precision_13: 0.8443 - val_mean_io_u_13: 0.8765 - val_accuracy: 0.9950 - val_auc: 0.9451 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2340 - recall_13: 0.8845 - precision_13: 0.8516 - mean_io_u_13: 0.8786 - accuracy: 0.9951 - auc: 0.9452\n",
      "Epoch 35: val_loss did not improve from 0.23955\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2340 - recall_13: 0.8845 - precision_13: 0.8516 - mean_io_u_13: 0.8786 - accuracy: 0.9951 - auc: 0.9452 - val_loss: 0.2605 - val_recall_13: 0.8500 - val_precision_13: 0.8506 - val_mean_io_u_13: 0.8628 - val_accuracy: 0.9946 - val_auc: 0.9282 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2310 - recall_13: 0.8855 - precision_13: 0.8544 - mean_io_u_13: 0.8799 - accuracy: 0.9952 - auc: 0.9456\n",
      "Epoch 36: val_loss did not improve from 0.23955\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2310 - recall_13: 0.8855 - precision_13: 0.8544 - mean_io_u_13: 0.8799 - accuracy: 0.9952 - auc: 0.9456 - val_loss: 0.2981 - val_recall_13: 0.8027 - val_precision_13: 0.8491 - val_mean_io_u_13: 0.8456 - val_accuracy: 0.9939 - val_auc: 0.9056 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2263 - recall_13: 0.8873 - precision_13: 0.8583 - mean_io_u_13: 0.8823 - accuracy: 0.9953 - auc: 0.9465\n",
      "Epoch 37: val_loss improved from 0.23955 to 0.22380, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 333ms/step - loss: 0.2263 - recall_13: 0.8873 - precision_13: 0.8583 - mean_io_u_13: 0.8823 - accuracy: 0.9953 - auc: 0.9465 - val_loss: 0.2238 - val_recall_13: 0.8839 - val_precision_13: 0.8644 - val_mean_io_u_13: 0.8829 - val_accuracy: 0.9954 - val_auc: 0.9453 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2269 - recall_13: 0.8862 - precision_13: 0.8588 - mean_io_u_13: 0.8817 - accuracy: 0.9953 - auc: 0.9461\n",
      "Epoch 38: val_loss did not improve from 0.22380\n",
      "65/65 [==============================] - 13s 208ms/step - loss: 0.2269 - recall_13: 0.8862 - precision_13: 0.8588 - mean_io_u_13: 0.8817 - accuracy: 0.9953 - auc: 0.9461 - val_loss: 0.2552 - val_recall_13: 0.8663 - val_precision_13: 0.8417 - val_mean_io_u_13: 0.8744 - val_accuracy: 0.9947 - val_auc: 0.9363 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2228 - recall_13: 0.8910 - precision_13: 0.8592 - mean_io_u_13: 0.8841 - accuracy: 0.9954 - auc: 0.9485\n",
      "Epoch 39: val_loss did not improve from 0.22380\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.2228 - recall_13: 0.8910 - precision_13: 0.8592 - mean_io_u_13: 0.8841 - accuracy: 0.9954 - auc: 0.9486 - val_loss: 0.2426 - val_recall_13: 0.8730 - val_precision_13: 0.8513 - val_mean_io_u_13: 0.8742 - val_accuracy: 0.9950 - val_auc: 0.9389 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2218 - recall_13: 0.8877 - precision_13: 0.8634 - mean_io_u_13: 0.8841 - accuracy: 0.9954 - auc: 0.9470\n",
      "Epoch 40: val_loss did not improve from 0.22380\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2219 - recall_13: 0.8877 - precision_13: 0.8634 - mean_io_u_13: 0.8841 - accuracy: 0.9954 - auc: 0.9470 - val_loss: 0.2495 - val_recall_13: 0.8476 - val_precision_13: 0.8676 - val_mean_io_u_13: 0.8690 - val_accuracy: 0.9949 - val_auc: 0.9273 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2173 - recall_13: 0.8935 - precision_13: 0.8636 - mean_io_u_13: 0.8867 - accuracy: 0.9955 - auc: 0.9498\n",
      "Epoch 41: val_loss did not improve from 0.22380\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2174 - recall_13: 0.8934 - precision_13: 0.8636 - mean_io_u_13: 0.8867 - accuracy: 0.9955 - auc: 0.9498 - val_loss: 0.2301 - val_recall_13: 0.8731 - val_precision_13: 0.8669 - val_mean_io_u_13: 0.8794 - val_accuracy: 0.9953 - val_auc: 0.9395 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2171 - recall_13: 0.8926 - precision_13: 0.8647 - mean_io_u_13: 0.8871 - accuracy: 0.9955 - auc: 0.9491\n",
      "Epoch 42: val_loss improved from 0.22380 to 0.22022, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 319ms/step - loss: 0.2171 - recall_13: 0.8926 - precision_13: 0.8646 - mean_io_u_13: 0.8870 - accuracy: 0.9955 - auc: 0.9491 - val_loss: 0.2202 - val_recall_13: 0.8908 - val_precision_13: 0.8625 - val_mean_io_u_13: 0.8860 - val_accuracy: 0.9955 - val_auc: 0.9479 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2146 - recall_13: 0.8932 - precision_13: 0.8671 - mean_io_u_13: 0.8883 - accuracy: 0.9956 - auc: 0.9494\n",
      "Epoch 43: val_loss did not improve from 0.22022\n",
      "65/65 [==============================] - 13s 204ms/step - loss: 0.2147 - recall_13: 0.8931 - precision_13: 0.8671 - mean_io_u_13: 0.8882 - accuracy: 0.9956 - auc: 0.9494 - val_loss: 0.2250 - val_recall_13: 0.8831 - val_precision_13: 0.8638 - val_mean_io_u_13: 0.8831 - val_accuracy: 0.9954 - val_auc: 0.9441 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2139 - recall_13: 0.8949 - precision_13: 0.8663 - mean_io_u_13: 0.8886 - accuracy: 0.9956 - auc: 0.9503\n",
      "Epoch 44: val_loss did not improve from 0.22022\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2139 - recall_13: 0.8949 - precision_13: 0.8663 - mean_io_u_13: 0.8886 - accuracy: 0.9956 - auc: 0.9504 - val_loss: 0.2285 - val_recall_13: 0.8806 - val_precision_13: 0.8621 - val_mean_io_u_13: 0.8809 - val_accuracy: 0.9953 - val_auc: 0.9433 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2131 - recall_13: 0.8948 - precision_13: 0.8674 - mean_io_u_13: 0.8890 - accuracy: 0.9956 - auc: 0.9503\n",
      "Epoch 45: val_loss did not improve from 0.22022\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2132 - recall_13: 0.8948 - precision_13: 0.8674 - mean_io_u_13: 0.8889 - accuracy: 0.9956 - auc: 0.9503 - val_loss: 0.2785 - val_recall_13: 0.8266 - val_precision_13: 0.8508 - val_mean_io_u_13: 0.8539 - val_accuracy: 0.9943 - val_auc: 0.9171 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2113 - recall_13: 0.8953 - precision_13: 0.8691 - mean_io_u_13: 0.8897 - accuracy: 0.9957 - auc: 0.9506\n",
      "Epoch 46: val_loss did not improve from 0.22022\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.2113 - recall_13: 0.8953 - precision_13: 0.8691 - mean_io_u_13: 0.8897 - accuracy: 0.9957 - auc: 0.9506 - val_loss: 0.2438 - val_recall_13: 0.8683 - val_precision_13: 0.8543 - val_mean_io_u_13: 0.8729 - val_accuracy: 0.9950 - val_auc: 0.9371 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2081 - recall_13: 0.8970 - precision_13: 0.8713 - mean_io_u_13: 0.8913 - accuracy: 0.9958 - auc: 0.9515\n",
      "Epoch 47: val_loss improved from 0.22022 to 0.21295, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 21s 329ms/step - loss: 0.2081 - recall_13: 0.8970 - precision_13: 0.8713 - mean_io_u_13: 0.8913 - accuracy: 0.9958 - auc: 0.9515 - val_loss: 0.2129 - val_recall_13: 0.8910 - val_precision_13: 0.8712 - val_mean_io_u_13: 0.8889 - val_accuracy: 0.9957 - val_auc: 0.9483 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.2089 - recall_13: 0.8952 - precision_13: 0.8721 - mean_io_u_13: 0.8908 - accuracy: 0.9957 - auc: 0.9505\n",
      "Epoch 48: val_loss did not improve from 0.21295\n",
      "65/65 [==============================] - 14s 209ms/step - loss: 0.2089 - recall_13: 0.8952 - precision_13: 0.8721 - mean_io_u_13: 0.8908 - accuracy: 0.9957 - auc: 0.9505 - val_loss: 0.2469 - val_recall_13: 0.8876 - val_precision_13: 0.8332 - val_mean_io_u_13: 0.8851 - val_accuracy: 0.9948 - val_auc: 0.9461 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2056 - recall_13: 0.8980 - precision_13: 0.8735 - mean_io_u_13: 0.8928 - accuracy: 0.9958 - auc: 0.9520\n",
      "Epoch 49: val_loss did not improve from 0.21295\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.2056 - recall_13: 0.8980 - precision_13: 0.8734 - mean_io_u_13: 0.8927 - accuracy: 0.9958 - auc: 0.9519 - val_loss: 0.2217 - val_recall_13: 0.8744 - val_precision_13: 0.8763 - val_mean_io_u_13: 0.8828 - val_accuracy: 0.9955 - val_auc: 0.9404 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2032 - recall_13: 0.8992 - precision_13: 0.8752 - mean_io_u_13: 0.8938 - accuracy: 0.9959 - auc: 0.9527\n",
      "Epoch 50: val_loss did not improve from 0.21295\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2033 - recall_13: 0.8992 - precision_13: 0.8751 - mean_io_u_13: 0.8938 - accuracy: 0.9959 - auc: 0.9526 - val_loss: 0.2162 - val_recall_13: 0.8966 - val_precision_13: 0.8617 - val_mean_io_u_13: 0.8884 - val_accuracy: 0.9955 - val_auc: 0.9511 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2055 - recall_13: 0.8963 - precision_13: 0.8752 - mean_io_u_13: 0.8926 - accuracy: 0.9958 - auc: 0.9511\n",
      "Epoch 51: val_loss did not improve from 0.21295\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2055 - recall_13: 0.8963 - precision_13: 0.8752 - mean_io_u_13: 0.8926 - accuracy: 0.9958 - auc: 0.9511 - val_loss: 0.4298 - val_recall_13: 0.6612 - val_precision_13: 0.8100 - val_mean_io_u_13: 0.7837 - val_accuracy: 0.9911 - val_auc: 0.8337 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.2014 - recall_13: 0.8998 - precision_13: 0.8768 - mean_io_u_13: 0.8946 - accuracy: 0.9959 - auc: 0.9530\n",
      "Epoch 52: val_loss did not improve from 0.21295\n",
      "\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.2014 - recall_13: 0.8998 - precision_13: 0.8768 - mean_io_u_13: 0.8946 - accuracy: 0.9959 - auc: 0.9530 - val_loss: 0.2150 - val_recall_13: 0.8846 - val_precision_13: 0.8748 - val_mean_io_u_13: 0.8874 - val_accuracy: 0.9956 - val_auc: 0.9452 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1951 - recall_13: 0.9050 - precision_13: 0.8794 - mean_io_u_13: 0.8980 - accuracy: 0.9961 - auc: 0.9554\n",
      "Epoch 53: val_loss did not improve from 0.21295\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1951 - recall_13: 0.9050 - precision_13: 0.8794 - mean_io_u_13: 0.8980 - accuracy: 0.9961 - auc: 0.9554 - val_loss: 0.2462 - val_recall_13: 0.8457 - val_precision_13: 0.8748 - val_mean_io_u_13: 0.8712 - val_accuracy: 0.9950 - val_auc: 0.9264 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1911 - recall_13: 0.9051 - precision_13: 0.8842 - mean_io_u_13: 0.8999 - accuracy: 0.9962 - auc: 0.9556\n",
      "Epoch 54: val_loss improved from 0.21295 to 0.19209, saving model to ./iter_IoULoss.model\n",
      "INFO:tensorflow:Assets written to: ./iter_IoULoss.model/assets\n",
      "65/65 [==============================] - 22s 337ms/step - loss: 0.1911 - recall_13: 0.9051 - precision_13: 0.8842 - mean_io_u_13: 0.8999 - accuracy: 0.9962 - auc: 0.9556 - val_loss: 0.1921 - val_recall_13: 0.9001 - val_precision_13: 0.8876 - val_mean_io_u_13: 0.8992 - val_accuracy: 0.9961 - val_auc: 0.9533 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1894 - recall_13: 0.9057 - precision_13: 0.8855 - mean_io_u_13: 0.9006 - accuracy: 0.9962 - auc: 0.9559\n",
      "Epoch 55: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1895 - recall_13: 0.9057 - precision_13: 0.8855 - mean_io_u_13: 0.9005 - accuracy: 0.9962 - auc: 0.9559 - val_loss: 0.2117 - val_recall_13: 0.8805 - val_precision_13: 0.8833 - val_mean_io_u_13: 0.8885 - val_accuracy: 0.9957 - val_auc: 0.9436 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1890 - recall_13: 0.9064 - precision_13: 0.8854 - mean_io_u_13: 0.9010 - accuracy: 0.9962 - auc: 0.9563\n",
      "Epoch 56: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1890 - recall_13: 0.9064 - precision_13: 0.8854 - mean_io_u_13: 0.9010 - accuracy: 0.9962 - auc: 0.9563 - val_loss: 0.3192 - val_recall_13: 0.7627 - val_precision_13: 0.8640 - val_mean_io_u_13: 0.8330 - val_accuracy: 0.9936 - val_auc: 0.8850 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1885 - recall_13: 0.9051 - precision_13: 0.8872 - mean_io_u_13: 0.9010 - accuracy: 0.9962 - auc: 0.9557\n",
      "Epoch 57: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1885 - recall_13: 0.9051 - precision_13: 0.8872 - mean_io_u_13: 0.9010 - accuracy: 0.9962 - auc: 0.9557 - val_loss: 0.2208 - val_recall_13: 0.8728 - val_precision_13: 0.8792 - val_mean_io_u_13: 0.8841 - val_accuracy: 0.9955 - val_auc: 0.9397 - lr: 1.0000e-04\n",
      "Epoch 58/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1878 - recall_13: 0.9069 - precision_13: 0.8863 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9565\n",
      "Epoch 58: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 14s 208ms/step - loss: 0.1878 - recall_13: 0.9069 - precision_13: 0.8863 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9565 - val_loss: 0.3290 - val_recall_13: 0.7540 - val_precision_13: 0.8597 - val_mean_io_u_13: 0.8290 - val_accuracy: 0.9933 - val_auc: 0.8805 - lr: 1.0000e-04\n",
      "Epoch 59/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1869 - recall_13: 0.9066 - precision_13: 0.8877 - mean_io_u_13: 0.9019 - accuracy: 0.9963 - auc: 0.9564\n",
      "Epoch 59: val_loss did not improve from 0.19209\n",
      "\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "65/65 [==============================] - 13s 206ms/step - loss: 0.1869 - recall_13: 0.9066 - precision_13: 0.8877 - mean_io_u_13: 0.9019 - accuracy: 0.9963 - auc: 0.9564 - val_loss: 0.2513 - val_recall_13: 0.8363 - val_precision_13: 0.8774 - val_mean_io_u_13: 0.8672 - val_accuracy: 0.9949 - val_auc: 0.9218 - lr: 1.0000e-04\n",
      "Epoch 60/200\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1864 - recall_13: 0.9075 - precision_13: 0.8874 - mean_io_u_13: 0.9022 - accuracy: 0.9963 - auc: 0.9568\n",
      "Epoch 60: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1864 - recall_13: 0.9075 - precision_13: 0.8874 - mean_io_u_13: 0.9022 - accuracy: 0.9963 - auc: 0.9568 - val_loss: 0.2802 - val_recall_13: 0.8044 - val_precision_13: 0.8730 - val_mean_io_u_13: 0.8525 - val_accuracy: 0.9944 - val_auc: 0.9059 - lr: 1.0000e-05\n",
      "Epoch 61/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1859 - recall_13: 0.9074 - precision_13: 0.8880 - mean_io_u_13: 0.9024 - accuracy: 0.9963 - auc: 0.9568\n",
      "Epoch 61: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1859 - recall_13: 0.9075 - precision_13: 0.8880 - mean_io_u_13: 0.9024 - accuracy: 0.9963 - auc: 0.9568 - val_loss: 0.2756 - val_recall_13: 0.8086 - val_precision_13: 0.8750 - val_mean_io_u_13: 0.8546 - val_accuracy: 0.9945 - val_auc: 0.9081 - lr: 1.0000e-05\n",
      "Epoch 62/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1860 - recall_13: 0.9073 - precision_13: 0.8880 - mean_io_u_13: 0.9024 - accuracy: 0.9963 - auc: 0.9568\n",
      "Epoch 62: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1861 - recall_13: 0.9073 - precision_13: 0.8880 - mean_io_u_13: 0.9024 - accuracy: 0.9963 - auc: 0.9568 - val_loss: 0.3040 - val_recall_13: 0.7769 - val_precision_13: 0.8701 - val_mean_io_u_13: 0.8402 - val_accuracy: 0.9939 - val_auc: 0.8922 - lr: 1.0000e-05\n",
      "Epoch 63/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1855 - recall_13: 0.9080 - precision_13: 0.8880 - mean_io_u_13: 0.9026 - accuracy: 0.9963 - auc: 0.9571\n",
      "Epoch 63: val_loss did not improve from 0.19209\n",
      "65/65 [==============================] - 13s 205ms/step - loss: 0.1855 - recall_13: 0.9080 - precision_13: 0.8879 - mean_io_u_13: 0.9026 - accuracy: 0.9963 - auc: 0.9571 - val_loss: 0.3003 - val_recall_13: 0.7820 - val_precision_13: 0.8696 - val_mean_io_u_13: 0.8423 - val_accuracy: 0.9940 - val_auc: 0.8947 - lr: 1.0000e-05\n",
      "Epoch 64/200\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1856 - recall_13: 0.9079 - precision_13: 0.8880 - mean_io_u_13: 0.9027 - accuracy: 0.9963 - auc: 0.9570\n",
      "Epoch 64: val_loss did not improve from 0.19209\n",
      "\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "65/65 [==============================] - 13s 207ms/step - loss: 0.1855 - recall_13: 0.9080 - precision_13: 0.8880 - mean_io_u_13: 0.9028 - accuracy: 0.9963 - auc: 0.9570 - val_loss: 0.2816 - val_recall_13: 0.8013 - val_precision_13: 0.8745 - val_mean_io_u_13: 0.8514 - val_accuracy: 0.9943 - val_auc: 0.9043 - lr: 1.0000e-05\n",
      "Epoch 64: early stopping\n",
      "\n",
      "\n",
      " f    <function IoULoss.<locals>.f at 0x7f046446d1f0>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for loss in models.keys():\n",
    "    if models[loss][0]!=0:\n",
    "        f = functions[loss.split('-')[0]](models[loss][0])\n",
    "    else:\n",
    "        f = functions[loss]()    \n",
    "    models[loss][1].compile(loss=f, optimizer=\"adam\", metrics=[Recall(),Precision(),\n",
    "                                                                    MeanIoU(num_classes=2), \"accuracy\", \"AUC\"])\n",
    "    \n",
    "\n",
    "    early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "    model_checkpoint = ModelCheckpoint(f\"./iter_{loss}.model\", save_best_only=True, verbose=1)\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "    epochs = 200\n",
    "    batch_size = 32\n",
    "\n",
    "    histories[loss] =  models[loss][1].fit(x_train, y_train,\n",
    "                        validation_data=[x_test, y_test], \n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        callbacks=[early_stopping, model_checkpoint, reduce_lr])\n",
    "    \n",
    "    fname = \"f\"\n",
    "    \n",
    "    print(f\"\\n\\n {fname}    {f}\\n\\n\\n\\n\")\n",
    "    model = load_model(f'./iter_{loss}.model', custom_objects={fname:f})\n",
    "    del models[loss][1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_chief_worker_only',\n",
       " '_implements_predict_batch_hooks',\n",
       " '_implements_test_batch_hooks',\n",
       " '_implements_train_batch_hooks',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_supports_tf_logs',\n",
       " 'epoch',\n",
       " 'history',\n",
       " 'model',\n",
       " 'on_batch_begin',\n",
       " 'on_batch_end',\n",
       " 'on_epoch_begin',\n",
       " 'on_epoch_end',\n",
       " 'on_predict_batch_begin',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_begin',\n",
       " 'on_predict_end',\n",
       " 'on_test_batch_begin',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_begin',\n",
       " 'on_test_end',\n",
       " 'on_train_batch_begin',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_begin',\n",
       " 'on_train_end',\n",
       " 'params',\n",
       " 'set_model',\n",
       " 'set_params',\n",
       " 'validation_data']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(histories['BCE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(histories[\"BCE\"].history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = list(histories.keys())\n",
    "\n",
    "argmaxindices = []\n",
    "precisions = []\n",
    "recall = []\n",
    "auc = []\n",
    "mean_io_u = []\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    metrics = histories[name].history.keys()\n",
    "    argmaxindices.append((tf.argmin(histories[name].history[\"val_loss\"])).numpy())\n",
    "    for metric in metrics:\n",
    "        if metric.startswith(\"precision\"):\n",
    "            precisions.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"recall\"):\n",
    "            recall.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"auc\"):\n",
    "            auc.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"mean_io_u\"):\n",
    "            mean_io_u.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        \n",
    "\n",
    "fig, ((ax00, ax01),(ax10,ax11)) = plt.subplots(2,2, figsize=(12,12))\n",
    "ax00.set_title(\"val_precision\")\n",
    "ax00.barh(names[:4]+names[5:], precisions[:4]+precisions[5:])\n",
    "\n",
    "ax01.set_title(\"val_recall\")\n",
    "ax01.barh(names[:4]+names[5:], recall[:4]+recall[5:])\n",
    "\n",
    "ax10.set_title(\"val_auc\")\n",
    "ax10.barh(names[:4]+names[5:], auc[:4]+auc[5:])\n",
    "\n",
    "ax11.set_title(\"val_mean_IoU\")\n",
    "ax11.barh(names[:4]+names[5:], mean_io_u[:4]+mean_io_u[5:])\n",
    "\n",
    "# fig.tight_layout()\n",
    "fig.subplots_adjust(wspace=0.3, hspace=0.2)\n",
    "fig.savefig(\"my_fig.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " f    <keras.losses.BinaryCrossentropy object at 0x7f0101773760>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f010c411d30>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f00d807f040>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f01019f6af0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f01842f4940>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedBinCrossEntr.<locals>.f at 0x7f013027d8b0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function diceLoss.<locals>.f at 0x7f00dbd439d0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f01303f4700>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f01306744c0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f01306635e0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f00d819d430>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function weightedDiceLoss.<locals>.f at 0x7f0101b2a310>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function DiceBCE.<locals>.f at 0x7f0184432040>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " f    <function IoULoss.<locals>.f at 0x7f01841efee0>\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = 14\n",
    "y_sample = y_test[t].reshape(256,256)\n",
    "\n",
    "fig, [[a01,a02,a03,a04],[a11,a12,a13,a14], [a21,a22,a23,a24], [a31,a32,a33,a34]] = plt.subplots(4,4, figsize=(8,8))\n",
    "fig.tight_layout()\n",
    "\n",
    "\n",
    "axs = [[a01,a02,a03,a04],[a11,a12,a13,a14], [a21,a22,a23,a24], [a31,a32,a33,a34]] \n",
    "\n",
    "a01.imshow(y_sample)\n",
    "a01.set_title(\"ground truth\")\n",
    "\n",
    "a02.imshow(x_test[t].reshape(256,256))\n",
    "a02.set_title(\"input data\")\n",
    "\n",
    "i=0\n",
    "j=2\n",
    "for loss in models.keys():\n",
    "    if models[loss][0]!=0:\n",
    "        f = functions[loss.split('-')[0]](models[loss][0])\n",
    "    else:\n",
    "        f = functions[loss]()  \n",
    "    \n",
    "    fname = \"f\"\n",
    "    \n",
    "    print(f\"\\n\\n {fname}    {f}\\n\\n\\n\\n\")\n",
    "    model = load_model(f'./iter_{loss}.model', custom_objects={fname:f})\n",
    "    \n",
    "    \n",
    "    predicted = model.predict(x_test)\n",
    "    axs[i][j].imshow(predicted[t].squeeze())\n",
    "    axs[i][j].set_title(loss)\n",
    "    j = (j+1)%4\n",
    "    if j==0: i+=1\n",
    "\n",
    "        \n",
    "fig.savefig(\"predictions.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Loss     |   Precision |   Recall |      AUC |   Mean IoU |\n",
      "|----------+-------------+----------+----------+------------|\n",
      "| BCE      |    0.91409  | 0.907954 | 0.999263 |   0.661571 |\n",
      "| wBCE-3   |    0.918204 | 0.899749 | 0.999312 |   0.594243 |\n",
      "| wBCE-10  |    0.915452 | 0.890431 | 0.999037 |   0.563584 |\n",
      "| wBCE-17  |    0.924417 | 0.891063 | 0.99896  |   0.498943 |\n",
      "| wBCE-25  |    0.095021 | 0.48759  | 0.578404 |   0.491814 |\n",
      "| wBCE-40  |    0.917349 | 0.883703 | 0.998537 |   0.501471 |\n",
      "| diceLoss |    0.729209 | 0.923778 | 0.963287 |   0.836579 |\n",
      "| wDice-3  |    0.860186 | 0.890365 | 0.948928 |   0.884593 |\n",
      "| wDice-10 |    0.881486 | 0.906755 | 0.956349 |   0.899613 |\n",
      "| wDice-17 |    0.881792 | 0.906569 | 0.957259 |   0.899269 |\n",
      "| wDice-25 |    0.88779  | 0.90858  | 0.958364 |   0.902758 |\n",
      "| wDice-40 |    0.86201  | 0.894641 | 0.950092 |   0.887416 |\n",
      "| DiceBCE  |    0.915831 | 0.927456 | 0.989068 |   0.697196 |\n",
      "| IoULoss  |    0.884173 | 0.905075 | 0.955582 |   0.899912 |\n"
     ]
    }
   ],
   "source": [
    "names = list(histories.keys())\n",
    "\n",
    "argmaxindices = []\n",
    "precisions = []\n",
    "recall = []\n",
    "auc = []\n",
    "mean_io_u = []\n",
    "\n",
    "\n",
    "for name in names:\n",
    "    metrics = histories[name].history.keys()\n",
    "    argmaxindices.append((tf.argmin(histories[name].history[\"val_loss\"])).numpy())\n",
    "    for metric in metrics:\n",
    "        if metric.startswith(\"precision\"):\n",
    "            precisions.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"recall\"):\n",
    "            recall.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"auc\"):\n",
    "            auc.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "        elif metric.startswith(\"mean_io_u\"):\n",
    "            mean_io_u.append(histories[name].history[metric][argmaxindices[-1]])\n",
    "\n",
    "l = []\n",
    "for i in range(len(names)):\n",
    "    l.append([])\n",
    "    l[-1].append(names[i])\n",
    "    l[-1].append(precisions[i])\n",
    "    l[-1].append(recall[i])\n",
    "    l[-1].append(auc[i])\n",
    "    l[-1].append(mean_io_u[i])\n",
    "table = tabulate(l, headers=['Loss', 'Precision', 'Recall', \"AUC\", \"Mean IoU\"], tablefmt='orgtbl')\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1.0,1.0,2.0]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f0200605f40>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[100].reshape(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f03443261f0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y_train[100].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/65 [============================>.] - ETA: 0s - loss: 0.1891 - recall_13: 0.9057 - precision_13: 0.8859 - mean_io_u_13: 0.9008 - accuracy: 0.9962 - auc: 0.9559\n",
      "Epoch 1: val_loss improved from inf to 0.34025, saving model to ./w4testBCE2D.model\n",
      "INFO:tensorflow:Assets written to: ./w4testBCE2D.model/assets\n",
      "65/65 [==============================] - 27s 368ms/step - loss: 0.1893 - recall_13: 0.9056 - precision_13: 0.8858 - mean_io_u_13: 0.9007 - accuracy: 0.9962 - auc: 0.9559 - val_loss: 0.3403 - val_recall_13: 0.7390 - val_precision_13: 0.8605 - val_mean_io_u_13: 0.8222 - val_accuracy: 0.9931 - val_auc: 0.8730 - lr: 1.0000e-04\n",
      "Epoch 2/5\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1892 - recall_13: 0.9060 - precision_13: 0.8856 - mean_io_u_13: 0.9007 - accuracy: 0.9962 - auc: 0.9560\n",
      "Epoch 2: val_loss did not improve from 0.34025\n",
      "65/65 [==============================] - 14s 211ms/step - loss: 0.1892 - recall_13: 0.9060 - precision_13: 0.8856 - mean_io_u_13: 0.9007 - accuracy: 0.9962 - auc: 0.9560 - val_loss: 0.3552 - val_recall_13: 0.7186 - val_precision_13: 0.8629 - val_mean_io_u_13: 0.8139 - val_accuracy: 0.9929 - val_auc: 0.8630 - lr: 1.0000e-04\n",
      "Epoch 3/5\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1879 - recall_13: 0.9061 - precision_13: 0.8869 - mean_io_u_13: 0.9016 - accuracy: 0.9962 - auc: 0.9561\n",
      "Epoch 3: val_loss improved from 0.34025 to 0.28945, saving model to ./w4testBCE2D.model\n",
      "INFO:tensorflow:Assets written to: ./w4testBCE2D.model/assets\n",
      "65/65 [==============================] - 21s 329ms/step - loss: 0.1879 - recall_13: 0.9061 - precision_13: 0.8869 - mean_io_u_13: 0.9016 - accuracy: 0.9962 - auc: 0.9561 - val_loss: 0.2894 - val_recall_13: 0.7915 - val_precision_13: 0.8750 - val_mean_io_u_13: 0.8471 - val_accuracy: 0.9942 - val_auc: 0.8996 - lr: 1.0000e-04\n",
      "Epoch 4/5\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1875 - recall_13: 0.9068 - precision_13: 0.8867 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9564\n",
      "Epoch 4: val_loss improved from 0.28945 to 0.18918, saving model to ./w4testBCE2D.model\n",
      "INFO:tensorflow:Assets written to: ./w4testBCE2D.model/assets\n",
      "65/65 [==============================] - 22s 341ms/step - loss: 0.1875 - recall_13: 0.9068 - precision_13: 0.8867 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9564 - val_loss: 0.1892 - val_recall_13: 0.9034 - val_precision_13: 0.8880 - val_mean_io_u_13: 0.9008 - val_accuracy: 0.9962 - val_auc: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 5/5\n",
      "65/65 [==============================] - ETA: 0s - loss: 0.1872 - recall_13: 0.9068 - precision_13: 0.8871 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9564\n",
      "Epoch 5: val_loss did not improve from 0.18918\n",
      "65/65 [==============================] - 14s 210ms/step - loss: 0.1872 - recall_13: 0.9068 - precision_13: 0.8871 - mean_io_u_13: 0.9017 - accuracy: 0.9962 - auc: 0.9564 - val_loss: 0.3158 - val_recall_13: 0.7621 - val_precision_13: 0.8702 - val_mean_io_u_13: 0.8337 - val_accuracy: 0.9937 - val_auc: 0.8846 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=10, verbose=1)\n",
    "model_checkpoint = ModelCheckpoint(\"./w4testBCE2D.model\", save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=5, min_lr=0.00001, verbose=1)\n",
    "\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# weights = {0:0.1, 1:1}\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    validation_data=[x_test, y_test], \n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[early_stopping, model_checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history = histories[\"IoULoss\"]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve for IoULoss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = histories[\"IoULoss\"]\n",
    "\n",
    "\n",
    "for name in history.keys():\n",
    "    if name.startswith(\"precision\"):\n",
    "        precisions = history[name]\n",
    "    elif name.startswith(\"recall\"):\n",
    "        recalls = history[name]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve for IoULoss\")\n",
    "plt.plot(history.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f020847f550>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"auc\"], label=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 256, 256, 20  200         ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 256, 256, 20  80         ['conv2d_38[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 256, 256, 20  3620        ['batch_normalization_36[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 256, 256, 20  80         ['conv2d_39[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 128, 128, 20  0          ['batch_normalization_37[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_16 (Dropout)           (None, 128, 128, 20  0           ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 128, 40  7240        ['dropout_16[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 128, 128, 40  160        ['conv2d_40[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 128, 40  14440       ['batch_normalization_38[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 128, 128, 40  160        ['conv2d_41[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 64, 64, 40)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_17 (Dropout)           (None, 64, 64, 40)   0           ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 64, 64, 80)   28880       ['dropout_17[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 64, 64, 80)  320         ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 64, 64, 80)   57680       ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 64, 64, 80)  320         ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_41[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 32, 32, 80)   0           ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 32, 160)  115360      ['dropout_18[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 32, 32, 160)  640        ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 32, 160)  230560      ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 32, 32, 160)  640        ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_43[0][0]'] \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 16, 16, 160)  0           ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 16, 320)  461120      ['dropout_19[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 16, 16, 320)  1280       ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 16, 320)  921920      ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 16, 16, 320)  1280       ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 32, 32, 160)  460960     ['batch_normalization_45[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 32, 32, 320)  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 32, 32, 320)  0           ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 32, 32, 160)  460960      ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 32, 32, 160)  640        ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 32, 160)  230560      ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 32, 32, 160)  640        ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 64, 64, 80)  115280      ['batch_normalization_47[0][0]'] \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 64, 64, 160)  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                                                  'batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 64, 64, 160)  0           ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 64, 64, 80)   115280      ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 64, 64, 80)  320         ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 64, 64, 80)   57680       ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 64, 64, 80)  320         ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_49[0][0]'] \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                )                                 'batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 128, 128, 80  0           ['concatenate_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 128, 128, 40  28840       ['dropout_22[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 128, 128, 40  160        ['conv2d_52[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 128, 128, 40  14440       ['batch_normalization_50[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 128, 128, 40  160        ['conv2d_53[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_51[0][0]'] \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                )                                 'batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 256, 256, 40  0           ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 256, 20  7220        ['dropout_23[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 256, 256, 20  80         ['conv2d_54[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 256, 256, 20  3620        ['batch_normalization_52[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 256, 256, 20  80         ['conv2d_55[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 256, 256, 1)  21          ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = load_model('./w15BCE2D.model', custom_objects={\"weightedBinCrossEntr\":weightedBinCrossEntr})\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicteds = model.predict(x_test)\n",
    "#plt.imshow(predicteds[0].reshape(1,512,512,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(514, 256, 256, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicteds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347866773605347 0.912050187587738\n"
     ]
    }
   ],
   "source": [
    "print(float(Precision()(y_test,predicteds)), float(Recall()(y_test,predicteds)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01e44501c0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax, p = plt.subplots(1,2)\n",
    "i=23\n",
    "p[0].imshow(predicteds[i].squeeze())\n",
    "p[1].imshow(y_test[i].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f02002a3c10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0].reshape(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01e4642280>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y_test[0].reshape(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f01ac54fc40>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(out_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://d5cea107-ea09-49c1-9235-867af2f808b7/assets\n",
      "INFO:tensorflow:Assets written to: ram://dfbf6e24-2868-4b5c-94c2-8085cde4bdca/assets\n",
      "INFO:tensorflow:Assets written to: ram://b5c34dc1-34e7-4527-aa1a-ddaf16546329/assets\n",
      "INFO:tensorflow:Assets written to: ram://ea5e628e-0d07-4540-9b15-aec1e6456308/assets\n",
      "INFO:tensorflow:Assets written to: ram://1e8ba0d5-7311-4ece-871b-36e70a5bf3cd/assets\n",
      "INFO:tensorflow:Assets written to: ram://d126c2e6-92b8-48ad-a1bd-c306edadbc46/assets\n",
      "INFO:tensorflow:Assets written to: ram://abe22fff-4402-4994-b1a8-30fe26604392/assets\n",
      "INFO:tensorflow:Assets written to: ram://caeef166-2123-42e8-b66d-83e64a4b626f/assets\n",
      "INFO:tensorflow:Assets written to: ram://d859bb88-3d03-4a5a-a7ed-aaf30c9bebb5/assets\n",
      "INFO:tensorflow:Assets written to: ram://81bef932-3ffa-440e-bd87-21bdd7b909e0/assets\n",
      "INFO:tensorflow:Assets written to: ram://97c78b72-54ce-4569-a387-8f0e602b5662/assets\n",
      "INFO:tensorflow:Assets written to: ram://cc104a4d-913a-48e8-ba8d-06e122fc0b60/assets\n",
      "INFO:tensorflow:Assets written to: ram://bf81cc3d-53bb-4841-a1bd-85365eea4048/assets\n",
      "INFO:tensorflow:Assets written to: ram://1fd69f65-6f21-47eb-94c0-49116c846c47/assets\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"historiesfile.txt\", \"wb\") as fh:\n",
    "    pickle.dump(histories, fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EYE029 slice 5 black.tif',\n",
       " 'EYE012 slice 30 black.tif',\n",
       " 'EYE009 slice 45 black.tif',\n",
       " 'EYE012 slice 20 black.tif',\n",
       " 'EYE044 slice 38 black.tif',\n",
       " 'EYE029 slice 19 black.tif',\n",
       " 'EYE038 slice 9 black.tif',\n",
       " 'EYE034 slice 47 black.tif',\n",
       " 'EYE016 slice 1 black.tif',\n",
       " 'EYE031 slice 36 black.tif',\n",
       " 'EYE004 slice 11 black.tif',\n",
       " 'EYE044 slice 13 black.tif',\n",
       " 'EYE011 slice 25 black.tif',\n",
       " 'EYE042 slice 44 black.tif',\n",
       " 'EYE025 slice 33 black.tif',\n",
       " 'EYE043 slice 26 black.tif',\n",
       " 'EYE046 slice 34 black.tif',\n",
       " 'EYE029 slice 23 black.tif',\n",
       " 'EYE010 slice 44 black.tif',\n",
       " 'EYE018 slice 22 black.tif',\n",
       " 'EYE044 slice 27 black.tif',\n",
       " 'EYE016 slice 13 black.tif',\n",
       " 'EYE002 slice 35 black.tif',\n",
       " 'EYE022 slice 14 black.tif',\n",
       " 'EYE033 slice 13 black.tif',\n",
       " 'EYE023 slice 25 black.tif',\n",
       " 'EYE030 slice 36 black.tif',\n",
       " 'EYE015 slice 6 black.tif',\n",
       " 'EYE009 slice 29 black.tif',\n",
       " 'EYE002 slice 3 black.tif',\n",
       " 'EYE027 slice 4 black.tif',\n",
       " 'EYE034 slice 42 black.tif',\n",
       " 'EYE051 slice 24 black.tif',\n",
       " 'EYE004 slice 10 black.tif',\n",
       " 'EYE040 slice 18 black.tif',\n",
       " 'EYE051 slice 11 black.tif',\n",
       " 'EYE019 slice 46 black.tif',\n",
       " 'EYE014 slice 28 black.tif',\n",
       " 'EYE038 slice 7 black.tif',\n",
       " 'EYE025 slice 4 black.tif',\n",
       " 'EYE018 slice 17 black.tif',\n",
       " 'EYE050 slice 30 black.tif',\n",
       " 'EYE043 slice 14 black.tif',\n",
       " 'EYE020 slice 41 black.tif',\n",
       " 'EYE013 slice 18 black.tif',\n",
       " 'EYE033 slice 9 black.tif',\n",
       " 'EYE006 slice 3 black.tif',\n",
       " 'EYE017 slice 46 black.tif',\n",
       " 'EYE048 slice 15 black.tif',\n",
       " 'EYE037 slice 11 black.tif',\n",
       " 'EYE006 slice 46 black.tif',\n",
       " 'EYE038 slice 10 black.tif',\n",
       " 'EYE044 slice 29 black.tif',\n",
       " 'EYE040 slice 39 black.tif',\n",
       " 'EYE048 slice 38 black.tif',\n",
       " 'EYE044 slice 39 black.tif',\n",
       " 'EYE013 slice 10 black.tif',\n",
       " 'EYE032 slice 42 black.tif',\n",
       " 'EYE048 slice 17 black.tif',\n",
       " 'EYE046 slice 35 black.tif',\n",
       " 'EYE025 slice 43 black.tif',\n",
       " 'EYE035 slice 25 black.tif',\n",
       " 'EYE041 slice 13 black.tif',\n",
       " 'EYE006 slice 18 black.tif',\n",
       " 'EYE026 slice 3 black.tif',\n",
       " 'EYE045 slice 40 black.tif',\n",
       " 'EYE051 slice 42 black.tif',\n",
       " 'EYE013 slice 40 black.tif',\n",
       " 'EYE013 slice 41 black.tif',\n",
       " 'EYE045 slice 37 black.tif',\n",
       " 'EYE049 slice 15 black.tif',\n",
       " 'EYE024 slice 2 black.tif',\n",
       " 'EYE047 slice 40 black.tif',\n",
       " 'EYE040 slice 35 black.tif',\n",
       " 'EYE029 slice 32 black.tif',\n",
       " 'EYE011 slice 12 black.tif',\n",
       " 'EYE020 slice 16 black.tif',\n",
       " 'EYE005 slice 34 black.tif',\n",
       " 'EYE001 slice 1 black.tif',\n",
       " 'EYE015 slice 35 black.tif',\n",
       " 'EYE034 slice 13 black.tif',\n",
       " 'EYE048 slice 43 black.tif',\n",
       " 'EYE023 slice 30 black.tif',\n",
       " 'EYE048 slice 19 black.tif',\n",
       " 'EYE008 slice 13 black.tif',\n",
       " 'EYE047 slice 8 black.tif',\n",
       " 'EYE039 slice 17 black.tif',\n",
       " 'EYE044 slice 34 black.tif',\n",
       " 'EYE019 slice 1 black.tif',\n",
       " 'EYE003 slice 19 black.tif',\n",
       " 'EYE045 slice 35 black.tif',\n",
       " 'EYE015 slice 27 black.tif',\n",
       " 'EYE036 slice 38 black.tif',\n",
       " 'EYE025 slice 5 black.tif',\n",
       " 'EYE028 slice 32 black.tif',\n",
       " 'EYE012 slice 42 black.tif',\n",
       " 'EYE042 slice 22 black.tif',\n",
       " 'EYE029 slice 48 black.tif',\n",
       " 'EYE039 slice 18 black.tif',\n",
       " 'EYE002 slice 36 black.tif',\n",
       " 'EYE034 slice 1 black.tif',\n",
       " 'EYE008 slice 34 black.tif',\n",
       " 'EYE024 slice 1 black.tif',\n",
       " 'EYE038 slice 49 black.tif',\n",
       " 'EYE049 slice 9 black.tif',\n",
       " 'EYE045 slice 45 black.tif',\n",
       " 'EYE004 slice 17 black.tif',\n",
       " 'EYE004 slice 28 black.tif',\n",
       " 'EYE001 slice 48 black.tif',\n",
       " 'EYE053 slice 14 black.tif',\n",
       " 'EYE039 slice 21 black.tif',\n",
       " 'EYE011 slice 22 black.tif',\n",
       " 'EYE053 slice 17 black.tif',\n",
       " 'EYE001 slice 18 black.tif',\n",
       " 'EYE005 slice 20 black.tif',\n",
       " 'EYE043 slice 41 black.tif',\n",
       " 'EYE024 slice 32 black.tif',\n",
       " 'EYE047 slice 38 black.tif',\n",
       " 'EYE030 slice 30 black.tif',\n",
       " 'EYE025 slice 9 black.tif',\n",
       " 'EYE016 slice 38 black.tif',\n",
       " 'EYE021 slice 43 black.tif',\n",
       " 'EYE007 slice 8 black.tif',\n",
       " 'EYE028 slice 13 black.tif',\n",
       " 'EYE032 slice 34 black.tif',\n",
       " 'EYE039 slice 4 black.tif',\n",
       " 'EYE020 slice 1 black.tif',\n",
       " 'EYE006 slice 13 black.tif',\n",
       " 'EYE005 slice 41 black.tif',\n",
       " 'EYE024 slice 35 black.tif',\n",
       " 'EYE037 slice 16 black.tif',\n",
       " 'EYE021 slice 28 black.tif',\n",
       " 'EYE001 slice 14 black.tif',\n",
       " 'EYE001 slice 47 black.tif',\n",
       " 'EYE049 slice 4 black.tif',\n",
       " 'EYE041 slice 4 black.tif',\n",
       " 'EYE022 slice 19 black.tif',\n",
       " 'EYE011 slice 37 black.tif',\n",
       " 'EYE044 slice 5 black.tif',\n",
       " 'EYE034 slice 22 black.tif',\n",
       " 'EYE030 slice 37 black.tif',\n",
       " 'EYE051 slice 30 black.tif',\n",
       " 'EYE029 slice 33 black.tif',\n",
       " 'EYE015 slice 17 black.tif',\n",
       " 'EYE004 slice 32 black.tif',\n",
       " 'EYE014 slice 31 black.tif',\n",
       " 'EYE008 slice 35 black.tif',\n",
       " 'EYE028 slice 35 black.tif',\n",
       " 'EYE026 slice 41 black.tif',\n",
       " 'EYE006 slice 25 black.tif',\n",
       " 'EYE022 slice 3 black.tif',\n",
       " 'EYE036 slice 21 black.tif',\n",
       " 'EYE025 slice 42 black.tif',\n",
       " 'EYE023 slice 24 black.tif',\n",
       " 'EYE037 slice 2 black.tif',\n",
       " 'EYE044 slice 4 black.tif',\n",
       " 'EYE027 slice 10 black.tif',\n",
       " 'EYE036 slice 22 black.tif',\n",
       " 'EYE016 slice 43 black.tif',\n",
       " 'EYE046 slice 19 black.tif',\n",
       " 'EYE006 slice 31 black.tif',\n",
       " 'EYE025 slice 44 black.tif',\n",
       " 'EYE027 slice 17 black.tif',\n",
       " 'EYE012 slice 16 black.tif',\n",
       " 'EYE029 slice 45 black.tif',\n",
       " 'EYE019 slice 8 black.tif',\n",
       " 'EYE038 slice 35 black.tif',\n",
       " 'EYE050 slice 37 black.tif',\n",
       " 'EYE044 slice 22 black.tif',\n",
       " 'EYE015 slice 30 black.tif',\n",
       " 'EYE034 slice 18 black.tif',\n",
       " 'EYE036 slice 49 black.tif',\n",
       " 'EYE006 slice 47 black.tif',\n",
       " 'EYE007 slice 41 black.tif',\n",
       " 'EYE051 slice 39 black.tif',\n",
       " 'EYE005 slice 14 black.tif',\n",
       " 'EYE052 slice 47 black.tif',\n",
       " 'EYE049 slice 10 black.tif',\n",
       " 'EYE026 slice 44 black.tif',\n",
       " 'EYE050 slice 19 black.tif',\n",
       " 'EYE028 slice 5 black.tif',\n",
       " 'EYE017 slice 17 black.tif',\n",
       " 'EYE035 slice 22 black.tif',\n",
       " 'EYE014 slice 46 black.tif',\n",
       " 'EYE048 slice 1 black.tif',\n",
       " 'EYE022 slice 8 black.tif',\n",
       " 'EYE029 slice 31 black.tif',\n",
       " 'EYE034 slice 35 black.tif',\n",
       " 'EYE004 slice 48 black.tif',\n",
       " 'EYE043 slice 2 black.tif',\n",
       " 'EYE049 slice 27 black.tif',\n",
       " 'EYE036 slice 1 black.tif',\n",
       " 'EYE051 slice 27 black.tif',\n",
       " 'EYE031 slice 31 black.tif',\n",
       " 'EYE021 slice 33 black.tif',\n",
       " 'EYE041 slice 39 black.tif',\n",
       " 'EYE020 slice 30 black.tif',\n",
       " 'EYE036 slice 12 black.tif',\n",
       " 'EYE046 slice 20 black.tif',\n",
       " 'EYE008 slice 23 black.tif',\n",
       " 'EYE053 slice 3 black.tif',\n",
       " 'EYE051 slice 22 black.tif',\n",
       " 'EYE050 slice 39 black.tif',\n",
       " 'EYE022 slice 7 black.tif',\n",
       " 'EYE041 slice 23 black.tif',\n",
       " 'EYE051 slice 28 black.tif',\n",
       " 'EYE035 slice 34 black.tif',\n",
       " 'EYE037 slice 22 black.tif',\n",
       " 'EYE006 slice 38 black.tif',\n",
       " 'EYE053 slice 46 black.tif',\n",
       " 'EYE043 slice 17 black.tif',\n",
       " 'EYE025 slice 32 black.tif',\n",
       " 'EYE043 slice 42 black.tif',\n",
       " 'EYE034 slice 19 black.tif',\n",
       " 'EYE035 slice 9 black.tif',\n",
       " 'EYE005 slice 48 black.tif',\n",
       " 'EYE010 slice 24 black.tif',\n",
       " 'EYE009 slice 27 black.tif',\n",
       " 'EYE052 slice 16 black.tif',\n",
       " 'EYE007 slice 46 black.tif',\n",
       " 'EYE037 slice 15 black.tif',\n",
       " 'EYE012 slice 33 black.tif',\n",
       " 'EYE031 slice 4 black.tif',\n",
       " 'EYE042 slice 17 black.tif',\n",
       " 'EYE004 slice 8 black.tif',\n",
       " 'EYE049 slice 41 black.tif',\n",
       " 'EYE031 slice 49 black.tif',\n",
       " 'EYE035 slice 1 black.tif',\n",
       " 'EYE049 slice 30 black.tif',\n",
       " 'EYE021 slice 22 black.tif',\n",
       " 'EYE052 slice 25 black.tif',\n",
       " 'EYE029 slice 26 black.tif',\n",
       " 'EYE010 slice 40 black.tif',\n",
       " 'EYE037 slice 1 black.tif',\n",
       " 'EYE042 slice 43 black.tif',\n",
       " 'EYE039 slice 1 black.tif',\n",
       " 'EYE043 slice 10 black.tif',\n",
       " 'EYE018 slice 6 black.tif',\n",
       " 'EYE049 slice 40 black.tif',\n",
       " 'EYE053 slice 41 black.tif',\n",
       " 'EYE016 slice 34 black.tif',\n",
       " 'EYE003 slice 36 black.tif',\n",
       " 'EYE004 slice 26 black.tif',\n",
       " 'EYE009 slice 18 black.tif',\n",
       " 'EYE031 slice 9 black.tif',\n",
       " 'EYE034 slice 23 black.tif',\n",
       " 'EYE047 slice 6 black.tif',\n",
       " 'EYE051 slice 9 black.tif',\n",
       " 'EYE042 slice 46 black.tif',\n",
       " 'EYE021 slice 5 black.tif',\n",
       " 'EYE046 slice 26 black.tif',\n",
       " 'EYE019 slice 28 black.tif',\n",
       " 'EYE017 slice 24 black.tif',\n",
       " 'EYE034 slice 3 black.tif',\n",
       " 'EYE009 slice 17 black.tif',\n",
       " 'EYE020 slice 36 black.tif',\n",
       " 'EYE016 slice 36 black.tif',\n",
       " 'EYE035 slice 32 black.tif',\n",
       " 'EYE021 slice 15 black.tif',\n",
       " 'EYE021 slice 38 black.tif',\n",
       " 'EYE022 slice 6 black.tif',\n",
       " 'EYE023 slice 32 black.tif',\n",
       " 'EYE047 slice 42 black.tif',\n",
       " 'EYE025 slice 10 black.tif',\n",
       " 'EYE034 slice 36 black.tif',\n",
       " 'EYE036 slice 6 black.tif',\n",
       " 'EYE001 slice 8 black.tif',\n",
       " 'EYE032 slice 25 black.tif',\n",
       " 'EYE031 slice 15 black.tif',\n",
       " 'EYE018 slice 29 black.tif',\n",
       " 'EYE003 slice 3 black.tif',\n",
       " 'EYE031 slice 8 black.tif',\n",
       " 'EYE040 slice 6 black.tif',\n",
       " 'EYE042 slice 1 black.tif',\n",
       " 'EYE034 slice 43 black.tif',\n",
       " 'EYE032 slice 28 black.tif',\n",
       " 'EYE002 slice 39 black.tif',\n",
       " 'EYE033 slice 3 black.tif',\n",
       " 'EYE020 slice 42 black.tif',\n",
       " 'EYE033 slice 7 black.tif',\n",
       " 'EYE039 slice 19 black.tif',\n",
       " 'EYE018 slice 44 black.tif',\n",
       " 'EYE044 slice 36 black.tif',\n",
       " 'EYE019 slice 47 black.tif',\n",
       " 'EYE002 slice 29 black.tif',\n",
       " 'EYE014 slice 16 black.tif',\n",
       " 'EYE020 slice 22 black.tif',\n",
       " 'EYE025 slice 17 black.tif',\n",
       " 'EYE007 slice 33 black.tif',\n",
       " 'EYE038 slice 18 black.tif',\n",
       " 'EYE036 slice 9 black.tif',\n",
       " 'EYE005 slice 49 black.tif',\n",
       " 'EYE018 slice 19 black.tif',\n",
       " 'EYE002 slice 19 black.tif',\n",
       " 'EYE011 slice 33 black.tif',\n",
       " 'EYE051 slice 3 black.tif',\n",
       " 'EYE043 slice 31 black.tif',\n",
       " 'EYE003 slice 27 black.tif',\n",
       " 'EYE029 slice 15 black.tif',\n",
       " 'EYE009 slice 42 black.tif',\n",
       " 'EYE018 slice 10 black.tif',\n",
       " 'EYE030 slice 3 black.tif',\n",
       " 'EYE036 slice 34 black.tif',\n",
       " 'EYE028 slice 8 black.tif',\n",
       " 'EYE036 slice 30 black.tif',\n",
       " 'EYE013 slice 14 black.tif',\n",
       " 'EYE047 slice 21 black.tif',\n",
       " 'EYE027 slice 47 black.tif',\n",
       " 'EYE030 slice 42 black.tif',\n",
       " 'EYE043 slice 46 black.tif',\n",
       " 'EYE023 slice 49 black.tif',\n",
       " 'EYE032 slice 2 black.tif',\n",
       " 'EYE030 slice 13 black.tif',\n",
       " 'EYE023 slice 4 black.tif',\n",
       " 'EYE015 slice 45 black.tif',\n",
       " 'EYE026 slice 38 black.tif',\n",
       " 'EYE009 slice 40 black.tif',\n",
       " 'EYE046 slice 40 black.tif',\n",
       " 'EYE021 slice 39 black.tif',\n",
       " 'EYE036 slice 10 black.tif',\n",
       " 'EYE039 slice 44 black.tif',\n",
       " 'EYE006 slice 21 black.tif',\n",
       " 'EYE035 slice 3 black.tif',\n",
       " 'EYE041 slice 28 black.tif',\n",
       " 'EYE005 slice 37 black.tif',\n",
       " 'EYE011 slice 29 black.tif',\n",
       " 'EYE048 slice 39 black.tif',\n",
       " 'EYE016 slice 37 black.tif',\n",
       " 'EYE040 slice 17 black.tif',\n",
       " 'EYE051 slice 32 black.tif',\n",
       " 'EYE017 slice 48 black.tif',\n",
       " 'EYE019 slice 3 black.tif',\n",
       " 'EYE013 slice 49 black.tif',\n",
       " 'EYE024 slice 10 black.tif',\n",
       " 'EYE007 slice 7 black.tif',\n",
       " 'EYE012 slice 4 black.tif',\n",
       " 'EYE019 slice 29 black.tif',\n",
       " 'EYE019 slice 36 black.tif',\n",
       " 'EYE013 slice 1 black.tif',\n",
       " 'EYE005 slice 11 black.tif',\n",
       " 'EYE026 slice 14 black.tif',\n",
       " 'EYE036 slice 41 black.tif',\n",
       " 'EYE043 slice 24 black.tif',\n",
       " 'EYE017 slice 9 black.tif',\n",
       " 'EYE034 slice 38 black.tif',\n",
       " 'EYE051 slice 46 black.tif',\n",
       " 'EYE021 slice 13 black.tif',\n",
       " 'EYE029 slice 38 black.tif',\n",
       " 'EYE008 slice 39 black.tif',\n",
       " 'EYE029 slice 25 black.tif',\n",
       " 'EYE048 slice 36 black.tif',\n",
       " 'EYE009 slice 9 black.tif',\n",
       " 'EYE038 slice 36 black.tif',\n",
       " 'EYE015 slice 41 black.tif',\n",
       " 'EYE040 slice 3 black.tif',\n",
       " 'EYE048 slice 27 black.tif',\n",
       " 'EYE039 slice 12 black.tif',\n",
       " 'EYE038 slice 8 black.tif',\n",
       " 'EYE041 slice 44 black.tif',\n",
       " 'EYE024 slice 28 black.tif',\n",
       " 'EYE008 slice 37 black.tif',\n",
       " 'EYE013 slice 32 black.tif',\n",
       " 'EYE042 slice 13 black.tif',\n",
       " 'EYE039 slice 46 black.tif',\n",
       " 'EYE040 slice 14 black.tif',\n",
       " 'EYE021 slice 20 black.tif',\n",
       " 'EYE006 slice 2 black.tif',\n",
       " 'EYE053 slice 48 black.tif',\n",
       " 'EYE032 slice 39 black.tif',\n",
       " 'EYE049 slice 43 black.tif',\n",
       " 'EYE050 slice 45 black.tif',\n",
       " 'EYE017 slice 11 black.tif',\n",
       " 'EYE018 slice 47 black.tif',\n",
       " 'EYE037 slice 34 black.tif',\n",
       " 'EYE029 slice 14 black.tif',\n",
       " 'EYE011 slice 36 black.tif',\n",
       " 'EYE033 slice 28 black.tif',\n",
       " 'EYE026 slice 32 black.tif',\n",
       " 'EYE023 slice 26 black.tif',\n",
       " 'EYE001 slice 13 black.tif',\n",
       " 'EYE022 slice 31 black.tif',\n",
       " 'EYE053 slice 27 black.tif',\n",
       " 'EYE022 slice 41 black.tif',\n",
       " 'EYE024 slice 17 black.tif',\n",
       " 'EYE018 slice 4 black.tif',\n",
       " 'EYE024 slice 40 black.tif',\n",
       " 'EYE014 slice 35 black.tif',\n",
       " 'EYE009 slice 1 black.tif',\n",
       " 'EYE042 slice 12 black.tif',\n",
       " 'EYE040 slice 41 black.tif',\n",
       " 'EYE017 slice 41 black.tif',\n",
       " 'EYE033 slice 46 black.tif',\n",
       " 'EYE052 slice 32 black.tif',\n",
       " 'EYE010 slice 17 black.tif',\n",
       " 'EYE048 slice 35 black.tif',\n",
       " 'EYE009 slice 14 black.tif',\n",
       " 'EYE015 slice 19 black.tif',\n",
       " 'EYE011 slice 2 black.tif',\n",
       " 'EYE019 slice 48 black.tif',\n",
       " 'EYE023 slice 40 black.tif',\n",
       " 'EYE052 slice 21 black.tif',\n",
       " 'EYE022 slice 16 black.tif',\n",
       " 'EYE025 slice 19 black.tif',\n",
       " 'EYE039 slice 27 black.tif',\n",
       " 'EYE044 slice 12 black.tif',\n",
       " 'EYE048 slice 41 black.tif',\n",
       " 'EYE044 slice 11 black.tif',\n",
       " 'EYE048 slice 49 black.tif',\n",
       " 'EYE006 slice 27 black.tif',\n",
       " 'EYE027 slice 1 black.tif',\n",
       " 'EYE047 slice 30 black.tif',\n",
       " 'EYE040 slice 29 black.tif',\n",
       " 'EYE052 slice 12 black.tif',\n",
       " 'EYE023 slice 44 black.tif',\n",
       " 'EYE015 slice 32 black.tif',\n",
       " 'EYE006 slice 23 black.tif',\n",
       " 'EYE046 slice 10 black.tif',\n",
       " 'EYE018 slice 46 black.tif',\n",
       " 'EYE018 slice 43 black.tif',\n",
       " 'EYE053 slice 11 black.tif',\n",
       " 'EYE021 slice 10 black.tif',\n",
       " 'EYE045 slice 18 black.tif',\n",
       " 'EYE012 slice 25 black.tif',\n",
       " 'EYE036 slice 27 black.tif',\n",
       " 'EYE034 slice 33 black.tif',\n",
       " 'EYE052 slice 41 black.tif',\n",
       " 'EYE026 slice 4 black.tif',\n",
       " 'EYE038 slice 30 black.tif',\n",
       " 'EYE015 slice 43 black.tif',\n",
       " 'EYE047 slice 49 black.tif',\n",
       " 'EYE016 slice 2 black.tif',\n",
       " 'EYE021 slice 14 black.tif',\n",
       " 'EYE047 slice 22 black.tif',\n",
       " 'EYE011 slice 26 black.tif',\n",
       " 'EYE038 slice 22 black.tif',\n",
       " 'EYE004 slice 47 black.tif',\n",
       " 'EYE045 slice 8 black.tif',\n",
       " 'EYE003 slice 37 black.tif',\n",
       " 'EYE034 slice 46 black.tif',\n",
       " 'EYE052 slice 22 black.tif',\n",
       " 'EYE006 slice 4 black.tif',\n",
       " 'EYE037 slice 19 black.tif',\n",
       " 'EYE003 slice 6 black.tif',\n",
       " 'EYE031 slice 34 black.tif',\n",
       " 'EYE019 slice 37 black.tif',\n",
       " 'EYE009 slice 16 black.tif',\n",
       " 'EYE027 slice 23 black.tif',\n",
       " 'EYE050 slice 40 black.tif',\n",
       " 'EYE012 slice 28 black.tif',\n",
       " 'EYE038 slice 25 black.tif',\n",
       " 'EYE020 slice 21 black.tif',\n",
       " 'EYE015 slice 22 black.tif',\n",
       " 'EYE006 slice 36 black.tif',\n",
       " 'EYE010 slice 38 black.tif',\n",
       " 'EYE042 slice 25 black.tif',\n",
       " 'EYE030 slice 2 black.tif',\n",
       " 'EYE046 slice 45 black.tif',\n",
       " 'EYE052 slice 1 black.tif',\n",
       " 'EYE023 slice 10 black.tif',\n",
       " 'EYE037 slice 38 black.tif',\n",
       " 'EYE009 slice 43 black.tif',\n",
       " 'EYE008 slice 2 black.tif',\n",
       " 'EYE015 slice 14 black.tif',\n",
       " 'EYE039 slice 33 black.tif',\n",
       " 'EYE047 slice 14 black.tif',\n",
       " 'EYE019 slice 30 black.tif',\n",
       " 'EYE037 slice 47 black.tif',\n",
       " 'EYE008 slice 15 black.tif',\n",
       " 'EYE043 slice 28 black.tif',\n",
       " 'EYE023 slice 41 black.tif',\n",
       " 'EYE014 slice 15 black.tif',\n",
       " 'EYE017 slice 35 black.tif',\n",
       " 'EYE001 slice 33 black.tif',\n",
       " 'EYE024 slice 13 black.tif',\n",
       " 'EYE027 slice 41 black.tif',\n",
       " 'EYE036 slice 17 black.tif',\n",
       " 'EYE028 slice 40 black.tif',\n",
       " 'EYE046 slice 18 black.tif',\n",
       " 'EYE036 slice 36 black.tif',\n",
       " 'EYE031 slice 7 black.tif',\n",
       " 'EYE048 slice 37 black.tif',\n",
       " 'EYE027 slice 34 black.tif',\n",
       " 'EYE037 slice 43 black.tif',\n",
       " 'EYE040 slice 42 black.tif',\n",
       " 'EYE004 slice 36 black.tif',\n",
       " 'EYE036 slice 48 black.tif',\n",
       " 'EYE024 slice 41 black.tif',\n",
       " 'EYE019 slice 42 black.tif',\n",
       " 'EYE050 slice 15 black.tif',\n",
       " 'EYE005 slice 5 black.tif',\n",
       " 'EYE035 slice 12 black.tif',\n",
       " 'EYE011 slice 1 black.tif',\n",
       " 'EYE030 slice 7 black.tif',\n",
       " 'EYE037 slice 14 black.tif',\n",
       " 'EYE027 slice 32 black.tif',\n",
       " 'EYE044 slice 2 black.tif',\n",
       " 'EYE036 slice 19 black.tif',\n",
       " 'EYE032 slice 37 black.tif',\n",
       " 'EYE005 slice 18 black.tif',\n",
       " 'EYE017 slice 7 black.tif',\n",
       " 'EYE007 slice 23 black.tif',\n",
       " 'EYE010 slice 7 black.tif',\n",
       " 'EYE033 slice 21 black.tif',\n",
       " 'EYE002 slice 30 black.tif',\n",
       " 'EYE032 slice 14 black.tif',\n",
       " 'EYE001 slice 9 black.tif',\n",
       " 'EYE020 slice 33 black.tif',\n",
       " 'EYE033 slice 27 black.tif',\n",
       " 'EYE052 slice 23 black.tif',\n",
       " 'EYE017 slice 1 black.tif',\n",
       " 'EYE026 slice 18 black.tif',\n",
       " 'EYE030 slice 33 black.tif',\n",
       " 'EYE005 slice 13 black.tif',\n",
       " 'EYE002 slice 7 black.tif',\n",
       " 'EYE026 slice 2 black.tif',\n",
       " 'EYE042 slice 39 black.tif',\n",
       " 'EYE046 slice 47 black.tif',\n",
       " 'EYE001 slice 4 black.tif',\n",
       " 'EYE042 slice 2 black.tif',\n",
       " 'EYE028 slice 31 black.tif',\n",
       " 'EYE034 slice 41 black.tif',\n",
       " 'EYE010 slice 2 black.tif',\n",
       " 'EYE012 slice 9 black.tif',\n",
       " 'EYE020 slice 43 black.tif',\n",
       " 'EYE041 slice 38 black.tif',\n",
       " 'EYE040 slice 40 black.tif',\n",
       " 'EYE050 slice 11 black.tif',\n",
       " 'EYE022 slice 18 black.tif',\n",
       " 'EYE016 slice 18 black.tif',\n",
       " 'EYE017 slice 40 black.tif',\n",
       " 'EYE048 slice 31 black.tif',\n",
       " 'EYE034 slice 31 black.tif',\n",
       " 'EYE027 slice 24 black.tif',\n",
       " 'EYE046 slice 8 black.tif',\n",
       " 'EYE047 slice 17 black.tif',\n",
       " 'EYE027 slice 22 black.tif',\n",
       " 'EYE044 slice 23 black.tif',\n",
       " 'EYE015 slice 15 black.tif',\n",
       " 'EYE003 slice 44 black.tif',\n",
       " 'EYE008 slice 7 black.tif',\n",
       " 'EYE051 slice 2 black.tif',\n",
       " 'EYE031 slice 5 black.tif',\n",
       " 'EYE030 slice 49 black.tif',\n",
       " 'EYE027 slice 3 black.tif',\n",
       " 'EYE015 slice 24 black.tif',\n",
       " 'EYE015 slice 44 black.tif',\n",
       " 'EYE050 slice 33 black.tif',\n",
       " 'EYE043 slice 23 black.tif',\n",
       " 'EYE042 slice 31 black.tif',\n",
       " 'EYE033 slice 42 black.tif',\n",
       " 'EYE028 slice 36 black.tif',\n",
       " 'EYE017 slice 14 black.tif',\n",
       " 'EYE029 slice 34 black.tif',\n",
       " 'EYE036 slice 40 black.tif',\n",
       " 'EYE035 slice 39 black.tif',\n",
       " 'EYE043 slice 36 black.tif',\n",
       " 'EYE026 slice 6 black.tif',\n",
       " 'EYE012 slice 6 black.tif',\n",
       " 'EYE043 slice 43 black.tif',\n",
       " 'EYE028 slice 12 black.tif',\n",
       " 'EYE034 slice 2 black.tif',\n",
       " 'EYE007 slice 34 black.tif',\n",
       " 'EYE051 slice 19 black.tif',\n",
       " 'EYE017 slice 20 black.tif',\n",
       " 'EYE034 slice 21 black.tif',\n",
       " 'EYE016 slice 30 black.tif',\n",
       " 'EYE030 slice 8 black.tif',\n",
       " 'EYE038 slice 1 black.tif',\n",
       " 'EYE004 slice 14 black.tif',\n",
       " 'EYE007 slice 14 black.tif',\n",
       " 'EYE038 slice 27 black.tif',\n",
       " 'EYE030 slice 15 black.tif',\n",
       " 'EYE047 slice 23 black.tif',\n",
       " 'EYE010 slice 30 black.tif',\n",
       " 'EYE014 slice 42 black.tif',\n",
       " 'EYE010 slice 20 black.tif',\n",
       " 'EYE008 slice 5 black.tif',\n",
       " 'EYE053 slice 35 black.tif',\n",
       " 'EYE037 slice 29 black.tif',\n",
       " 'EYE051 slice 5 black.tif',\n",
       " 'EYE026 slice 5 black.tif',\n",
       " 'EYE024 slice 42 black.tif',\n",
       " 'EYE002 slice 45 black.tif',\n",
       " 'EYE047 slice 24 black.tif',\n",
       " 'EYE010 slice 37 black.tif',\n",
       " 'EYE035 slice 49 black.tif',\n",
       " 'EYE035 slice 28 black.tif',\n",
       " 'EYE024 slice 38 black.tif',\n",
       " 'EYE017 slice 43 black.tif',\n",
       " 'EYE035 slice 17 black.tif',\n",
       " 'EYE002 slice 8 black.tif',\n",
       " 'EYE001 slice 23 black.tif',\n",
       " 'EYE013 slice 12 black.tif',\n",
       " 'EYE014 slice 7 black.tif',\n",
       " 'EYE011 slice 10 black.tif',\n",
       " 'EYE031 slice 33 black.tif',\n",
       " 'EYE041 slice 29 black.tif',\n",
       " 'EYE042 slice 24 black.tif',\n",
       " 'EYE044 slice 48 black.tif',\n",
       " 'EYE033 slice 34 black.tif',\n",
       " 'EYE011 slice 39 black.tif',\n",
       " 'EYE030 slice 14 black.tif',\n",
       " 'EYE003 slice 49 black.tif',\n",
       " 'EYE052 slice 29 black.tif',\n",
       " 'EYE052 slice 35 black.tif',\n",
       " 'EYE019 slice 23 black.tif',\n",
       " 'EYE014 slice 19 black.tif',\n",
       " 'EYE030 slice 43 black.tif',\n",
       " 'EYE050 slice 3 black.tif',\n",
       " 'EYE053 slice 2 black.tif',\n",
       " 'EYE012 slice 18 black.tif',\n",
       " 'EYE003 slice 11 black.tif',\n",
       " 'EYE042 slice 41 black.tif',\n",
       " 'EYE021 slice 4 black.tif',\n",
       " 'EYE038 slice 38 black.tif',\n",
       " 'EYE022 slice 33 black.tif',\n",
       " 'EYE024 slice 43 black.tif',\n",
       " 'EYE007 slice 3 black.tif',\n",
       " 'EYE045 slice 20 black.tif',\n",
       " 'EYE010 slice 45 black.tif',\n",
       " 'EYE004 slice 16 black.tif',\n",
       " 'EYE039 slice 13 black.tif',\n",
       " 'EYE027 slice 42 black.tif',\n",
       " 'EYE041 slice 19 black.tif',\n",
       " 'EYE052 slice 11 black.tif',\n",
       " 'EYE036 slice 39 black.tif',\n",
       " 'EYE028 slice 48 black.tif',\n",
       " 'EYE017 slice 4 black.tif',\n",
       " 'EYE030 slice 23 black.tif',\n",
       " 'EYE006 slice 24 black.tif',\n",
       " 'EYE030 slice 39 black.tif',\n",
       " 'EYE016 slice 46 black.tif',\n",
       " 'EYE024 slice 18 black.tif',\n",
       " 'EYE052 slice 27 black.tif',\n",
       " 'EYE007 slice 17 black.tif',\n",
       " 'EYE003 slice 40 black.tif',\n",
       " 'EYE024 slice 31 black.tif',\n",
       " 'EYE014 slice 1 black.tif',\n",
       " 'EYE041 slice 26 black.tif',\n",
       " 'EYE005 slice 45 black.tif',\n",
       " 'EYE017 slice 2 black.tif',\n",
       " 'EYE026 slice 45 black.tif',\n",
       " 'EYE008 slice 28 black.tif',\n",
       " 'EYE020 slice 9 black.tif',\n",
       " 'EYE010 slice 41 black.tif',\n",
       " 'EYE024 slice 25 black.tif',\n",
       " 'EYE032 slice 36 black.tif',\n",
       " 'EYE003 slice 24 black.tif',\n",
       " 'EYE021 slice 34 black.tif',\n",
       " 'EYE049 slice 14 black.tif',\n",
       " 'EYE043 slice 34 black.tif',\n",
       " 'EYE038 slice 44 black.tif',\n",
       " 'EYE025 slice 48 black.tif',\n",
       " 'EYE048 slice 6 black.tif',\n",
       " 'EYE002 slice 49 black.tif',\n",
       " 'EYE007 slice 10 black.tif',\n",
       " 'EYE001 slice 26 black.tif',\n",
       " 'EYE022 slice 5 black.tif',\n",
       " 'EYE049 slice 21 black.tif',\n",
       " 'EYE027 slice 35 black.tif',\n",
       " 'EYE035 slice 23 black.tif',\n",
       " 'EYE051 slice 4 black.tif',\n",
       " 'EYE010 slice 31 black.tif',\n",
       " 'EYE038 slice 14 black.tif',\n",
       " 'EYE053 slice 47 black.tif',\n",
       " 'EYE039 slice 11 black.tif',\n",
       " 'EYE004 slice 18 black.tif',\n",
       " 'EYE053 slice 33 black.tif',\n",
       " 'EYE044 slice 16 black.tif',\n",
       " 'EYE032 slice 6 black.tif',\n",
       " 'EYE051 slice 14 black.tif',\n",
       " 'EYE010 slice 46 black.tif',\n",
       " 'EYE028 slice 14 black.tif',\n",
       " 'EYE013 slice 21 black.tif',\n",
       " 'EYE046 slice 14 black.tif',\n",
       " 'EYE034 slice 20 black.tif',\n",
       " 'EYE005 slice 3 black.tif',\n",
       " 'EYE037 slice 4 black.tif',\n",
       " 'EYE013 slice 34 black.tif',\n",
       " 'EYE024 slice 21 black.tif',\n",
       " 'EYE048 slice 10 black.tif',\n",
       " 'EYE024 slice 15 black.tif',\n",
       " 'EYE035 slice 29 black.tif',\n",
       " 'EYE049 slice 45 black.tif',\n",
       " 'EYE053 slice 49 black.tif',\n",
       " 'EYE018 slice 15 black.tif',\n",
       " 'EYE027 slice 39 black.tif',\n",
       " 'EYE049 slice 29 black.tif',\n",
       " 'EYE013 slice 46 black.tif',\n",
       " 'EYE020 slice 40 black.tif',\n",
       " 'EYE031 slice 10 black.tif',\n",
       " 'EYE017 slice 23 black.tif',\n",
       " 'EYE021 slice 32 black.tif',\n",
       " 'EYE001 slice 17 black.tif',\n",
       " 'EYE005 slice 39 black.tif',\n",
       " 'EYE030 slice 19 black.tif',\n",
       " 'EYE051 slice 44 black.tif',\n",
       " 'EYE013 slice 22 black.tif',\n",
       " 'EYE020 slice 13 black.tif',\n",
       " 'EYE034 slice 12 black.tif',\n",
       " 'EYE008 slice 18 black.tif',\n",
       " 'EYE034 slice 9 black.tif',\n",
       " 'EYE039 slice 16 black.tif',\n",
       " 'EYE051 slice 21 black.tif',\n",
       " 'EYE040 slice 43 black.tif',\n",
       " 'EYE043 slice 38 black.tif',\n",
       " 'EYE024 slice 44 black.tif',\n",
       " 'EYE013 slice 2 black.tif',\n",
       " 'EYE023 slice 6 black.tif',\n",
       " 'EYE009 slice 39 black.tif',\n",
       " 'EYE005 slice 26 black.tif',\n",
       " 'EYE051 slice 17 black.tif',\n",
       " 'EYE011 slice 38 black.tif',\n",
       " 'EYE032 slice 47 black.tif',\n",
       " 'EYE034 slice 30 black.tif',\n",
       " 'EYE016 slice 20 black.tif',\n",
       " 'EYE028 slice 29 black.tif',\n",
       " 'EYE050 slice 32 black.tif',\n",
       " 'EYE046 slice 30 black.tif',\n",
       " 'EYE039 slice 24 black.tif',\n",
       " 'EYE052 slice 15 black.tif',\n",
       " 'EYE043 slice 37 black.tif',\n",
       " 'EYE036 slice 42 black.tif',\n",
       " 'EYE014 slice 34 black.tif',\n",
       " 'EYE043 slice 18 black.tif',\n",
       " 'EYE003 slice 8 black.tif',\n",
       " 'EYE041 slice 41 black.tif',\n",
       " 'EYE038 slice 40 black.tif',\n",
       " 'EYE025 slice 2 black.tif',\n",
       " 'EYE028 slice 18 black.tif',\n",
       " 'EYE024 slice 14 black.tif',\n",
       " 'EYE011 slice 17 black.tif',\n",
       " 'EYE003 slice 20 black.tif',\n",
       " 'EYE019 slice 34 black.tif',\n",
       " 'EYE007 slice 27 black.tif',\n",
       " 'EYE053 slice 16 black.tif',\n",
       " 'EYE013 slice 11 black.tif',\n",
       " 'EYE026 slice 20 black.tif',\n",
       " 'EYE038 slice 16 black.tif',\n",
       " 'EYE003 slice 32 black.tif',\n",
       " 'EYE031 slice 23 black.tif',\n",
       " 'EYE031 slice 14 black.tif',\n",
       " 'EYE044 slice 46 black.tif',\n",
       " 'EYE046 slice 28 black.tif',\n",
       " 'EYE044 slice 17 black.tif',\n",
       " 'EYE047 slice 28 black.tif',\n",
       " 'EYE040 slice 25 black.tif',\n",
       " 'EYE046 slice 38 black.tif',\n",
       " 'EYE021 slice 19 black.tif',\n",
       " 'EYE010 slice 47 black.tif',\n",
       " 'EYE002 slice 26 black.tif',\n",
       " 'EYE043 slice 21 black.tif',\n",
       " 'EYE010 slice 39 black.tif',\n",
       " 'EYE003 slice 15 black.tif',\n",
       " 'EYE051 slice 34 black.tif',\n",
       " 'EYE020 slice 6 black.tif',\n",
       " 'EYE037 slice 26 black.tif',\n",
       " 'EYE040 slice 31 black.tif',\n",
       " 'EYE024 slice 11 black.tif',\n",
       " 'EYE052 slice 34 black.tif',\n",
       " 'EYE003 slice 13 black.tif',\n",
       " 'EYE026 slice 11 black.tif',\n",
       " 'EYE043 slice 13 black.tif',\n",
       " 'EYE020 slice 32 black.tif',\n",
       " 'EYE023 slice 18 black.tif',\n",
       " 'EYE022 slice 44 black.tif',\n",
       " 'EYE022 slice 38 black.tif',\n",
       " 'EYE013 slice 24 black.tif',\n",
       " 'EYE046 slice 12 black.tif',\n",
       " 'EYE014 slice 45 black.tif',\n",
       " 'EYE016 slice 35 black.tif',\n",
       " 'EYE019 slice 41 black.tif',\n",
       " 'EYE018 slice 41 black.tif',\n",
       " 'EYE049 slice 2 black.tif',\n",
       " 'EYE006 slice 20 black.tif',\n",
       " 'EYE004 slice 7 black.tif',\n",
       " 'EYE035 slice 7 black.tif',\n",
       " 'EYE022 slice 21 black.tif',\n",
       " 'EYE005 slice 38 black.tif',\n",
       " 'EYE003 slice 30 black.tif',\n",
       " 'EYE029 slice 28 black.tif',\n",
       " 'EYE041 slice 32 black.tif',\n",
       " 'EYE036 slice 2 black.tif',\n",
       " 'EYE049 slice 24 black.tif',\n",
       " 'EYE035 slice 19 black.tif',\n",
       " 'EYE009 slice 5 black.tif',\n",
       " 'EYE024 slice 16 black.tif',\n",
       " 'EYE021 slice 3 black.tif',\n",
       " 'EYE053 slice 28 black.tif',\n",
       " 'EYE029 slice 49 black.tif',\n",
       " 'EYE035 slice 14 black.tif',\n",
       " 'EYE029 slice 6 black.tif',\n",
       " 'EYE044 slice 31 black.tif',\n",
       " 'EYE043 slice 27 black.tif',\n",
       " 'EYE006 slice 19 black.tif',\n",
       " 'EYE044 slice 25 black.tif',\n",
       " 'EYE014 slice 24 black.tif',\n",
       " 'EYE002 slice 42 black.tif',\n",
       " 'EYE013 slice 38 black.tif',\n",
       " 'EYE034 slice 10 black.tif',\n",
       " 'EYE019 slice 43 black.tif',\n",
       " 'EYE051 slice 26 black.tif',\n",
       " 'EYE025 slice 45 black.tif',\n",
       " 'EYE038 slice 45 black.tif',\n",
       " 'EYE003 slice 26 black.tif',\n",
       " 'EYE048 slice 13 black.tif',\n",
       " 'EYE020 slice 28 black.tif',\n",
       " 'EYE024 slice 48 black.tif',\n",
       " 'EYE011 slice 44 black.tif',\n",
       " 'EYE040 slice 32 black.tif',\n",
       " 'EYE053 slice 36 black.tif',\n",
       " 'EYE028 slice 26 black.tif',\n",
       " 'EYE022 slice 26 black.tif',\n",
       " 'EYE029 slice 41 black.tif',\n",
       " 'EYE019 slice 26 black.tif',\n",
       " 'EYE024 slice 6 black.tif',\n",
       " 'EYE001 slice 36 black.tif',\n",
       " 'EYE010 slice 32 black.tif',\n",
       " 'EYE031 slice 24 black.tif',\n",
       " 'EYE013 slice 4 black.tif',\n",
       " 'EYE027 slice 25 black.tif',\n",
       " 'EYE036 slice 18 black.tif',\n",
       " 'EYE050 slice 42 black.tif',\n",
       " 'EYE034 slice 32 black.tif',\n",
       " 'EYE019 slice 44 black.tif',\n",
       " 'EYE004 slice 13 black.tif',\n",
       " 'EYE010 slice 36 black.tif',\n",
       " 'EYE011 slice 31 black.tif',\n",
       " 'EYE030 slice 5 black.tif',\n",
       " 'EYE003 slice 21 black.tif',\n",
       " 'EYE041 slice 42 black.tif',\n",
       " 'EYE021 slice 21 black.tif',\n",
       " 'EYE053 slice 22 black.tif',\n",
       " 'EYE036 slice 14 black.tif',\n",
       " 'EYE047 slice 45 black.tif',\n",
       " 'EYE022 slice 17 black.tif',\n",
       " 'EYE010 slice 18 black.tif',\n",
       " 'EYE046 slice 21 black.tif',\n",
       " 'EYE014 slice 32 black.tif',\n",
       " 'EYE048 slice 16 black.tif',\n",
       " 'EYE029 slice 44 black.tif',\n",
       " 'EYE005 slice 12 black.tif',\n",
       " 'EYE012 slice 15 black.tif',\n",
       " 'EYE052 slice 45 black.tif',\n",
       " 'EYE019 slice 18 black.tif',\n",
       " 'EYE045 slice 17 black.tif',\n",
       " 'EYE039 slice 40 black.tif',\n",
       " 'EYE012 slice 23 black.tif',\n",
       " 'EYE002 slice 21 black.tif',\n",
       " 'EYE017 slice 38 black.tif',\n",
       " 'EYE020 slice 45 black.tif',\n",
       " 'EYE041 slice 36 black.tif',\n",
       " 'EYE015 slice 37 black.tif',\n",
       " 'EYE012 slice 31 black.tif',\n",
       " 'EYE033 slice 10 black.tif',\n",
       " 'EYE037 slice 39 black.tif',\n",
       " 'EYE022 slice 4 black.tif',\n",
       " 'EYE050 slice 31 black.tif',\n",
       " 'EYE043 slice 15 black.tif',\n",
       " 'EYE041 slice 35 black.tif',\n",
       " 'EYE050 slice 12 black.tif',\n",
       " 'EYE010 slice 9 black.tif',\n",
       " 'EYE012 slice 14 black.tif',\n",
       " 'EYE033 slice 32 black.tif',\n",
       " 'EYE027 slice 37 black.tif',\n",
       " 'EYE014 slice 4 black.tif',\n",
       " 'EYE016 slice 33 black.tif',\n",
       " 'EYE030 slice 46 black.tif',\n",
       " 'EYE003 slice 5 black.tif',\n",
       " 'EYE048 slice 3 black.tif',\n",
       " 'EYE017 slice 45 black.tif',\n",
       " 'EYE053 slice 34 black.tif',\n",
       " 'EYE001 slice 2 black.tif',\n",
       " 'EYE041 slice 27 black.tif',\n",
       " 'EYE040 slice 19 black.tif',\n",
       " 'EYE043 slice 5 black.tif',\n",
       " 'EYE049 slice 11 black.tif',\n",
       " 'EYE009 slice 7 black.tif',\n",
       " 'EYE004 slice 49 black.tif',\n",
       " 'EYE016 slice 31 black.tif',\n",
       " 'EYE025 slice 11 black.tif',\n",
       " 'EYE046 slice 22 black.tif',\n",
       " 'EYE015 slice 25 black.tif',\n",
       " 'EYE006 slice 44 black.tif',\n",
       " 'EYE048 slice 4 black.tif',\n",
       " 'EYE035 slice 27 black.tif',\n",
       " 'EYE005 slice 30 black.tif',\n",
       " 'EYE047 slice 33 black.tif',\n",
       " 'EYE015 slice 1 black.tif',\n",
       " 'EYE004 slice 30 black.tif',\n",
       " 'EYE004 slice 39 black.tif',\n",
       " 'EYE018 slice 30 black.tif',\n",
       " 'EYE013 slice 35 black.tif',\n",
       " 'EYE022 slice 2 black.tif',\n",
       " 'EYE050 slice 35 black.tif',\n",
       " 'EYE004 slice 5 black.tif',\n",
       " 'EYE050 slice 21 black.tif',\n",
       " 'EYE020 slice 38 black.tif',\n",
       " 'EYE049 slice 22 black.tif',\n",
       " 'EYE030 slice 48 black.tif',\n",
       " 'EYE050 slice 9 black.tif',\n",
       " 'EYE043 slice 47 black.tif',\n",
       " 'EYE028 slice 3 black.tif',\n",
       " 'EYE026 slice 46 black.tif',\n",
       " 'EYE036 slice 45 black.tif',\n",
       " 'EYE014 slice 40 black.tif',\n",
       " 'EYE009 slice 24 black.tif',\n",
       " 'EYE016 slice 41 black.tif',\n",
       " 'EYE039 slice 20 black.tif',\n",
       " 'EYE035 slice 40 black.tif',\n",
       " 'EYE047 slice 29 black.tif',\n",
       " 'EYE031 slice 41 black.tif',\n",
       " 'EYE052 slice 40 black.tif',\n",
       " 'EYE002 slice 46 black.tif',\n",
       " 'EYE027 slice 33 black.tif',\n",
       " 'EYE046 slice 46 black.tif',\n",
       " 'EYE011 slice 4 black.tif',\n",
       " 'EYE050 slice 25 black.tif',\n",
       " 'EYE043 slice 29 black.tif',\n",
       " 'EYE053 slice 21 black.tif',\n",
       " 'EYE006 slice 41 black.tif',\n",
       " 'EYE009 slice 8 black.tif',\n",
       " 'EYE002 slice 6 black.tif',\n",
       " 'EYE022 slice 9 black.tif',\n",
       " 'EYE005 slice 31 black.tif',\n",
       " 'EYE049 slice 47 black.tif',\n",
       " 'EYE010 slice 1 black.tif',\n",
       " 'EYE045 slice 26 black.tif',\n",
       " 'EYE032 slice 13 black.tif',\n",
       " 'EYE033 slice 37 black.tif',\n",
       " 'EYE051 slice 15 black.tif',\n",
       " 'EYE013 slice 31 black.tif',\n",
       " 'EYE020 slice 5 black.tif',\n",
       " 'EYE010 slice 5 black.tif',\n",
       " 'EYE014 slice 17 black.tif',\n",
       " 'EYE020 slice 7 black.tif',\n",
       " 'EYE042 slice 37 black.tif',\n",
       " 'EYE017 slice 39 black.tif',\n",
       " 'EYE024 slice 46 black.tif',\n",
       " 'EYE005 slice 46 black.tif',\n",
       " 'EYE039 slice 23 black.tif',\n",
       " 'EYE011 slice 35 black.tif',\n",
       " 'EYE020 slice 4 black.tif',\n",
       " 'EYE047 slice 37 black.tif',\n",
       " 'EYE046 slice 41 black.tif',\n",
       " 'EYE045 slice 1 black.tif',\n",
       " 'EYE001 slice 19 black.tif',\n",
       " 'EYE005 slice 28 black.tif',\n",
       " 'EYE045 slice 39 black.tif',\n",
       " 'EYE033 slice 33 black.tif',\n",
       " 'EYE003 slice 2 black.tif',\n",
       " 'EYE018 slice 32 black.tif',\n",
       " 'EYE011 slice 32 black.tif',\n",
       " 'EYE041 slice 9 black.tif',\n",
       " 'EYE039 slice 2 black.tif',\n",
       " 'EYE019 slice 35 black.tif',\n",
       " 'EYE053 slice 42 black.tif',\n",
       " 'EYE045 slice 31 black.tif',\n",
       " 'EYE017 slice 6 black.tif',\n",
       " 'EYE019 slice 20 black.tif',\n",
       " 'EYE006 slice 5 black.tif',\n",
       " 'EYE034 slice 24 black.tif',\n",
       " 'EYE023 slice 22 black.tif',\n",
       " 'EYE012 slice 47 black.tif',\n",
       " 'EYE032 slice 7 black.tif',\n",
       " 'EYE038 slice 11 black.tif',\n",
       " 'EYE033 slice 14 black.tif',\n",
       " 'EYE038 slice 13 black.tif',\n",
       " 'EYE033 slice 36 black.tif',\n",
       " 'EYE016 slice 42 black.tif',\n",
       " 'EYE045 slice 25 black.tif',\n",
       " 'EYE012 slice 39 black.tif',\n",
       " 'EYE019 slice 7 black.tif',\n",
       " 'EYE048 slice 29 black.tif',\n",
       " 'EYE051 slice 18 black.tif',\n",
       " 'EYE037 slice 9 black.tif',\n",
       " 'EYE026 slice 27 black.tif',\n",
       " 'EYE038 slice 20 black.tif',\n",
       " 'EYE048 slice 14 black.tif',\n",
       " 'EYE045 slice 6 black.tif',\n",
       " 'EYE010 slice 22 black.tif',\n",
       " 'EYE018 slice 49 black.tif',\n",
       " 'EYE015 slice 16 black.tif',\n",
       " 'EYE005 slice 7 black.tif',\n",
       " 'EYE013 slice 5 black.tif',\n",
       " 'EYE051 slice 36 black.tif',\n",
       " 'EYE009 slice 46 black.tif',\n",
       " 'EYE014 slice 30 black.tif',\n",
       " 'EYE035 slice 41 black.tif',\n",
       " 'EYE044 slice 7 black.tif',\n",
       " 'EYE019 slice 19 black.tif',\n",
       " 'EYE007 slice 19 black.tif',\n",
       " 'EYE025 slice 26 black.tif',\n",
       " 'EYE039 slice 15 black.tif',\n",
       " 'EYE037 slice 20 black.tif',\n",
       " 'EYE016 slice 16 black.tif',\n",
       " 'EYE013 slice 33 black.tif',\n",
       " 'EYE009 slice 20 black.tif',\n",
       " 'EYE050 slice 17 black.tif',\n",
       " 'EYE036 slice 26 black.tif',\n",
       " ...]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"TIFF black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_285 (Conv2D)            (None, 256, 256, 20  200         ['input_16[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_270 (Batch  (None, 256, 256, 20  80         ['conv2d_285[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_286 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_270[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_271 (Batch  (None, 256, 256, 20  80         ['conv2d_286[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_60 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_271[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_120 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_60[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_287 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_120[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_272 (Batch  (None, 128, 128, 40  160        ['conv2d_287[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_288 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_272[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_273 (Batch  (None, 128, 128, 40  160        ['conv2d_288[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_61 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_273[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_121 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_61[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_289 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_121[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_274 (Batch  (None, 64, 64, 80)  320         ['conv2d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_290 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_274[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_275 (Batch  (None, 64, 64, 80)  320         ['conv2d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_62 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_275[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_122 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_62[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_291 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_122[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_276 (Batch  (None, 32, 32, 160)  640        ['conv2d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_292 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_276[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_277 (Batch  (None, 32, 32, 160)  640        ['conv2d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_63 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_277[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_123 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_63[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_293 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_123[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_278 (Batch  (None, 16, 16, 320)  1280       ['conv2d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_294 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_278[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_279 (Batch  (None, 16, 16, 320)  1280       ['conv2d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_60 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_279[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_60 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_60[0][0]',    \n",
      "                                                                  'batch_normalization_277[0][0]']\n",
      "                                                                                                  \n",
      " dropout_124 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_60[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_295 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_124[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_280 (Batch  (None, 32, 32, 160)  640        ['conv2d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_296 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_280[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_281 (Batch  (None, 32, 32, 160)  640        ['conv2d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_61 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_281[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_61 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_61[0][0]',    \n",
      "                                                                  'batch_normalization_275[0][0]']\n",
      "                                                                                                  \n",
      " dropout_125 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_61[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_297 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_125[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_282 (Batch  (None, 64, 64, 80)  320         ['conv2d_297[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_298 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_282[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_283 (Batch  (None, 64, 64, 80)  320         ['conv2d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_62 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_283[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_62 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_62[0][0]',    \n",
      "                                )                                 'batch_normalization_273[0][0]']\n",
      "                                                                                                  \n",
      " dropout_126 (Dropout)          (None, 128, 128, 80  0           ['concatenate_62[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_299 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_126[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_284 (Batch  (None, 128, 128, 40  160        ['conv2d_299[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_300 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_284[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_285 (Batch  (None, 128, 128, 40  160        ['conv2d_300[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_63 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_285[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_63 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_63[0][0]',    \n",
      "                                )                                 'batch_normalization_271[0][0]']\n",
      "                                                                                                  \n",
      " dropout_127 (Dropout)          (None, 256, 256, 40  0           ['concatenate_63[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_301 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_127[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_286 (Batch  (None, 256, 256, 20  80         ['conv2d_301[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_302 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_286[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_287 (Batch  (None, 256, 256, 20  80         ['conv2d_302[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_303 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_287[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_304 (Conv2D)            (None, 256, 256, 20  200         ['input_17[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_288 (Batch  (None, 256, 256, 20  80         ['conv2d_304[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_305 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_288[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_289 (Batch  (None, 256, 256, 20  80         ['conv2d_305[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_64 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_289[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_128 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_64[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_306 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_128[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_290 (Batch  (None, 128, 128, 40  160        ['conv2d_306[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_307 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_290[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_291 (Batch  (None, 128, 128, 40  160        ['conv2d_307[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_65 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_291[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_129 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_65[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_308 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_129[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_292 (Batch  (None, 64, 64, 80)  320         ['conv2d_308[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_309 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_292[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_293 (Batch  (None, 64, 64, 80)  320         ['conv2d_309[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_66 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_293[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_130 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_66[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_310 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_130[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_294 (Batch  (None, 32, 32, 160)  640        ['conv2d_310[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_311 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_294[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_295 (Batch  (None, 32, 32, 160)  640        ['conv2d_311[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_67 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_295[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_131 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_67[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_312 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_131[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_296 (Batch  (None, 16, 16, 320)  1280       ['conv2d_312[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_313 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_296[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_297 (Batch  (None, 16, 16, 320)  1280       ['conv2d_313[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_64 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_297[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_64 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_64[0][0]',    \n",
      "                                                                  'batch_normalization_295[0][0]']\n",
      "                                                                                                  \n",
      " dropout_132 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_64[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_314 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_132[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_298 (Batch  (None, 32, 32, 160)  640        ['conv2d_314[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_315 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_298[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_299 (Batch  (None, 32, 32, 160)  640        ['conv2d_315[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_65 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_299[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_65 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_65[0][0]',    \n",
      "                                                                  'batch_normalization_293[0][0]']\n",
      "                                                                                                  \n",
      " dropout_133 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_65[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_316 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_133[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_300 (Batch  (None, 64, 64, 80)  320         ['conv2d_316[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_317 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_300[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_301 (Batch  (None, 64, 64, 80)  320         ['conv2d_317[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_66 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_301[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_66 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_66[0][0]',    \n",
      "                                )                                 'batch_normalization_291[0][0]']\n",
      "                                                                                                  \n",
      " dropout_134 (Dropout)          (None, 128, 128, 80  0           ['concatenate_66[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_318 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_134[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_302 (Batch  (None, 128, 128, 40  160        ['conv2d_318[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_319 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_302[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_303 (Batch  (None, 128, 128, 40  160        ['conv2d_319[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_67 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_303[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_67 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_67[0][0]',    \n",
      "                                )                                 'batch_normalization_289[0][0]']\n",
      "                                                                                                  \n",
      " dropout_135 (Dropout)          (None, 256, 256, 40  0           ['concatenate_67[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_320 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_135[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_304 (Batch  (None, 256, 256, 20  80         ['conv2d_320[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_321 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_304[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_305 (Batch  (None, 256, 256, 20  80         ['conv2d_321[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_322 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_305[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_18 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_323 (Conv2D)            (None, 256, 256, 20  200         ['input_18[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_306 (Batch  (None, 256, 256, 20  80         ['conv2d_323[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_324 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_306[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_307 (Batch  (None, 256, 256, 20  80         ['conv2d_324[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_68 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_307[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_136 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_68[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_325 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_136[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_308 (Batch  (None, 128, 128, 40  160        ['conv2d_325[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_326 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_308[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_309 (Batch  (None, 128, 128, 40  160        ['conv2d_326[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_69 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_309[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_137 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_69[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_327 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_137[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_310 (Batch  (None, 64, 64, 80)  320         ['conv2d_327[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_328 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_310[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_311 (Batch  (None, 64, 64, 80)  320         ['conv2d_328[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_70 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_311[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_138 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_70[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_329 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_138[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_312 (Batch  (None, 32, 32, 160)  640        ['conv2d_329[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_330 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_312[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_313 (Batch  (None, 32, 32, 160)  640        ['conv2d_330[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_71 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_313[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_139 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_71[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_331 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_139[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_314 (Batch  (None, 16, 16, 320)  1280       ['conv2d_331[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_332 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_314[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_315 (Batch  (None, 16, 16, 320)  1280       ['conv2d_332[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_68 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_315[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_68 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_68[0][0]',    \n",
      "                                                                  'batch_normalization_313[0][0]']\n",
      "                                                                                                  \n",
      " dropout_140 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_68[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_333 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_140[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_316 (Batch  (None, 32, 32, 160)  640        ['conv2d_333[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_334 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_316[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_317 (Batch  (None, 32, 32, 160)  640        ['conv2d_334[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_69 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_317[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_69 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_69[0][0]',    \n",
      "                                                                  'batch_normalization_311[0][0]']\n",
      "                                                                                                  \n",
      " dropout_141 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_69[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_335 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_141[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_318 (Batch  (None, 64, 64, 80)  320         ['conv2d_335[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_336 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_318[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_319 (Batch  (None, 64, 64, 80)  320         ['conv2d_336[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_70 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_319[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_70 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_70[0][0]',    \n",
      "                                )                                 'batch_normalization_309[0][0]']\n",
      "                                                                                                  \n",
      " dropout_142 (Dropout)          (None, 128, 128, 80  0           ['concatenate_70[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_337 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_142[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_320 (Batch  (None, 128, 128, 40  160        ['conv2d_337[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_338 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_320[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_321 (Batch  (None, 128, 128, 40  160        ['conv2d_338[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_71 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_321[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_71 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_71[0][0]',    \n",
      "                                )                                 'batch_normalization_307[0][0]']\n",
      "                                                                                                  \n",
      " dropout_143 (Dropout)          (None, 256, 256, 40  0           ['concatenate_71[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_339 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_143[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_322 (Batch  (None, 256, 256, 20  80         ['conv2d_339[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_340 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_322[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_323 (Batch  (None, 256, 256, 20  80         ['conv2d_340[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_341 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_323[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_19 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_342 (Conv2D)            (None, 256, 256, 20  200         ['input_19[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_324 (Batch  (None, 256, 256, 20  80         ['conv2d_342[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_343 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_324[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_325 (Batch  (None, 256, 256, 20  80         ['conv2d_343[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_72 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_325[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_144 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_72[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_344 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_144[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_326 (Batch  (None, 128, 128, 40  160        ['conv2d_344[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_345 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_326[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_327 (Batch  (None, 128, 128, 40  160        ['conv2d_345[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_73 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_327[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_145 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_73[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_346 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_145[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_328 (Batch  (None, 64, 64, 80)  320         ['conv2d_346[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_347 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_328[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_329 (Batch  (None, 64, 64, 80)  320         ['conv2d_347[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_74 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_329[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_74[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_348 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_146[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_330 (Batch  (None, 32, 32, 160)  640        ['conv2d_348[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_349 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_330[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_331 (Batch  (None, 32, 32, 160)  640        ['conv2d_349[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_75 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_331[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_75[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_350 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_332 (Batch  (None, 16, 16, 320)  1280       ['conv2d_350[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_351 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_332[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_333 (Batch  (None, 16, 16, 320)  1280       ['conv2d_351[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_72 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_333[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_72 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_72[0][0]',    \n",
      "                                                                  'batch_normalization_331[0][0]']\n",
      "                                                                                                  \n",
      " dropout_148 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_72[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_352 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_148[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_334 (Batch  (None, 32, 32, 160)  640        ['conv2d_352[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_353 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_334[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_335 (Batch  (None, 32, 32, 160)  640        ['conv2d_353[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_73 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_335[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_73 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_73[0][0]',    \n",
      "                                                                  'batch_normalization_329[0][0]']\n",
      "                                                                                                  \n",
      " dropout_149 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_73[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_354 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_149[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_336 (Batch  (None, 64, 64, 80)  320         ['conv2d_354[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_355 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_336[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_337 (Batch  (None, 64, 64, 80)  320         ['conv2d_355[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_74 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_337[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_74 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_74[0][0]',    \n",
      "                                )                                 'batch_normalization_327[0][0]']\n",
      "                                                                                                  \n",
      " dropout_150 (Dropout)          (None, 128, 128, 80  0           ['concatenate_74[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_356 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_150[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_338 (Batch  (None, 128, 128, 40  160        ['conv2d_356[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_357 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_338[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_339 (Batch  (None, 128, 128, 40  160        ['conv2d_357[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_75 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_339[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_75 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_75[0][0]',    \n",
      "                                )                                 'batch_normalization_325[0][0]']\n",
      "                                                                                                  \n",
      " dropout_151 (Dropout)          (None, 256, 256, 40  0           ['concatenate_75[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_358 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_151[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_340 (Batch  (None, 256, 256, 20  80         ['conv2d_358[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_359 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_340[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_341 (Batch  (None, 256, 256, 20  80         ['conv2d_359[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_360 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_341[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_20 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_361 (Conv2D)            (None, 256, 256, 20  200         ['input_20[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_342 (Batch  (None, 256, 256, 20  80         ['conv2d_361[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_362 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_342[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_343 (Batch  (None, 256, 256, 20  80         ['conv2d_362[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_76 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_343[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_152 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_76[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_363 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_152[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_344 (Batch  (None, 128, 128, 40  160        ['conv2d_363[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_364 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_344[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_345 (Batch  (None, 128, 128, 40  160        ['conv2d_364[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_77 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_345[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_153 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_77[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_365 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_153[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_346 (Batch  (None, 64, 64, 80)  320         ['conv2d_365[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_366 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_346[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_347 (Batch  (None, 64, 64, 80)  320         ['conv2d_366[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_78 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_347[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_154 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_78[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_367 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_154[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_348 (Batch  (None, 32, 32, 160)  640        ['conv2d_367[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_368 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_348[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_349 (Batch  (None, 32, 32, 160)  640        ['conv2d_368[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_79 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_349[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_155 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_79[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_369 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_155[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_350 (Batch  (None, 16, 16, 320)  1280       ['conv2d_369[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_370 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_350[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_351 (Batch  (None, 16, 16, 320)  1280       ['conv2d_370[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_76 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_351[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_76 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_76[0][0]',    \n",
      "                                                                  'batch_normalization_349[0][0]']\n",
      "                                                                                                  \n",
      " dropout_156 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_76[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_371 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_156[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_352 (Batch  (None, 32, 32, 160)  640        ['conv2d_371[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_372 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_352[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_353 (Batch  (None, 32, 32, 160)  640        ['conv2d_372[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_77 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_353[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_77 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_77[0][0]',    \n",
      "                                                                  'batch_normalization_347[0][0]']\n",
      "                                                                                                  \n",
      " dropout_157 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_77[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_373 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_157[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_354 (Batch  (None, 64, 64, 80)  320         ['conv2d_373[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_374 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_354[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_355 (Batch  (None, 64, 64, 80)  320         ['conv2d_374[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_78 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_355[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_78 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_78[0][0]',    \n",
      "                                )                                 'batch_normalization_345[0][0]']\n",
      "                                                                                                  \n",
      " dropout_158 (Dropout)          (None, 128, 128, 80  0           ['concatenate_78[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_375 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_158[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_356 (Batch  (None, 128, 128, 40  160        ['conv2d_375[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_376 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_356[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_357 (Batch  (None, 128, 128, 40  160        ['conv2d_376[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_79 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_357[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_79 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_79[0][0]',    \n",
      "                                )                                 'batch_normalization_343[0][0]']\n",
      "                                                                                                  \n",
      " dropout_159 (Dropout)          (None, 256, 256, 40  0           ['concatenate_79[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_377 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_159[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_358 (Batch  (None, 256, 256, 20  80         ['conv2d_377[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_378 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_358[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_359 (Batch  (None, 256, 256, 20  80         ['conv2d_378[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_379 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_359[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_21 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_380 (Conv2D)            (None, 256, 256, 20  200         ['input_21[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_360 (Batch  (None, 256, 256, 20  80         ['conv2d_380[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_381 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_360[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_361 (Batch  (None, 256, 256, 20  80         ['conv2d_381[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_80 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_361[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_160 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_80[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_382 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_160[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_362 (Batch  (None, 128, 128, 40  160        ['conv2d_382[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_383 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_362[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_363 (Batch  (None, 128, 128, 40  160        ['conv2d_383[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_81 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_363[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_161 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_81[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_384 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_161[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_364 (Batch  (None, 64, 64, 80)  320         ['conv2d_384[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_385 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_364[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_365 (Batch  (None, 64, 64, 80)  320         ['conv2d_385[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_82 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_365[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_162 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_82[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_386 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_162[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_366 (Batch  (None, 32, 32, 160)  640        ['conv2d_386[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_387 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_366[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_367 (Batch  (None, 32, 32, 160)  640        ['conv2d_387[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_83 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_367[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_163 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_83[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_388 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_163[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_368 (Batch  (None, 16, 16, 320)  1280       ['conv2d_388[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_389 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_368[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_369 (Batch  (None, 16, 16, 320)  1280       ['conv2d_389[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_80 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_369[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_80 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_80[0][0]',    \n",
      "                                                                  'batch_normalization_367[0][0]']\n",
      "                                                                                                  \n",
      " dropout_164 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_80[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_390 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_164[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_370 (Batch  (None, 32, 32, 160)  640        ['conv2d_390[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_391 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_370[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_371 (Batch  (None, 32, 32, 160)  640        ['conv2d_391[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_81 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_371[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_81 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_81[0][0]',    \n",
      "                                                                  'batch_normalization_365[0][0]']\n",
      "                                                                                                  \n",
      " dropout_165 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_81[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_392 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_165[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_372 (Batch  (None, 64, 64, 80)  320         ['conv2d_392[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_393 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_372[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_373 (Batch  (None, 64, 64, 80)  320         ['conv2d_393[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_82 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_373[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_82 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_82[0][0]',    \n",
      "                                )                                 'batch_normalization_363[0][0]']\n",
      "                                                                                                  \n",
      " dropout_166 (Dropout)          (None, 128, 128, 80  0           ['concatenate_82[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_394 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_166[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_374 (Batch  (None, 128, 128, 40  160        ['conv2d_394[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_395 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_374[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_375 (Batch  (None, 128, 128, 40  160        ['conv2d_395[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_83 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_375[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_83 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_83[0][0]',    \n",
      "                                )                                 'batch_normalization_361[0][0]']\n",
      "                                                                                                  \n",
      " dropout_167 (Dropout)          (None, 256, 256, 40  0           ['concatenate_83[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_396 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_167[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_376 (Batch  (None, 256, 256, 20  80         ['conv2d_396[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_397 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_376[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_377 (Batch  (None, 256, 256, 20  80         ['conv2d_397[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_398 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_377[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_22 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_399 (Conv2D)            (None, 256, 256, 20  200         ['input_22[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_378 (Batch  (None, 256, 256, 20  80         ['conv2d_399[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_400 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_378[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_379 (Batch  (None, 256, 256, 20  80         ['conv2d_400[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_84 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_379[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_168 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_84[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_401 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_168[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_380 (Batch  (None, 128, 128, 40  160        ['conv2d_401[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_402 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_380[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_381 (Batch  (None, 128, 128, 40  160        ['conv2d_402[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_85 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_381[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_169 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_85[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_403 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_169[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_382 (Batch  (None, 64, 64, 80)  320         ['conv2d_403[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_404 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_382[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_383 (Batch  (None, 64, 64, 80)  320         ['conv2d_404[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_86 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_383[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_170 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_86[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_405 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_170[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_384 (Batch  (None, 32, 32, 160)  640        ['conv2d_405[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_406 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_384[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_385 (Batch  (None, 32, 32, 160)  640        ['conv2d_406[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_87 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_385[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_171 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_87[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_407 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_171[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_386 (Batch  (None, 16, 16, 320)  1280       ['conv2d_407[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_408 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_386[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_387 (Batch  (None, 16, 16, 320)  1280       ['conv2d_408[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_84 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_387[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_84 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_84[0][0]',    \n",
      "                                                                  'batch_normalization_385[0][0]']\n",
      "                                                                                                  \n",
      " dropout_172 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_84[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_409 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_172[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_388 (Batch  (None, 32, 32, 160)  640        ['conv2d_409[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_410 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_388[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_389 (Batch  (None, 32, 32, 160)  640        ['conv2d_410[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_85 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_389[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_85 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_85[0][0]',    \n",
      "                                                                  'batch_normalization_383[0][0]']\n",
      "                                                                                                  \n",
      " dropout_173 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_85[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_411 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_173[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_390 (Batch  (None, 64, 64, 80)  320         ['conv2d_411[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_412 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_390[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_391 (Batch  (None, 64, 64, 80)  320         ['conv2d_412[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_86 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_391[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_86 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_86[0][0]',    \n",
      "                                )                                 'batch_normalization_381[0][0]']\n",
      "                                                                                                  \n",
      " dropout_174 (Dropout)          (None, 128, 128, 80  0           ['concatenate_86[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_413 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_174[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_392 (Batch  (None, 128, 128, 40  160        ['conv2d_413[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_414 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_392[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_393 (Batch  (None, 128, 128, 40  160        ['conv2d_414[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_87 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_393[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_87 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_87[0][0]',    \n",
      "                                )                                 'batch_normalization_379[0][0]']\n",
      "                                                                                                  \n",
      " dropout_175 (Dropout)          (None, 256, 256, 40  0           ['concatenate_87[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_415 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_175[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_394 (Batch  (None, 256, 256, 20  80         ['conv2d_415[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_416 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_394[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_395 (Batch  (None, 256, 256, 20  80         ['conv2d_416[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_417 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_395[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_23 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_418 (Conv2D)            (None, 256, 256, 20  200         ['input_23[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_396 (Batch  (None, 256, 256, 20  80         ['conv2d_418[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_419 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_396[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_397 (Batch  (None, 256, 256, 20  80         ['conv2d_419[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_88 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_397[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_176 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_88[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_420 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_176[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_398 (Batch  (None, 128, 128, 40  160        ['conv2d_420[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_421 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_398[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_399 (Batch  (None, 128, 128, 40  160        ['conv2d_421[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_89 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_399[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_177 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_89[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_422 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_177[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_400 (Batch  (None, 64, 64, 80)  320         ['conv2d_422[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_423 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_400[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_401 (Batch  (None, 64, 64, 80)  320         ['conv2d_423[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_90 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_401[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_178 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_90[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_424 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_178[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_402 (Batch  (None, 32, 32, 160)  640        ['conv2d_424[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_425 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_402[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_403 (Batch  (None, 32, 32, 160)  640        ['conv2d_425[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_91 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_403[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_179 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_91[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_426 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_179[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_404 (Batch  (None, 16, 16, 320)  1280       ['conv2d_426[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_427 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_404[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_405 (Batch  (None, 16, 16, 320)  1280       ['conv2d_427[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_88 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_405[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_88 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_88[0][0]',    \n",
      "                                                                  'batch_normalization_403[0][0]']\n",
      "                                                                                                  \n",
      " dropout_180 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_88[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_428 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_180[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_406 (Batch  (None, 32, 32, 160)  640        ['conv2d_428[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_429 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_406[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_407 (Batch  (None, 32, 32, 160)  640        ['conv2d_429[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_89 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_407[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_89 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_89[0][0]',    \n",
      "                                                                  'batch_normalization_401[0][0]']\n",
      "                                                                                                  \n",
      " dropout_181 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_89[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_430 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_181[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_408 (Batch  (None, 64, 64, 80)  320         ['conv2d_430[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_431 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_408[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_409 (Batch  (None, 64, 64, 80)  320         ['conv2d_431[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_90 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_409[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_90 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_90[0][0]',    \n",
      "                                )                                 'batch_normalization_399[0][0]']\n",
      "                                                                                                  \n",
      " dropout_182 (Dropout)          (None, 128, 128, 80  0           ['concatenate_90[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_432 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_182[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_410 (Batch  (None, 128, 128, 40  160        ['conv2d_432[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_433 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_410[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_411 (Batch  (None, 128, 128, 40  160        ['conv2d_433[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_91 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_411[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_91 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_91[0][0]',    \n",
      "                                )                                 'batch_normalization_397[0][0]']\n",
      "                                                                                                  \n",
      " dropout_183 (Dropout)          (None, 256, 256, 40  0           ['concatenate_91[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_434 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_183[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_412 (Batch  (None, 256, 256, 20  80         ['conv2d_434[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_435 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_412[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_413 (Batch  (None, 256, 256, 20  80         ['conv2d_435[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_436 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_413[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_24 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_437 (Conv2D)            (None, 256, 256, 20  200         ['input_24[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_414 (Batch  (None, 256, 256, 20  80         ['conv2d_437[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_438 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_414[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_415 (Batch  (None, 256, 256, 20  80         ['conv2d_438[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_92 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_415[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_184 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_92[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_439 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_184[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_416 (Batch  (None, 128, 128, 40  160        ['conv2d_439[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_440 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_416[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_417 (Batch  (None, 128, 128, 40  160        ['conv2d_440[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_93 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_417[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_185 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_93[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_441 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_185[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_418 (Batch  (None, 64, 64, 80)  320         ['conv2d_441[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_442 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_418[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_419 (Batch  (None, 64, 64, 80)  320         ['conv2d_442[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_94 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_419[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_186 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_94[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_443 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_186[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_420 (Batch  (None, 32, 32, 160)  640        ['conv2d_443[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_444 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_420[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_421 (Batch  (None, 32, 32, 160)  640        ['conv2d_444[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_95 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_421[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_187 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_95[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_445 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_187[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_422 (Batch  (None, 16, 16, 320)  1280       ['conv2d_445[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_446 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_422[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_423 (Batch  (None, 16, 16, 320)  1280       ['conv2d_446[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_92 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_423[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_92 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_92[0][0]',    \n",
      "                                                                  'batch_normalization_421[0][0]']\n",
      "                                                                                                  \n",
      " dropout_188 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_92[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_447 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_188[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_424 (Batch  (None, 32, 32, 160)  640        ['conv2d_447[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_448 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_424[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_425 (Batch  (None, 32, 32, 160)  640        ['conv2d_448[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_93 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_425[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_93 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_93[0][0]',    \n",
      "                                                                  'batch_normalization_419[0][0]']\n",
      "                                                                                                  \n",
      " dropout_189 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_93[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_449 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_189[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_426 (Batch  (None, 64, 64, 80)  320         ['conv2d_449[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_450 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_426[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_427 (Batch  (None, 64, 64, 80)  320         ['conv2d_450[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_94 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_427[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_94 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_94[0][0]',    \n",
      "                                )                                 'batch_normalization_417[0][0]']\n",
      "                                                                                                  \n",
      " dropout_190 (Dropout)          (None, 128, 128, 80  0           ['concatenate_94[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_451 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_190[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_428 (Batch  (None, 128, 128, 40  160        ['conv2d_451[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_452 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_428[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_429 (Batch  (None, 128, 128, 40  160        ['conv2d_452[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_95 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_429[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_95 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_95[0][0]',    \n",
      "                                )                                 'batch_normalization_415[0][0]']\n",
      "                                                                                                  \n",
      " dropout_191 (Dropout)          (None, 256, 256, 40  0           ['concatenate_95[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_453 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_191[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_430 (Batch  (None, 256, 256, 20  80         ['conv2d_453[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_454 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_430[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_431 (Batch  (None, 256, 256, 20  80         ['conv2d_454[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_455 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_431[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_25 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_456 (Conv2D)            (None, 256, 256, 20  200         ['input_25[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_432 (Batch  (None, 256, 256, 20  80         ['conv2d_456[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_457 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_432[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_433 (Batch  (None, 256, 256, 20  80         ['conv2d_457[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_96 (MaxPooling2D  (None, 128, 128, 20  0          ['batch_normalization_433[0][0]']\n",
      " )                              )                                                                 \n",
      "                                                                                                  \n",
      " dropout_192 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_96[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_458 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_192[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_434 (Batch  (None, 128, 128, 40  160        ['conv2d_458[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_459 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_434[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_435 (Batch  (None, 128, 128, 40  160        ['conv2d_459[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_97 (MaxPooling2D  (None, 64, 64, 40)  0           ['batch_normalization_435[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_193 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_97[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_460 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_193[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_436 (Batch  (None, 64, 64, 80)  320         ['conv2d_460[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_461 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_436[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_437 (Batch  (None, 64, 64, 80)  320         ['conv2d_461[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_98 (MaxPooling2D  (None, 32, 32, 80)  0           ['batch_normalization_437[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_194 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_98[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_462 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_194[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_438 (Batch  (None, 32, 32, 160)  640        ['conv2d_462[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_463 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_438[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_439 (Batch  (None, 32, 32, 160)  640        ['conv2d_463[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_99 (MaxPooling2D  (None, 16, 16, 160)  0          ['batch_normalization_439[0][0]']\n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dropout_195 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_99[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_464 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_195[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_440 (Batch  (None, 16, 16, 320)  1280       ['conv2d_464[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_465 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_440[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_441 (Batch  (None, 16, 16, 320)  1280       ['conv2d_465[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_96 (Conv2DTra  (None, 32, 32, 160)  460960     ['batch_normalization_441[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_96 (Concatenate)   (None, 32, 32, 320)  0           ['conv2d_transpose_96[0][0]',    \n",
      "                                                                  'batch_normalization_439[0][0]']\n",
      "                                                                                                  \n",
      " dropout_196 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_96[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_466 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_196[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_442 (Batch  (None, 32, 32, 160)  640        ['conv2d_466[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_467 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_442[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_443 (Batch  (None, 32, 32, 160)  640        ['conv2d_467[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_97 (Conv2DTra  (None, 64, 64, 80)  115280      ['batch_normalization_443[0][0]']\n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_97 (Concatenate)   (None, 64, 64, 160)  0           ['conv2d_transpose_97[0][0]',    \n",
      "                                                                  'batch_normalization_437[0][0]']\n",
      "                                                                                                  \n",
      " dropout_197 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_97[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_468 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_197[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_444 (Batch  (None, 64, 64, 80)  320         ['conv2d_468[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_469 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_444[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_445 (Batch  (None, 64, 64, 80)  320         ['conv2d_469[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_98 (Conv2DTra  (None, 128, 128, 40  28840      ['batch_normalization_445[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_98 (Concatenate)   (None, 128, 128, 80  0           ['conv2d_transpose_98[0][0]',    \n",
      "                                )                                 'batch_normalization_435[0][0]']\n",
      "                                                                                                  \n",
      " dropout_198 (Dropout)          (None, 128, 128, 80  0           ['concatenate_98[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_470 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_198[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_446 (Batch  (None, 128, 128, 40  160        ['conv2d_470[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_471 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_446[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_447 (Batch  (None, 128, 128, 40  160        ['conv2d_471[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_99 (Conv2DTra  (None, 256, 256, 20  7220       ['batch_normalization_447[0][0]']\n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_99 (Concatenate)   (None, 256, 256, 40  0           ['conv2d_transpose_99[0][0]',    \n",
      "                                )                                 'batch_normalization_433[0][0]']\n",
      "                                                                                                  \n",
      " dropout_199 (Dropout)          (None, 256, 256, 40  0           ['concatenate_99[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_472 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_199[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_448 (Batch  (None, 256, 256, 20  80         ['conv2d_472[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_473 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_448[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_449 (Batch  (None, 256, 256, 20  80         ['conv2d_473[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_474 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_449[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_26 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_475 (Conv2D)            (None, 256, 256, 20  200         ['input_26[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_450 (Batch  (None, 256, 256, 20  80         ['conv2d_475[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_476 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_450[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_451 (Batch  (None, 256, 256, 20  80         ['conv2d_476[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_100 (MaxPooling2  (None, 128, 128, 20  0          ['batch_normalization_451[0][0]']\n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " dropout_200 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_100[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_477 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_200[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_452 (Batch  (None, 128, 128, 40  160        ['conv2d_477[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_478 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_452[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_453 (Batch  (None, 128, 128, 40  160        ['conv2d_478[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_101 (MaxPooling2  (None, 64, 64, 40)  0           ['batch_normalization_453[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_201 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_101[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_479 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_201[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_454 (Batch  (None, 64, 64, 80)  320         ['conv2d_479[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_480 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_454[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_455 (Batch  (None, 64, 64, 80)  320         ['conv2d_480[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_102 (MaxPooling2  (None, 32, 32, 80)  0           ['batch_normalization_455[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_202 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_102[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_481 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_202[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_456 (Batch  (None, 32, 32, 160)  640        ['conv2d_481[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_482 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_456[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_457 (Batch  (None, 32, 32, 160)  640        ['conv2d_482[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_103 (MaxPooling2  (None, 16, 16, 160)  0          ['batch_normalization_457[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_203 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_103[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_483 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_203[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_458 (Batch  (None, 16, 16, 320)  1280       ['conv2d_483[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_484 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_458[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_459 (Batch  (None, 16, 16, 320)  1280       ['conv2d_484[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_100 (Conv2DTr  (None, 32, 32, 160)  460960     ['batch_normalization_459[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_100 (Concatenate)  (None, 32, 32, 320)  0           ['conv2d_transpose_100[0][0]',   \n",
      "                                                                  'batch_normalization_457[0][0]']\n",
      "                                                                                                  \n",
      " dropout_204 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_100[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_485 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_204[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_460 (Batch  (None, 32, 32, 160)  640        ['conv2d_485[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_486 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_460[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_461 (Batch  (None, 32, 32, 160)  640        ['conv2d_486[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_101 (Conv2DTr  (None, 64, 64, 80)  115280      ['batch_normalization_461[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_101 (Concatenate)  (None, 64, 64, 160)  0           ['conv2d_transpose_101[0][0]',   \n",
      "                                                                  'batch_normalization_455[0][0]']\n",
      "                                                                                                  \n",
      " dropout_205 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_101[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_487 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_205[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_462 (Batch  (None, 64, 64, 80)  320         ['conv2d_487[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_488 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_462[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_463 (Batch  (None, 64, 64, 80)  320         ['conv2d_488[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_102 (Conv2DTr  (None, 128, 128, 40  28840      ['batch_normalization_463[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_102 (Concatenate)  (None, 128, 128, 80  0           ['conv2d_transpose_102[0][0]',   \n",
      "                                )                                 'batch_normalization_453[0][0]']\n",
      "                                                                                                  \n",
      " dropout_206 (Dropout)          (None, 128, 128, 80  0           ['concatenate_102[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_489 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_206[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_464 (Batch  (None, 128, 128, 40  160        ['conv2d_489[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_490 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_464[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_465 (Batch  (None, 128, 128, 40  160        ['conv2d_490[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_103 (Conv2DTr  (None, 256, 256, 20  7220       ['batch_normalization_465[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_103 (Concatenate)  (None, 256, 256, 40  0           ['conv2d_transpose_103[0][0]',   \n",
      "                                )                                 'batch_normalization_451[0][0]']\n",
      "                                                                                                  \n",
      " dropout_207 (Dropout)          (None, 256, 256, 40  0           ['concatenate_103[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_491 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_207[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_466 (Batch  (None, 256, 256, 20  80         ['conv2d_491[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_492 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_466[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_467 (Batch  (None, 256, 256, 20  80         ['conv2d_492[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_493 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_467[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_27 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_494 (Conv2D)            (None, 256, 256, 20  200         ['input_27[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_468 (Batch  (None, 256, 256, 20  80         ['conv2d_494[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_495 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_468[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_469 (Batch  (None, 256, 256, 20  80         ['conv2d_495[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_104 (MaxPooling2  (None, 128, 128, 20  0          ['batch_normalization_469[0][0]']\n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " dropout_208 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_104[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_496 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_208[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_470 (Batch  (None, 128, 128, 40  160        ['conv2d_496[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_497 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_470[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_471 (Batch  (None, 128, 128, 40  160        ['conv2d_497[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_105 (MaxPooling2  (None, 64, 64, 40)  0           ['batch_normalization_471[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_209 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_105[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_498 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_209[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_472 (Batch  (None, 64, 64, 80)  320         ['conv2d_498[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_499 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_472[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_473 (Batch  (None, 64, 64, 80)  320         ['conv2d_499[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_106 (MaxPooling2  (None, 32, 32, 80)  0           ['batch_normalization_473[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_210 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_106[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_500 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_210[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_474 (Batch  (None, 32, 32, 160)  640        ['conv2d_500[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_501 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_474[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_475 (Batch  (None, 32, 32, 160)  640        ['conv2d_501[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_107 (MaxPooling2  (None, 16, 16, 160)  0          ['batch_normalization_475[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_211 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_107[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_502 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_211[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_476 (Batch  (None, 16, 16, 320)  1280       ['conv2d_502[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_503 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_476[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_477 (Batch  (None, 16, 16, 320)  1280       ['conv2d_503[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_104 (Conv2DTr  (None, 32, 32, 160)  460960     ['batch_normalization_477[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_104 (Concatenate)  (None, 32, 32, 320)  0           ['conv2d_transpose_104[0][0]',   \n",
      "                                                                  'batch_normalization_475[0][0]']\n",
      "                                                                                                  \n",
      " dropout_212 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_104[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_504 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_212[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_478 (Batch  (None, 32, 32, 160)  640        ['conv2d_504[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_505 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_478[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_479 (Batch  (None, 32, 32, 160)  640        ['conv2d_505[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_105 (Conv2DTr  (None, 64, 64, 80)  115280      ['batch_normalization_479[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_105 (Concatenate)  (None, 64, 64, 160)  0           ['conv2d_transpose_105[0][0]',   \n",
      "                                                                  'batch_normalization_473[0][0]']\n",
      "                                                                                                  \n",
      " dropout_213 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_105[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_506 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_213[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_480 (Batch  (None, 64, 64, 80)  320         ['conv2d_506[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_507 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_480[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_481 (Batch  (None, 64, 64, 80)  320         ['conv2d_507[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_106 (Conv2DTr  (None, 128, 128, 40  28840      ['batch_normalization_481[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_106 (Concatenate)  (None, 128, 128, 80  0           ['conv2d_transpose_106[0][0]',   \n",
      "                                )                                 'batch_normalization_471[0][0]']\n",
      "                                                                                                  \n",
      " dropout_214 (Dropout)          (None, 128, 128, 80  0           ['concatenate_106[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_508 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_214[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_482 (Batch  (None, 128, 128, 40  160        ['conv2d_508[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_509 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_482[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_483 (Batch  (None, 128, 128, 40  160        ['conv2d_509[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_107 (Conv2DTr  (None, 256, 256, 20  7220       ['batch_normalization_483[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_107 (Concatenate)  (None, 256, 256, 40  0           ['conv2d_transpose_107[0][0]',   \n",
      "                                )                                 'batch_normalization_469[0][0]']\n",
      "                                                                                                  \n",
      " dropout_215 (Dropout)          (None, 256, 256, 40  0           ['concatenate_107[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_510 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_215[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_484 (Batch  (None, 256, 256, 20  80         ['conv2d_510[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_511 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_484[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_485 (Batch  (None, 256, 256, 20  80         ['conv2d_511[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_512 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_485[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_28 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_513 (Conv2D)            (None, 256, 256, 20  200         ['input_28[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_486 (Batch  (None, 256, 256, 20  80         ['conv2d_513[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_514 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_486[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_487 (Batch  (None, 256, 256, 20  80         ['conv2d_514[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_108 (MaxPooling2  (None, 128, 128, 20  0          ['batch_normalization_487[0][0]']\n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " dropout_216 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_108[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_515 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_216[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_488 (Batch  (None, 128, 128, 40  160        ['conv2d_515[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_516 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_488[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_489 (Batch  (None, 128, 128, 40  160        ['conv2d_516[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_109 (MaxPooling2  (None, 64, 64, 40)  0           ['batch_normalization_489[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_217 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_109[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_517 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_217[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_490 (Batch  (None, 64, 64, 80)  320         ['conv2d_517[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_518 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_490[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_491 (Batch  (None, 64, 64, 80)  320         ['conv2d_518[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_110 (MaxPooling2  (None, 32, 32, 80)  0           ['batch_normalization_491[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_218 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_110[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_519 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_218[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_492 (Batch  (None, 32, 32, 160)  640        ['conv2d_519[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_520 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_492[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_493 (Batch  (None, 32, 32, 160)  640        ['conv2d_520[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_111 (MaxPooling2  (None, 16, 16, 160)  0          ['batch_normalization_493[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_219 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_111[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_521 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_219[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_494 (Batch  (None, 16, 16, 320)  1280       ['conv2d_521[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_522 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_494[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_495 (Batch  (None, 16, 16, 320)  1280       ['conv2d_522[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_108 (Conv2DTr  (None, 32, 32, 160)  460960     ['batch_normalization_495[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_108 (Concatenate)  (None, 32, 32, 320)  0           ['conv2d_transpose_108[0][0]',   \n",
      "                                                                  'batch_normalization_493[0][0]']\n",
      "                                                                                                  \n",
      " dropout_220 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_108[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_523 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_220[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_496 (Batch  (None, 32, 32, 160)  640        ['conv2d_523[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_524 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_496[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_497 (Batch  (None, 32, 32, 160)  640        ['conv2d_524[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_109 (Conv2DTr  (None, 64, 64, 80)  115280      ['batch_normalization_497[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_109 (Concatenate)  (None, 64, 64, 160)  0           ['conv2d_transpose_109[0][0]',   \n",
      "                                                                  'batch_normalization_491[0][0]']\n",
      "                                                                                                  \n",
      " dropout_221 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_109[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_525 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_221[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_498 (Batch  (None, 64, 64, 80)  320         ['conv2d_525[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_526 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_498[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_499 (Batch  (None, 64, 64, 80)  320         ['conv2d_526[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_110 (Conv2DTr  (None, 128, 128, 40  28840      ['batch_normalization_499[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_110 (Concatenate)  (None, 128, 128, 80  0           ['conv2d_transpose_110[0][0]',   \n",
      "                                )                                 'batch_normalization_489[0][0]']\n",
      "                                                                                                  \n",
      " dropout_222 (Dropout)          (None, 128, 128, 80  0           ['concatenate_110[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_527 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_222[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_500 (Batch  (None, 128, 128, 40  160        ['conv2d_527[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_528 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_500[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_501 (Batch  (None, 128, 128, 40  160        ['conv2d_528[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_111 (Conv2DTr  (None, 256, 256, 20  7220       ['batch_normalization_501[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_111 (Concatenate)  (None, 256, 256, 40  0           ['conv2d_transpose_111[0][0]',   \n",
      "                                )                                 'batch_normalization_487[0][0]']\n",
      "                                                                                                  \n",
      " dropout_223 (Dropout)          (None, 256, 256, 40  0           ['concatenate_111[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_529 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_223[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_502 (Batch  (None, 256, 256, 20  80         ['conv2d_529[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_530 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_502[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_503 (Batch  (None, 256, 256, 20  80         ['conv2d_530[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_531 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_503[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_29 (InputLayer)          [(None, 256, 256, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_532 (Conv2D)            (None, 256, 256, 20  200         ['input_29[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_504 (Batch  (None, 256, 256, 20  80         ['conv2d_532[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_533 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_504[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_505 (Batch  (None, 256, 256, 20  80         ['conv2d_533[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_112 (MaxPooling2  (None, 128, 128, 20  0          ['batch_normalization_505[0][0]']\n",
      " D)                             )                                                                 \n",
      "                                                                                                  \n",
      " dropout_224 (Dropout)          (None, 128, 128, 20  0           ['max_pooling2d_112[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_534 (Conv2D)            (None, 128, 128, 40  7240        ['dropout_224[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_506 (Batch  (None, 128, 128, 40  160        ['conv2d_534[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_535 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_506[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_507 (Batch  (None, 128, 128, 40  160        ['conv2d_535[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_113 (MaxPooling2  (None, 64, 64, 40)  0           ['batch_normalization_507[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_225 (Dropout)          (None, 64, 64, 40)   0           ['max_pooling2d_113[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_536 (Conv2D)            (None, 64, 64, 80)   28880       ['dropout_225[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_508 (Batch  (None, 64, 64, 80)  320         ['conv2d_536[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_537 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_508[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_509 (Batch  (None, 64, 64, 80)  320         ['conv2d_537[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_114 (MaxPooling2  (None, 32, 32, 80)  0           ['batch_normalization_509[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_226 (Dropout)          (None, 32, 32, 80)   0           ['max_pooling2d_114[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_538 (Conv2D)            (None, 32, 32, 160)  115360      ['dropout_226[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_510 (Batch  (None, 32, 32, 160)  640        ['conv2d_538[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_539 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_510[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_511 (Batch  (None, 32, 32, 160)  640        ['conv2d_539[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d_115 (MaxPooling2  (None, 16, 16, 160)  0          ['batch_normalization_511[0][0]']\n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " dropout_227 (Dropout)          (None, 16, 16, 160)  0           ['max_pooling2d_115[0][0]']      \n",
      "                                                                                                  \n",
      " conv2d_540 (Conv2D)            (None, 16, 16, 320)  461120      ['dropout_227[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_512 (Batch  (None, 16, 16, 320)  1280       ['conv2d_540[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_541 (Conv2D)            (None, 16, 16, 320)  921920      ['batch_normalization_512[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_513 (Batch  (None, 16, 16, 320)  1280       ['conv2d_541[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_112 (Conv2DTr  (None, 32, 32, 160)  460960     ['batch_normalization_513[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_112 (Concatenate)  (None, 32, 32, 320)  0           ['conv2d_transpose_112[0][0]',   \n",
      "                                                                  'batch_normalization_511[0][0]']\n",
      "                                                                                                  \n",
      " dropout_228 (Dropout)          (None, 32, 32, 320)  0           ['concatenate_112[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_542 (Conv2D)            (None, 32, 32, 160)  460960      ['dropout_228[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_514 (Batch  (None, 32, 32, 160)  640        ['conv2d_542[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_543 (Conv2D)            (None, 32, 32, 160)  230560      ['batch_normalization_514[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_515 (Batch  (None, 32, 32, 160)  640        ['conv2d_543[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_113 (Conv2DTr  (None, 64, 64, 80)  115280      ['batch_normalization_515[0][0]']\n",
      " anspose)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_113 (Concatenate)  (None, 64, 64, 160)  0           ['conv2d_transpose_113[0][0]',   \n",
      "                                                                  'batch_normalization_509[0][0]']\n",
      "                                                                                                  \n",
      " dropout_229 (Dropout)          (None, 64, 64, 160)  0           ['concatenate_113[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_544 (Conv2D)            (None, 64, 64, 80)   115280      ['dropout_229[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_516 (Batch  (None, 64, 64, 80)  320         ['conv2d_544[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_545 (Conv2D)            (None, 64, 64, 80)   57680       ['batch_normalization_516[0][0]']\n",
      "                                                                                                  \n",
      " batch_normalization_517 (Batch  (None, 64, 64, 80)  320         ['conv2d_545[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv2d_transpose_114 (Conv2DTr  (None, 128, 128, 40  28840      ['batch_normalization_517[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_114 (Concatenate)  (None, 128, 128, 80  0           ['conv2d_transpose_114[0][0]',   \n",
      "                                )                                 'batch_normalization_507[0][0]']\n",
      "                                                                                                  \n",
      " dropout_230 (Dropout)          (None, 128, 128, 80  0           ['concatenate_114[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_546 (Conv2D)            (None, 128, 128, 40  28840       ['dropout_230[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_518 (Batch  (None, 128, 128, 40  160        ['conv2d_546[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_547 (Conv2D)            (None, 128, 128, 40  14440       ['batch_normalization_518[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_519 (Batch  (None, 128, 128, 40  160        ['conv2d_547[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_115 (Conv2DTr  (None, 256, 256, 20  7220       ['batch_normalization_519[0][0]']\n",
      " anspose)                       )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_115 (Concatenate)  (None, 256, 256, 40  0           ['conv2d_transpose_115[0][0]',   \n",
      "                                )                                 'batch_normalization_505[0][0]']\n",
      "                                                                                                  \n",
      " dropout_231 (Dropout)          (None, 256, 256, 40  0           ['concatenate_115[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_548 (Conv2D)            (None, 256, 256, 20  7220        ['dropout_231[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_520 (Batch  (None, 256, 256, 20  80         ['conv2d_548[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_549 (Conv2D)            (None, 256, 256, 20  3620        ['batch_normalization_520[0][0]']\n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_521 (Batch  (None, 256, 256, 20  80         ['conv2d_549[0][0]']             \n",
      " Normalization)                 )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_550 (Conv2D)            (None, 256, 256, 1)  21          ['batch_normalization_521[0][0]']\n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,379,301\n",
      "Trainable params: 3,375,621\n",
      "Non-trainable params: 3,680\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "models1 = {}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model(input_layer, output_layer) for x in range(20)\n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models1[\"BCE\"]=[0,Model(input_layer, output_layer)]\n",
    "\n",
    "\n",
    "for i in [3,10, 17, 25, 40]:\n",
    "    input_layer = Input((img_size_target, img_size_target,1))\n",
    "    output_layer = build_model(input_layer, 20)\n",
    "    models1[\"wBCE-\"+str(i)]=[i, Model(input_layer, output_layer)]\n",
    "\n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models1[\"diceLoss\"] = [0,Model(input_layer, output_layer)]\n",
    "\n",
    "\n",
    "for i in [3,10, 17, 25, 40]:\n",
    "    input_layer = Input((img_size_target, img_size_target,1))\n",
    "    output_layer = build_model(input_layer, 20)\n",
    "    models1[\"wDice-\"+str(i)]=[i, Model(input_layer, output_layer)]\n",
    "\n",
    "    \n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models1[\"DiceBCE\"] = [0,Model(input_layer, output_layer)]\n",
    "    \n",
    "    \n",
    "input_layer = Input((img_size_target, img_size_target,1))\n",
    "output_layer = build_model(input_layer, 20)\n",
    "models1[\"IoULoss\"]=[0, Model(input_layer, output_layer)]\n",
    "functions = {   \"BCE\": BinaryCrossentropy,\n",
    "                \"wBCE\": weightedBinCrossEntr,\n",
    "                \"diceLoss\": diceLoss,\n",
    "                \"wDice\": weightedDiceLoss,\n",
    "                \"DiceBCE\": DiceBCE,\n",
    "                \"IoULoss\":IoULoss\n",
    "            }\n",
    "for loss in models1.keys():\n",
    "    if models1[loss][0]!=0:\n",
    "        f = functions[loss.split('-')[0]](models[loss][0])\n",
    "    else:\n",
    "        f = functions[loss]()    \n",
    "    models1[loss][1].compile(loss=f, optimizer=\"adam\", metrics=[Recall(),Precision(),\n",
    "                                                                    MeanIoU(num_classes=2), \"accuracy\", \"AUC\"])\n",
    "    print(models1[loss][1].summary())\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
